{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d032c5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68882278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/59/1f/4975d1ab3ed2244053876321ef65bc02935daed67da76c6e7d65900772a3/torch-2.2.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading torch-2.2.1-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\asusf512ua-ej269t\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.10.0)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Obtaining dependency information for typing-extensions>=4.8.0 from https://files.pythonhosted.org/packages/f9/de/dc04a3ea60b22624b51c703a84bbe0184abcd1d0b9bc8074b5d6b7ab90bb/typing_extensions-4.10.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: sympy in c:\\users\\asusf512ua-ej269t\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\asusf512ua-ej269t\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asusf512ua-ej269t\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Collecting fsspec (from torch)\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/ad/30/2281c062222dc39328843bd1ddd30ff3005ef8e30b2fd09c4d2792766061/fsspec-2024.2.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asusf512ua-ej269t\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\asusf512ua-ej269t\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torch-2.2.1-cp311-cp311-win_amd64.whl (198.6 MB)\n",
      "   ---------------------------------------- 0.0/198.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/198.6 MB 1.1 MB/s eta 0:03:03\n",
      "   ---------------------------------------- 0.2/198.6 MB 1.8 MB/s eta 0:01:48\n",
      "   ---------------------------------------- 0.3/198.6 MB 2.0 MB/s eta 0:01:41\n",
      "   ---------------------------------------- 0.4/198.6 MB 2.1 MB/s eta 0:01:36\n",
      "   ---------------------------------------- 0.5/198.6 MB 2.2 MB/s eta 0:01:32\n",
      "   ---------------------------------------- 0.6/198.6 MB 2.2 MB/s eta 0:01:33\n",
      "   ---------------------------------------- 0.8/198.6 MB 2.5 MB/s eta 0:01:21\n",
      "   ---------------------------------------- 1.0/198.6 MB 2.7 MB/s eta 0:01:14\n",
      "   ---------------------------------------- 1.1/198.6 MB 2.7 MB/s eta 0:01:14\n",
      "   ---------------------------------------- 1.2/198.6 MB 2.8 MB/s eta 0:01:11\n",
      "   ---------------------------------------- 1.3/198.6 MB 2.7 MB/s eta 0:01:15\n",
      "   ---------------------------------------- 1.3/198.6 MB 2.7 MB/s eta 0:01:15\n",
      "   ---------------------------------------- 1.6/198.6 MB 2.6 MB/s eta 0:01:16\n",
      "   ---------------------------------------- 1.7/198.6 MB 2.6 MB/s eta 0:01:15\n",
      "   ---------------------------------------- 1.7/198.6 MB 2.6 MB/s eta 0:01:15\n",
      "   ---------------------------------------- 1.7/198.6 MB 2.6 MB/s eta 0:01:15\n",
      "   ---------------------------------------- 1.7/198.6 MB 2.6 MB/s eta 0:01:15\n",
      "   ---------------------------------------- 1.7/198.6 MB 2.6 MB/s eta 0:01:15\n",
      "   ---------------------------------------- 2.2/198.6 MB 2.4 MB/s eta 0:01:21\n",
      "    --------------------------------------- 2.8/198.6 MB 3.0 MB/s eta 0:01:05\n",
      "    --------------------------------------- 2.8/198.6 MB 2.9 MB/s eta 0:01:08\n",
      "    --------------------------------------- 3.0/198.6 MB 2.9 MB/s eta 0:01:07\n",
      "    --------------------------------------- 3.1/198.6 MB 2.9 MB/s eta 0:01:08\n",
      "    --------------------------------------- 3.2/198.6 MB 2.8 MB/s eta 0:01:10\n",
      "    --------------------------------------- 3.3/198.6 MB 2.8 MB/s eta 0:01:09\n",
      "    --------------------------------------- 3.4/198.6 MB 2.8 MB/s eta 0:01:11\n",
      "    --------------------------------------- 3.5/198.6 MB 2.8 MB/s eta 0:01:11\n",
      "    --------------------------------------- 3.5/198.6 MB 2.7 MB/s eta 0:01:13\n",
      "    --------------------------------------- 3.7/198.6 MB 2.7 MB/s eta 0:01:12\n",
      "    --------------------------------------- 3.8/198.6 MB 2.7 MB/s eta 0:01:12\n",
      "    --------------------------------------- 3.9/198.6 MB 2.7 MB/s eta 0:01:13\n",
      "    --------------------------------------- 4.1/198.6 MB 2.8 MB/s eta 0:01:11\n",
      "    --------------------------------------- 4.2/198.6 MB 2.7 MB/s eta 0:01:11\n",
      "    --------------------------------------- 4.2/198.6 MB 2.7 MB/s eta 0:01:11\n",
      "    --------------------------------------- 4.3/198.6 MB 2.6 MB/s eta 0:01:15\n",
      "    --------------------------------------- 4.8/198.6 MB 2.9 MB/s eta 0:01:08\n",
      "    --------------------------------------- 4.9/198.6 MB 2.8 MB/s eta 0:01:10\n",
      "   - -------------------------------------- 5.1/198.6 MB 2.9 MB/s eta 0:01:08\n",
      "   - -------------------------------------- 5.2/198.6 MB 2.8 MB/s eta 0:01:09\n",
      "   - -------------------------------------- 5.2/198.6 MB 2.8 MB/s eta 0:01:09\n",
      "   - -------------------------------------- 5.5/198.6 MB 2.9 MB/s eta 0:01:08\n",
      "   - -------------------------------------- 5.6/198.6 MB 2.9 MB/s eta 0:01:08\n",
      "   - -------------------------------------- 5.8/198.6 MB 2.9 MB/s eta 0:01:08\n",
      "   - -------------------------------------- 6.0/198.6 MB 2.9 MB/s eta 0:01:07\n",
      "   - -------------------------------------- 6.2/198.6 MB 2.9 MB/s eta 0:01:06\n",
      "   - -------------------------------------- 6.4/198.6 MB 3.0 MB/s eta 0:01:05\n",
      "   - -------------------------------------- 6.6/198.6 MB 3.0 MB/s eta 0:01:05\n",
      "   - -------------------------------------- 6.8/198.6 MB 3.0 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 7.0/198.6 MB 3.0 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 7.0/198.6 MB 3.0 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 7.0/198.6 MB 3.0 MB/s eta 0:01:05\n",
      "   - -------------------------------------- 7.1/198.6 MB 2.9 MB/s eta 0:01:06\n",
      "   - -------------------------------------- 7.3/198.6 MB 2.9 MB/s eta 0:01:06\n",
      "   - -------------------------------------- 7.4/198.6 MB 2.9 MB/s eta 0:01:06\n",
      "   - -------------------------------------- 7.7/198.6 MB 3.0 MB/s eta 0:01:05\n",
      "   - -------------------------------------- 7.8/198.6 MB 3.0 MB/s eta 0:01:05\n",
      "   - -------------------------------------- 8.0/198.6 MB 3.0 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 8.1/198.6 MB 3.0 MB/s eta 0:01:05\n",
      "   - -------------------------------------- 8.3/198.6 MB 3.0 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 8.3/198.6 MB 3.0 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 8.5/198.6 MB 3.0 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 8.5/198.6 MB 3.0 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 8.8/198.6 MB 3.0 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 9.0/198.6 MB 3.0 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 9.0/198.6 MB 3.0 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 9.2/198.6 MB 3.0 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 9.3/198.6 MB 3.0 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 9.6/198.6 MB 3.0 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 9.8/198.6 MB 3.0 MB/s eta 0:01:04\n",
      "   -- ------------------------------------- 10.0/198.6 MB 3.0 MB/s eta 0:01:04\n",
      "   -- ------------------------------------- 10.2/198.6 MB 3.0 MB/s eta 0:01:04\n",
      "   -- ------------------------------------- 10.3/198.6 MB 3.0 MB/s eta 0:01:03\n",
      "   -- ------------------------------------- 10.5/198.6 MB 3.0 MB/s eta 0:01:03\n",
      "   -- ------------------------------------- 10.7/198.6 MB 3.1 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 10.9/198.6 MB 3.1 MB/s eta 0:01:01\n",
      "   -- ------------------------------------- 11.1/198.6 MB 3.1 MB/s eta 0:01:01\n",
      "   -- ------------------------------------- 11.1/198.6 MB 3.0 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 11.2/198.6 MB 3.0 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 11.4/198.6 MB 3.0 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 11.4/198.6 MB 3.0 MB/s eta 0:01:03\n",
      "   -- ------------------------------------- 11.6/198.6 MB 3.1 MB/s eta 0:01:01\n",
      "   -- ------------------------------------- 11.7/198.6 MB 3.1 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 11.7/198.6 MB 3.1 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 11.9/198.6 MB 3.0 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 12.1/198.6 MB 3.2 MB/s eta 0:00:59\n",
      "   -- ------------------------------------- 12.3/198.6 MB 3.1 MB/s eta 0:01:00\n",
      "   -- ------------------------------------- 12.4/198.6 MB 3.1 MB/s eta 0:01:00\n",
      "   -- ------------------------------------- 12.5/198.6 MB 3.1 MB/s eta 0:01:01\n",
      "   -- ------------------------------------- 12.7/198.6 MB 3.0 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 12.7/198.6 MB 3.0 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 12.7/198.6 MB 3.0 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 12.7/198.6 MB 3.0 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 12.7/198.6 MB 3.0 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 12.7/198.6 MB 3.0 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 12.7/198.6 MB 3.0 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 12.8/198.6 MB 2.8 MB/s eta 0:01:07\n",
      "   -- ------------------------------------- 12.9/198.6 MB 2.8 MB/s eta 0:01:08\n",
      "   -- ------------------------------------- 13.1/198.6 MB 2.8 MB/s eta 0:01:08\n",
      "   -- ------------------------------------- 13.2/198.6 MB 2.8 MB/s eta 0:01:08\n",
      "   -- ------------------------------------- 13.4/198.6 MB 2.8 MB/s eta 0:01:06\n",
      "   -- ------------------------------------- 13.4/198.6 MB 2.8 MB/s eta 0:01:06\n",
      "   -- ------------------------------------- 13.4/198.6 MB 2.8 MB/s eta 0:01:06\n",
      "   -- ------------------------------------- 13.5/198.6 MB 2.8 MB/s eta 0:01:08\n",
      "   -- ------------------------------------- 13.5/198.6 MB 2.8 MB/s eta 0:01:08\n",
      "   -- ------------------------------------- 13.5/198.6 MB 2.8 MB/s eta 0:01:08\n",
      "   -- ------------------------------------- 13.6/198.6 MB 2.7 MB/s eta 0:01:10\n",
      "   -- ------------------------------------- 13.8/198.6 MB 2.7 MB/s eta 0:01:09\n",
      "   -- ------------------------------------- 14.0/198.6 MB 2.7 MB/s eta 0:01:09\n",
      "   -- ------------------------------------- 14.1/198.6 MB 2.7 MB/s eta 0:01:09\n",
      "   -- ------------------------------------- 14.2/198.6 MB 2.7 MB/s eta 0:01:09\n",
      "   -- ------------------------------------- 14.3/198.6 MB 2.7 MB/s eta 0:01:09\n",
      "   -- ------------------------------------- 14.5/198.6 MB 2.7 MB/s eta 0:01:09\n",
      "   -- ------------------------------------- 14.6/198.6 MB 2.7 MB/s eta 0:01:08\n",
      "   -- ------------------------------------- 14.7/198.6 MB 2.7 MB/s eta 0:01:09\n",
      "   --- ------------------------------------ 14.9/198.6 MB 2.7 MB/s eta 0:01:10\n",
      "   --- ------------------------------------ 15.0/198.6 MB 2.6 MB/s eta 0:01:10\n",
      "   --- ------------------------------------ 15.1/198.6 MB 2.6 MB/s eta 0:01:11\n",
      "   --- ------------------------------------ 15.2/198.6 MB 2.6 MB/s eta 0:01:11\n",
      "   --- ------------------------------------ 15.4/198.6 MB 2.6 MB/s eta 0:01:10\n",
      "   --- ------------------------------------ 15.5/198.6 MB 2.6 MB/s eta 0:01:10\n",
      "   --- ------------------------------------ 15.7/198.6 MB 2.6 MB/s eta 0:01:11\n",
      "   --- ------------------------------------ 15.8/198.6 MB 2.6 MB/s eta 0:01:11\n",
      "   --- ------------------------------------ 15.9/198.6 MB 2.6 MB/s eta 0:01:11\n",
      "   --- ------------------------------------ 16.0/198.6 MB 2.6 MB/s eta 0:01:11\n",
      "   --- ------------------------------------ 16.2/198.6 MB 2.6 MB/s eta 0:01:12\n",
      "   --- ------------------------------------ 16.3/198.6 MB 2.5 MB/s eta 0:01:12\n",
      "   --- ------------------------------------ 16.5/198.6 MB 2.5 MB/s eta 0:01:12\n",
      "   --- ------------------------------------ 16.6/198.6 MB 2.5 MB/s eta 0:01:13\n",
      "   --- ------------------------------------ 16.6/198.6 MB 2.5 MB/s eta 0:01:13\n",
      "   --- ------------------------------------ 16.8/198.6 MB 2.5 MB/s eta 0:01:14\n",
      "   --- ------------------------------------ 16.8/198.6 MB 2.5 MB/s eta 0:01:14\n",
      "   --- ------------------------------------ 16.9/198.6 MB 2.5 MB/s eta 0:01:14\n",
      "   --- ------------------------------------ 17.0/198.6 MB 2.4 MB/s eta 0:01:15\n",
      "   --- ------------------------------------ 17.2/198.6 MB 2.5 MB/s eta 0:01:13\n",
      "   --- ------------------------------------ 17.4/198.6 MB 2.5 MB/s eta 0:01:14\n",
      "   --- ------------------------------------ 17.5/198.6 MB 2.5 MB/s eta 0:01:14\n",
      "   --- ------------------------------------ 17.6/198.6 MB 2.5 MB/s eta 0:01:14\n",
      "   --- ------------------------------------ 17.7/198.6 MB 2.5 MB/s eta 0:01:14\n",
      "   --- ------------------------------------ 17.9/198.6 MB 2.5 MB/s eta 0:01:14\n",
      "   --- ------------------------------------ 17.9/198.6 MB 2.4 MB/s eta 0:01:15\n",
      "   --- ------------------------------------ 18.0/198.6 MB 2.4 MB/s eta 0:01:15\n",
      "   --- ------------------------------------ 18.1/198.6 MB 2.4 MB/s eta 0:01:15\n",
      "   --- ------------------------------------ 18.2/198.6 MB 2.4 MB/s eta 0:01:16\n",
      "   --- ------------------------------------ 18.3/198.6 MB 2.4 MB/s eta 0:01:16\n",
      "   --- ------------------------------------ 18.4/198.6 MB 2.4 MB/s eta 0:01:16\n",
      "   --- ------------------------------------ 18.6/198.6 MB 2.4 MB/s eta 0:01:15\n",
      "   --- ------------------------------------ 18.7/198.6 MB 2.4 MB/s eta 0:01:16\n",
      "   --- ------------------------------------ 18.9/198.6 MB 2.4 MB/s eta 0:01:15\n",
      "   --- ------------------------------------ 19.0/198.6 MB 2.4 MB/s eta 0:01:15\n",
      "   --- ------------------------------------ 19.1/198.6 MB 2.4 MB/s eta 0:01:16\n",
      "   --- ------------------------------------ 19.2/198.6 MB 2.4 MB/s eta 0:01:16\n",
      "   --- ------------------------------------ 19.2/198.6 MB 2.4 MB/s eta 0:01:16\n",
      "   --- ------------------------------------ 19.4/198.6 MB 2.4 MB/s eta 0:01:16\n",
      "   --- ------------------------------------ 19.5/198.6 MB 2.4 MB/s eta 0:01:16\n",
      "   --- ------------------------------------ 19.6/198.6 MB 2.4 MB/s eta 0:01:16\n",
      "   --- ------------------------------------ 19.7/198.6 MB 2.4 MB/s eta 0:01:16\n",
      "   --- ------------------------------------ 19.7/198.6 MB 2.4 MB/s eta 0:01:16\n",
      "   ---- ----------------------------------- 19.9/198.6 MB 2.3 MB/s eta 0:01:17\n",
      "   ---- ----------------------------------- 20.0/198.6 MB 2.3 MB/s eta 0:01:17\n",
      "   ---- ----------------------------------- 20.1/198.6 MB 2.3 MB/s eta 0:01:17\n",
      "   ---- ----------------------------------- 20.3/198.6 MB 2.3 MB/s eta 0:01:17\n",
      "   ---- ----------------------------------- 20.4/198.6 MB 2.3 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 20.6/198.6 MB 2.3 MB/s eta 0:01:17\n",
      "   ---- ----------------------------------- 20.7/198.6 MB 2.3 MB/s eta 0:01:17\n",
      "   ---- ----------------------------------- 20.8/198.6 MB 2.3 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 20.9/198.6 MB 2.3 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 21.0/198.6 MB 2.3 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 21.0/198.6 MB 2.3 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 21.2/198.6 MB 2.3 MB/s eta 0:01:19\n",
      "   ---- ----------------------------------- 21.3/198.6 MB 2.3 MB/s eta 0:01:19\n",
      "   ---- ----------------------------------- 21.4/198.6 MB 2.3 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 21.6/198.6 MB 2.3 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 21.7/198.6 MB 2.3 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 21.8/198.6 MB 2.3 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 21.9/198.6 MB 2.3 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 22.0/198.6 MB 2.2 MB/s eta 0:01:19\n",
      "   ---- ----------------------------------- 22.1/198.6 MB 2.3 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 22.3/198.6 MB 2.3 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 22.4/198.6 MB 2.3 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 22.5/198.6 MB 2.3 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 22.7/198.6 MB 2.3 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 22.8/198.6 MB 2.3 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 23.0/198.6 MB 2.4 MB/s eta 0:01:13\n",
      "   ---- ----------------------------------- 23.1/198.6 MB 2.4 MB/s eta 0:01:13\n",
      "   ---- ----------------------------------- 23.2/198.6 MB 2.4 MB/s eta 0:01:14\n",
      "   ---- ----------------------------------- 23.4/198.6 MB 2.4 MB/s eta 0:01:14\n",
      "   ---- ----------------------------------- 23.5/198.6 MB 2.4 MB/s eta 0:01:14\n",
      "   ---- ----------------------------------- 23.7/198.6 MB 2.4 MB/s eta 0:01:12\n",
      "   ---- ----------------------------------- 23.8/198.6 MB 2.5 MB/s eta 0:01:10\n",
      "   ---- ----------------------------------- 24.1/198.6 MB 2.5 MB/s eta 0:01:11\n",
      "   ---- ----------------------------------- 24.2/198.6 MB 2.5 MB/s eta 0:01:11\n",
      "   ---- ----------------------------------- 24.3/198.6 MB 2.5 MB/s eta 0:01:10\n",
      "   ---- ----------------------------------- 24.4/198.6 MB 2.5 MB/s eta 0:01:11\n",
      "   ---- ----------------------------------- 24.4/198.6 MB 2.5 MB/s eta 0:01:12\n",
      "   ---- ----------------------------------- 24.5/198.6 MB 2.4 MB/s eta 0:01:12\n",
      "   ---- ----------------------------------- 24.6/198.6 MB 2.4 MB/s eta 0:01:12\n",
      "   ---- ----------------------------------- 24.7/198.6 MB 2.4 MB/s eta 0:01:12\n",
      "   ---- ----------------------------------- 24.8/198.6 MB 2.4 MB/s eta 0:01:12\n",
      "   ----- ---------------------------------- 24.9/198.6 MB 2.4 MB/s eta 0:01:12\n",
      "   ----- ---------------------------------- 25.1/198.6 MB 2.4 MB/s eta 0:01:12\n",
      "   ----- ---------------------------------- 25.2/198.6 MB 2.4 MB/s eta 0:01:12\n",
      "   ----- ---------------------------------- 25.2/198.6 MB 2.4 MB/s eta 0:01:13\n",
      "   ----- ---------------------------------- 25.4/198.6 MB 2.4 MB/s eta 0:01:11\n",
      "   ----- ---------------------------------- 25.5/198.6 MB 2.5 MB/s eta 0:01:11\n",
      "   ----- ---------------------------------- 25.6/198.6 MB 2.5 MB/s eta 0:01:11\n",
      "   ----- ---------------------------------- 25.7/198.6 MB 2.5 MB/s eta 0:01:11\n",
      "   ----- ---------------------------------- 25.9/198.6 MB 2.5 MB/s eta 0:01:11\n",
      "   ----- ---------------------------------- 26.1/198.6 MB 2.5 MB/s eta 0:01:10\n",
      "   ----- ---------------------------------- 26.1/198.6 MB 2.5 MB/s eta 0:01:11\n",
      "   ----- ---------------------------------- 26.2/198.6 MB 2.5 MB/s eta 0:01:10\n",
      "   ----- ---------------------------------- 26.3/198.6 MB 2.5 MB/s eta 0:01:11\n",
      "   ----- ---------------------------------- 26.5/198.6 MB 2.4 MB/s eta 0:01:11\n",
      "   ----- ---------------------------------- 26.6/198.6 MB 2.5 MB/s eta 0:01:11\n",
      "   ----- ---------------------------------- 26.7/198.6 MB 2.5 MB/s eta 0:01:11\n",
      "   ----- ---------------------------------- 26.8/198.6 MB 2.5 MB/s eta 0:01:10\n",
      "   ----- ---------------------------------- 27.0/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 27.2/198.6 MB 2.5 MB/s eta 0:01:10\n",
      "   ----- ---------------------------------- 27.3/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 27.4/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 27.5/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 27.6/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 27.7/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 27.8/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 28.0/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 28.0/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 28.1/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 28.3/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 28.4/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 28.5/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 28.6/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 28.8/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ----- ---------------------------------- 28.9/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 29.0/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 29.1/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 29.2/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 29.3/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 29.4/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ----- ---------------------------------- 29.5/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 29.7/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 29.8/198.6 MB 2.5 MB/s eta 0:01:09\n",
      "   ------ --------------------------------- 30.0/198.6 MB 2.5 MB/s eta 0:01:07\n",
      "   ------ --------------------------------- 30.1/198.6 MB 2.5 MB/s eta 0:01:07\n",
      "   ------ --------------------------------- 30.2/198.6 MB 2.5 MB/s eta 0:01:07\n",
      "   ------ --------------------------------- 30.3/198.6 MB 2.5 MB/s eta 0:01:07\n",
      "   ------ --------------------------------- 30.4/198.6 MB 2.5 MB/s eta 0:01:07\n",
      "   ------ --------------------------------- 30.5/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 30.6/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 30.7/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 30.8/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 30.9/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 31.0/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 31.2/198.6 MB 2.5 MB/s eta 0:01:07\n",
      "   ------ --------------------------------- 31.3/198.6 MB 2.5 MB/s eta 0:01:07\n",
      "   ------ --------------------------------- 31.4/198.6 MB 2.5 MB/s eta 0:01:07\n",
      "   ------ --------------------------------- 31.5/198.6 MB 2.5 MB/s eta 0:01:07\n",
      "   ------ --------------------------------- 31.5/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 31.7/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 31.8/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 31.9/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 32.0/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 32.1/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 32.2/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 32.2/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 32.4/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 32.4/198.6 MB 2.4 MB/s eta 0:01:09\n",
      "   ------ --------------------------------- 32.6/198.6 MB 2.4 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 32.7/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 32.9/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 32.9/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 33.0/198.6 MB 2.4 MB/s eta 0:01:09\n",
      "   ------ --------------------------------- 33.2/198.6 MB 2.4 MB/s eta 0:01:09\n",
      "   ------ --------------------------------- 33.3/198.6 MB 2.4 MB/s eta 0:01:09\n",
      "   ------ --------------------------------- 33.5/198.6 MB 2.5 MB/s eta 0:01:07\n",
      "   ------ --------------------------------- 33.6/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 33.8/198.6 MB 2.5 MB/s eta 0:01:07\n",
      "   ------ --------------------------------- 33.9/198.6 MB 2.5 MB/s eta 0:01:07\n",
      "   ------ --------------------------------- 34.0/198.6 MB 2.5 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 34.1/198.6 MB 2.5 MB/s eta 0:01:07\n",
      "   ------ --------------------------------- 34.2/198.6 MB 2.4 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 34.3/198.6 MB 2.4 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 34.4/198.6 MB 2.4 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 34.5/198.6 MB 2.4 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 34.5/198.6 MB 2.4 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 34.5/198.6 MB 2.4 MB/s eta 0:01:08\n",
      "   ------- -------------------------------- 34.9/198.6 MB 2.5 MB/s eta 0:01:07\n",
      "   ------- -------------------------------- 35.0/198.6 MB 2.5 MB/s eta 0:01:06\n",
      "   ------- -------------------------------- 35.1/198.6 MB 2.5 MB/s eta 0:01:06\n",
      "   ------- -------------------------------- 35.2/198.6 MB 2.5 MB/s eta 0:01:06\n",
      "   ------- -------------------------------- 35.2/198.6 MB 2.5 MB/s eta 0:01:06\n",
      "   ------- -------------------------------- 35.4/198.6 MB 2.4 MB/s eta 0:01:07\n",
      "   ------- -------------------------------- 35.4/198.6 MB 2.5 MB/s eta 0:01:07\n",
      "   ------- -------------------------------- 35.6/198.6 MB 2.5 MB/s eta 0:01:07\n",
      "   ------- -------------------------------- 35.7/198.6 MB 2.4 MB/s eta 0:01:07\n",
      "   ------- -------------------------------- 35.8/198.6 MB 2.4 MB/s eta 0:01:07\n",
      "   ------- -------------------------------- 36.0/198.6 MB 2.5 MB/s eta 0:01:07\n",
      "   ------- -------------------------------- 36.0/198.6 MB 2.4 MB/s eta 0:01:08\n",
      "   ------- -------------------------------- 36.1/198.6 MB 2.4 MB/s eta 0:01:07\n",
      "   ------- -------------------------------- 36.2/198.6 MB 2.4 MB/s eta 0:01:08\n",
      "   ------- -------------------------------- 36.3/198.6 MB 2.4 MB/s eta 0:01:08\n",
      "   ------- -------------------------------- 36.4/198.6 MB 2.4 MB/s eta 0:01:08\n",
      "   ------- -------------------------------- 36.6/198.6 MB 2.4 MB/s eta 0:01:07\n",
      "   ------- -------------------------------- 36.7/198.6 MB 2.4 MB/s eta 0:01:07\n",
      "   ------- -------------------------------- 36.8/198.6 MB 2.4 MB/s eta 0:01:07\n",
      "   ------- -------------------------------- 37.0/198.6 MB 2.4 MB/s eta 0:01:07\n",
      "   ------- -------------------------------- 37.1/198.6 MB 2.4 MB/s eta 0:01:07\n",
      "   ------- -------------------------------- 37.3/198.6 MB 2.4 MB/s eta 0:01:07\n",
      "   ------- -------------------------------- 37.5/198.6 MB 2.5 MB/s eta 0:01:06\n",
      "   ------- -------------------------------- 37.6/198.6 MB 2.5 MB/s eta 0:01:06\n",
      "   ------- -------------------------------- 37.8/198.6 MB 2.5 MB/s eta 0:01:06\n",
      "   ------- -------------------------------- 37.8/198.6 MB 2.4 MB/s eta 0:01:06\n",
      "   ------- -------------------------------- 37.9/198.6 MB 2.5 MB/s eta 0:01:06\n",
      "   ------- -------------------------------- 38.0/198.6 MB 2.5 MB/s eta 0:01:06\n",
      "   ------- -------------------------------- 38.2/198.6 MB 2.5 MB/s eta 0:01:06\n",
      "   ------- -------------------------------- 38.2/198.6 MB 2.5 MB/s eta 0:01:06\n",
      "   ------- -------------------------------- 38.4/198.6 MB 2.5 MB/s eta 0:01:05\n",
      "   ------- -------------------------------- 38.6/198.6 MB 2.5 MB/s eta 0:01:05\n",
      "   ------- -------------------------------- 38.7/198.6 MB 2.5 MB/s eta 0:01:05\n",
      "   ------- -------------------------------- 38.9/198.6 MB 2.5 MB/s eta 0:01:04\n",
      "   ------- -------------------------------- 39.0/198.6 MB 2.5 MB/s eta 0:01:04\n",
      "   ------- -------------------------------- 39.0/198.6 MB 2.5 MB/s eta 0:01:05\n",
      "   ------- -------------------------------- 39.2/198.6 MB 2.5 MB/s eta 0:01:05\n",
      "   ------- -------------------------------- 39.3/198.6 MB 2.5 MB/s eta 0:01:05\n",
      "   ------- -------------------------------- 39.4/198.6 MB 2.5 MB/s eta 0:01:04\n",
      "   ------- -------------------------------- 39.4/198.6 MB 2.5 MB/s eta 0:01:05\n",
      "   ------- -------------------------------- 39.6/198.6 MB 2.5 MB/s eta 0:01:04\n",
      "   ------- -------------------------------- 39.7/198.6 MB 2.5 MB/s eta 0:01:05\n",
      "   -------- ------------------------------- 39.7/198.6 MB 2.5 MB/s eta 0:01:05\n",
      "   -------- ------------------------------- 39.8/198.6 MB 2.4 MB/s eta 0:01:05\n",
      "   -------- ------------------------------- 39.9/198.6 MB 2.4 MB/s eta 0:01:05\n",
      "   -------- ------------------------------- 40.0/198.6 MB 2.4 MB/s eta 0:01:05\n",
      "   -------- ------------------------------- 40.2/198.6 MB 2.4 MB/s eta 0:01:06\n",
      "   -------- ------------------------------- 40.3/198.6 MB 2.4 MB/s eta 0:01:05\n",
      "   -------- ------------------------------- 40.5/198.6 MB 2.4 MB/s eta 0:01:05\n",
      "   -------- ------------------------------- 40.6/198.6 MB 2.5 MB/s eta 0:01:05\n",
      "   -------- ------------------------------- 40.8/198.6 MB 2.5 MB/s eta 0:01:04\n",
      "   -------- ------------------------------- 40.9/198.6 MB 2.5 MB/s eta 0:01:04\n",
      "   -------- ------------------------------- 41.0/198.6 MB 2.5 MB/s eta 0:01:03\n",
      "   -------- ------------------------------- 41.1/198.6 MB 2.5 MB/s eta 0:01:04\n",
      "   -------- ------------------------------- 41.2/198.6 MB 2.5 MB/s eta 0:01:03\n",
      "   -------- ------------------------------- 41.3/198.6 MB 2.5 MB/s eta 0:01:04\n",
      "   -------- ------------------------------- 41.5/198.6 MB 2.5 MB/s eta 0:01:03\n",
      "   -------- ------------------------------- 41.6/198.6 MB 2.5 MB/s eta 0:01:04\n",
      "   -------- ------------------------------- 41.8/198.6 MB 2.5 MB/s eta 0:01:03\n",
      "   -------- ------------------------------- 41.9/198.6 MB 2.5 MB/s eta 0:01:03\n",
      "   -------- ------------------------------- 42.1/198.6 MB 2.5 MB/s eta 0:01:02\n",
      "   -------- ------------------------------- 42.1/198.6 MB 2.5 MB/s eta 0:01:02\n",
      "   -------- ------------------------------- 42.3/198.6 MB 2.5 MB/s eta 0:01:02\n",
      "   -------- ------------------------------- 42.4/198.6 MB 2.5 MB/s eta 0:01:02\n",
      "   -------- ------------------------------- 42.5/198.6 MB 2.6 MB/s eta 0:01:01\n",
      "   -------- ------------------------------- 42.6/198.6 MB 2.6 MB/s eta 0:01:01\n",
      "   -------- ------------------------------- 42.7/198.6 MB 2.6 MB/s eta 0:01:00\n",
      "   -------- ------------------------------- 42.9/198.6 MB 2.6 MB/s eta 0:01:01\n",
      "   -------- ------------------------------- 43.0/198.6 MB 2.6 MB/s eta 0:01:01\n",
      "   -------- ------------------------------- 43.2/198.6 MB 2.6 MB/s eta 0:01:00\n",
      "   -------- ------------------------------- 43.2/198.6 MB 2.6 MB/s eta 0:01:01\n",
      "   -------- ------------------------------- 43.4/198.6 MB 2.6 MB/s eta 0:01:01\n",
      "   -------- ------------------------------- 43.5/198.6 MB 2.6 MB/s eta 0:01:01\n",
      "   -------- ------------------------------- 43.6/198.6 MB 2.6 MB/s eta 0:01:01\n",
      "   -------- ------------------------------- 43.8/198.6 MB 2.6 MB/s eta 0:01:01\n",
      "   -------- ------------------------------- 44.0/198.6 MB 2.6 MB/s eta 0:01:01\n",
      "   -------- ------------------------------- 44.2/198.6 MB 2.6 MB/s eta 0:01:00\n",
      "   -------- ------------------------------- 44.3/198.6 MB 2.6 MB/s eta 0:01:00\n",
      "   -------- ------------------------------- 44.5/198.6 MB 2.6 MB/s eta 0:00:59\n",
      "   -------- ------------------------------- 44.6/198.6 MB 2.6 MB/s eta 0:00:59\n",
      "   --------- ------------------------------ 44.8/198.6 MB 2.7 MB/s eta 0:00:57\n",
      "   --------- ------------------------------ 44.8/198.6 MB 2.7 MB/s eta 0:00:57\n",
      "   --------- ------------------------------ 45.0/198.6 MB 2.7 MB/s eta 0:00:58\n",
      "   --------- ------------------------------ 45.1/198.6 MB 2.7 MB/s eta 0:00:58\n",
      "   --------- ------------------------------ 45.3/198.6 MB 2.7 MB/s eta 0:00:58\n",
      "   --------- ------------------------------ 45.5/198.6 MB 2.7 MB/s eta 0:00:58\n",
      "   --------- ------------------------------ 45.6/198.6 MB 2.7 MB/s eta 0:00:57\n",
      "   --------- ------------------------------ 45.8/198.6 MB 2.7 MB/s eta 0:00:56\n",
      "   --------- ------------------------------ 45.9/198.6 MB 2.8 MB/s eta 0:00:56\n",
      "   --------- ------------------------------ 46.1/198.6 MB 2.8 MB/s eta 0:00:56\n",
      "   --------- ------------------------------ 46.2/198.6 MB 2.8 MB/s eta 0:00:55\n",
      "   --------- ------------------------------ 46.3/198.6 MB 2.8 MB/s eta 0:00:55\n",
      "   --------- ------------------------------ 46.4/198.6 MB 2.8 MB/s eta 0:00:55\n",
      "   --------- ------------------------------ 46.5/198.6 MB 2.8 MB/s eta 0:00:55\n",
      "   --------- ------------------------------ 46.6/198.6 MB 2.8 MB/s eta 0:00:55\n",
      "   --------- ------------------------------ 46.7/198.6 MB 2.8 MB/s eta 0:00:55\n",
      "   --------- ------------------------------ 46.8/198.6 MB 2.8 MB/s eta 0:00:55\n",
      "   --------- ------------------------------ 46.9/198.6 MB 2.7 MB/s eta 0:00:56\n",
      "   --------- ------------------------------ 47.0/198.6 MB 2.7 MB/s eta 0:00:56\n",
      "   --------- ------------------------------ 47.2/198.6 MB 2.7 MB/s eta 0:00:56\n",
      "   --------- ------------------------------ 47.3/198.6 MB 2.7 MB/s eta 0:00:56\n",
      "   --------- ------------------------------ 47.4/198.6 MB 2.7 MB/s eta 0:00:56\n",
      "   --------- ------------------------------ 47.6/198.6 MB 2.7 MB/s eta 0:00:56\n",
      "   --------- ------------------------------ 47.8/198.6 MB 2.7 MB/s eta 0:00:56\n",
      "   --------- ------------------------------ 48.0/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   --------- ------------------------------ 48.1/198.6 MB 2.8 MB/s eta 0:00:55\n",
      "   --------- ------------------------------ 48.2/198.6 MB 2.8 MB/s eta 0:00:55\n",
      "   --------- ------------------------------ 48.3/198.6 MB 2.8 MB/s eta 0:00:55\n",
      "   --------- ------------------------------ 48.4/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   --------- ------------------------------ 48.6/198.6 MB 2.8 MB/s eta 0:00:55\n",
      "   --------- ------------------------------ 48.7/198.6 MB 2.8 MB/s eta 0:00:55\n",
      "   --------- ------------------------------ 48.9/198.6 MB 2.8 MB/s eta 0:00:55\n",
      "   --------- ------------------------------ 48.9/198.6 MB 2.8 MB/s eta 0:00:55\n",
      "   --------- ------------------------------ 49.1/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   --------- ------------------------------ 49.3/198.6 MB 2.8 MB/s eta 0:00:54\n",
      "   --------- ------------------------------ 49.4/198.6 MB 2.8 MB/s eta 0:00:54\n",
      "   --------- ------------------------------ 49.5/198.6 MB 2.8 MB/s eta 0:00:54\n",
      "   ---------- ----------------------------- 49.7/198.6 MB 2.8 MB/s eta 0:00:53\n",
      "   ---------- ----------------------------- 49.8/198.6 MB 2.8 MB/s eta 0:00:53\n",
      "   ---------- ----------------------------- 49.9/198.6 MB 2.8 MB/s eta 0:00:53\n",
      "   ---------- ----------------------------- 50.0/198.6 MB 2.8 MB/s eta 0:00:53\n",
      "   ---------- ----------------------------- 50.0/198.6 MB 2.8 MB/s eta 0:00:53\n",
      "   ---------- ----------------------------- 50.0/198.6 MB 2.8 MB/s eta 0:00:54\n",
      "   ---------- ----------------------------- 50.0/198.6 MB 2.8 MB/s eta 0:00:54\n",
      "   ---------- ----------------------------- 50.0/198.6 MB 2.8 MB/s eta 0:00:54\n",
      "   ---------- ----------------------------- 50.0/198.6 MB 2.7 MB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 50.1/198.6 MB 2.7 MB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 50.2/198.6 MB 2.7 MB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 50.4/198.6 MB 2.7 MB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 50.6/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 50.8/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 50.9/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 51.0/198.6 MB 2.7 MB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 51.2/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 51.2/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 51.4/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 51.4/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 51.6/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 51.8/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 52.0/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 52.0/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 52.2/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 52.3/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 52.3/198.6 MB 2.6 MB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 52.5/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 52.7/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 52.8/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 52.8/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 53.0/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 53.1/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 53.3/198.6 MB 2.7 MB/s eta 0:00:54\n",
      "   ---------- ----------------------------- 53.4/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 53.5/198.6 MB 2.7 MB/s eta 0:00:54\n",
      "   ---------- ----------------------------- 53.6/198.6 MB 2.7 MB/s eta 0:00:54\n",
      "   ---------- ----------------------------- 53.7/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 53.8/198.6 MB 2.7 MB/s eta 0:00:54\n",
      "   ---------- ----------------------------- 54.0/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 54.1/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 54.4/198.6 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 54.5/198.6 MB 2.7 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 54.7/198.6 MB 2.7 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 54.8/198.6 MB 2.7 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 54.9/198.6 MB 2.7 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 55.0/198.6 MB 2.6 MB/s eta 0:00:55\n",
      "   ----------- ---------------------------- 55.2/198.6 MB 2.7 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 55.3/198.6 MB 2.7 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 55.4/198.6 MB 2.7 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 55.6/198.6 MB 2.7 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 55.6/198.6 MB 2.7 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 55.8/198.6 MB 2.7 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 56.0/198.6 MB 2.6 MB/s eta 0:00:55\n",
      "   ----------- ---------------------------- 56.1/198.6 MB 2.6 MB/s eta 0:00:55\n",
      "   ----------- ---------------------------- 56.3/198.6 MB 2.6 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 56.4/198.6 MB 2.6 MB/s eta 0:00:55\n",
      "   ----------- ---------------------------- 56.5/198.6 MB 2.6 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 56.7/198.6 MB 2.7 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 56.7/198.6 MB 2.6 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 56.8/198.6 MB 2.7 MB/s eta 0:00:53\n",
      "   ----------- ---------------------------- 56.9/198.6 MB 2.6 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 57.1/198.6 MB 2.7 MB/s eta 0:00:53\n",
      "   ----------- ---------------------------- 57.1/198.6 MB 2.7 MB/s eta 0:00:53\n",
      "   ----------- ---------------------------- 57.3/198.6 MB 2.6 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 57.4/198.6 MB 2.6 MB/s eta 0:00:55\n",
      "   ----------- ---------------------------- 57.5/198.6 MB 2.6 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 57.7/198.6 MB 2.6 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 57.8/198.6 MB 2.6 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 57.9/198.6 MB 2.6 MB/s eta 0:00:55\n",
      "   ----------- ---------------------------- 58.1/198.6 MB 2.6 MB/s eta 0:00:55\n",
      "   ----------- ---------------------------- 58.2/198.6 MB 2.6 MB/s eta 0:00:55\n",
      "   ----------- ---------------------------- 58.4/198.6 MB 2.6 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 58.6/198.6 MB 2.6 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 58.7/198.6 MB 2.6 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 58.9/198.6 MB 2.6 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 59.1/198.6 MB 2.6 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 59.1/198.6 MB 2.6 MB/s eta 0:00:55\n",
      "   ----------- ---------------------------- 59.2/198.6 MB 2.6 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 59.5/198.6 MB 2.6 MB/s eta 0:00:54\n",
      "   ------------ --------------------------- 59.6/198.6 MB 2.6 MB/s eta 0:00:54\n",
      "   ------------ --------------------------- 59.8/198.6 MB 2.6 MB/s eta 0:00:54\n",
      "   ------------ --------------------------- 60.0/198.6 MB 2.6 MB/s eta 0:00:54\n",
      "   ------------ --------------------------- 60.1/198.6 MB 2.6 MB/s eta 0:00:54\n",
      "   ------------ --------------------------- 60.2/198.6 MB 2.6 MB/s eta 0:00:54\n",
      "   ------------ --------------------------- 60.4/198.6 MB 2.8 MB/s eta 0:00:51\n",
      "   ------------ --------------------------- 60.6/198.6 MB 2.8 MB/s eta 0:00:50\n",
      "   ------------ --------------------------- 60.9/198.6 MB 2.8 MB/s eta 0:00:50\n",
      "   ------------ --------------------------- 61.1/198.6 MB 2.8 MB/s eta 0:00:49\n",
      "   ------------ --------------------------- 61.4/198.6 MB 2.8 MB/s eta 0:00:49\n",
      "   ------------ --------------------------- 61.7/198.6 MB 2.8 MB/s eta 0:00:49\n",
      "   ------------ --------------------------- 61.7/198.6 MB 2.9 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 62.1/198.6 MB 2.9 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 62.2/198.6 MB 2.9 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 62.3/198.6 MB 2.9 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 62.4/198.6 MB 2.9 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 62.6/198.6 MB 2.9 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 62.8/198.6 MB 2.9 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 63.0/198.6 MB 2.9 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 63.2/198.6 MB 2.9 MB/s eta 0:00:47\n",
      "   ------------ --------------------------- 63.4/198.6 MB 3.0 MB/s eta 0:00:46\n",
      "   ------------ --------------------------- 63.6/198.6 MB 3.0 MB/s eta 0:00:46\n",
      "   ------------ --------------------------- 63.8/198.6 MB 3.0 MB/s eta 0:00:46\n",
      "   ------------ --------------------------- 64.0/198.6 MB 3.0 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 64.2/198.6 MB 3.0 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 64.3/198.6 MB 3.0 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 64.4/198.6 MB 3.0 MB/s eta 0:00:45\n",
      "   ------------- -------------------------- 64.5/198.6 MB 3.0 MB/s eta 0:00:45\n",
      "   ------------- -------------------------- 64.7/198.6 MB 3.0 MB/s eta 0:00:45\n",
      "   ------------- -------------------------- 64.9/198.6 MB 3.0 MB/s eta 0:00:46\n",
      "   ------------- -------------------------- 65.0/198.6 MB 2.9 MB/s eta 0:00:46\n",
      "   ------------- -------------------------- 65.3/198.6 MB 3.0 MB/s eta 0:00:45\n",
      "   ------------- -------------------------- 65.4/198.6 MB 3.0 MB/s eta 0:00:45\n",
      "   ------------- -------------------------- 65.7/198.6 MB 3.0 MB/s eta 0:00:44\n",
      "   ------------- -------------------------- 65.9/198.6 MB 3.1 MB/s eta 0:00:44\n",
      "   ------------- -------------------------- 66.1/198.6 MB 3.1 MB/s eta 0:00:44\n",
      "   ------------- -------------------------- 66.3/198.6 MB 3.1 MB/s eta 0:00:44\n",
      "   ------------- -------------------------- 66.5/198.6 MB 3.1 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 66.7/198.6 MB 3.1 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 66.7/198.6 MB 3.1 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 66.9/198.6 MB 3.1 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 67.1/198.6 MB 3.1 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 67.3/198.6 MB 3.2 MB/s eta 0:00:41\n",
      "   ------------- -------------------------- 67.4/198.6 MB 3.2 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 67.6/198.6 MB 3.1 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 67.7/198.6 MB 3.2 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 68.0/198.6 MB 3.2 MB/s eta 0:00:41\n",
      "   ------------- -------------------------- 68.1/198.6 MB 3.2 MB/s eta 0:00:41\n",
      "   ------------- -------------------------- 68.3/198.6 MB 3.2 MB/s eta 0:00:41\n",
      "   ------------- -------------------------- 68.3/198.6 MB 3.2 MB/s eta 0:00:41\n",
      "   ------------- -------------------------- 68.5/198.6 MB 3.2 MB/s eta 0:00:41\n",
      "   ------------- -------------------------- 68.7/198.6 MB 3.2 MB/s eta 0:00:41\n",
      "   ------------- -------------------------- 68.7/198.6 MB 3.2 MB/s eta 0:00:41\n",
      "   ------------- -------------------------- 68.8/198.6 MB 3.1 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 69.0/198.6 MB 3.1 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 69.2/198.6 MB 3.1 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 69.3/198.6 MB 3.2 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 69.5/198.6 MB 3.2 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 69.6/198.6 MB 3.2 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 69.7/198.6 MB 3.2 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 69.9/198.6 MB 3.2 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 70.0/198.6 MB 3.2 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 70.1/198.6 MB 3.1 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 70.2/198.6 MB 3.1 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 70.5/198.6 MB 3.2 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 70.7/198.6 MB 3.2 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 70.8/198.6 MB 3.2 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 71.0/198.6 MB 3.1 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 71.3/198.6 MB 3.1 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 71.5/198.6 MB 3.1 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 71.7/198.6 MB 3.1 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 72.0/198.6 MB 3.1 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 72.1/198.6 MB 3.1 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 72.2/198.6 MB 3.1 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 72.3/198.6 MB 3.1 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 72.3/198.6 MB 3.1 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 72.6/198.6 MB 3.1 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 72.8/198.6 MB 3.1 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 73.0/198.6 MB 3.1 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 73.2/198.6 MB 3.1 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 73.4/198.6 MB 3.1 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 73.6/198.6 MB 3.1 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 73.8/198.6 MB 3.1 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 74.0/198.6 MB 3.1 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 74.1/198.6 MB 3.1 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 74.4/198.6 MB 3.1 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 74.7/198.6 MB 3.1 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 74.9/198.6 MB 3.2 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 75.1/198.6 MB 3.2 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 75.4/198.6 MB 3.2 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 75.7/198.6 MB 3.2 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 75.9/198.6 MB 3.2 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 76.1/198.6 MB 3.2 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 76.3/198.6 MB 3.2 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 76.5/198.6 MB 3.2 MB/s eta 0:00:38\n",
      "   --------------- ------------------------ 76.7/198.6 MB 3.2 MB/s eta 0:00:38\n",
      "   --------------- ------------------------ 76.9/198.6 MB 3.2 MB/s eta 0:00:38\n",
      "   --------------- ------------------------ 77.1/198.6 MB 3.2 MB/s eta 0:00:38\n",
      "   --------------- ------------------------ 77.6/198.6 MB 3.3 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 77.7/198.6 MB 3.3 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 78.0/198.6 MB 3.4 MB/s eta 0:00:36\n",
      "   --------------- ------------------------ 78.2/198.6 MB 3.4 MB/s eta 0:00:36\n",
      "   --------------- ------------------------ 78.4/198.6 MB 3.4 MB/s eta 0:00:36\n",
      "   --------------- ------------------------ 78.7/198.6 MB 3.5 MB/s eta 0:00:35\n",
      "   --------------- ------------------------ 78.9/198.6 MB 3.5 MB/s eta 0:00:35\n",
      "   --------------- ------------------------ 79.0/198.6 MB 3.5 MB/s eta 0:00:34\n",
      "   --------------- ------------------------ 79.2/198.6 MB 3.6 MB/s eta 0:00:34\n",
      "   --------------- ------------------------ 79.4/198.6 MB 3.6 MB/s eta 0:00:34\n",
      "   ---------------- ----------------------- 79.7/198.6 MB 3.6 MB/s eta 0:00:34\n",
      "   ---------------- ----------------------- 79.8/198.6 MB 3.6 MB/s eta 0:00:34\n",
      "   ---------------- ----------------------- 80.1/198.6 MB 3.6 MB/s eta 0:00:34\n",
      "   ---------------- ----------------------- 80.3/198.6 MB 3.7 MB/s eta 0:00:33\n",
      "   ---------------- ----------------------- 80.5/198.6 MB 3.7 MB/s eta 0:00:32\n",
      "   ---------------- ----------------------- 80.8/198.6 MB 3.8 MB/s eta 0:00:32\n",
      "   ---------------- ----------------------- 80.9/198.6 MB 3.7 MB/s eta 0:00:32\n",
      "   ---------------- ----------------------- 81.2/198.6 MB 3.8 MB/s eta 0:00:32\n",
      "   ---------------- ----------------------- 81.5/198.6 MB 3.8 MB/s eta 0:00:31\n",
      "   ---------------- ----------------------- 81.7/198.6 MB 3.9 MB/s eta 0:00:31\n",
      "   ---------------- ----------------------- 81.9/198.6 MB 3.8 MB/s eta 0:00:31\n",
      "   ---------------- ----------------------- 82.0/198.6 MB 3.8 MB/s eta 0:00:31\n",
      "   ---------------- ----------------------- 82.4/198.6 MB 3.9 MB/s eta 0:00:30\n",
      "   ---------------- ----------------------- 82.4/198.6 MB 3.8 MB/s eta 0:00:31\n",
      "   ---------------- ----------------------- 82.7/198.6 MB 4.0 MB/s eta 0:00:30\n",
      "   ---------------- ----------------------- 83.0/198.6 MB 3.9 MB/s eta 0:00:30\n",
      "   ---------------- ----------------------- 83.1/198.6 MB 3.9 MB/s eta 0:00:30\n",
      "   ---------------- ----------------------- 83.1/198.6 MB 3.9 MB/s eta 0:00:30\n",
      "   ---------------- ----------------------- 83.1/198.6 MB 3.8 MB/s eta 0:00:31\n",
      "   ---------------- ----------------------- 83.5/198.6 MB 3.9 MB/s eta 0:00:30\n",
      "   ---------------- ----------------------- 83.6/198.6 MB 3.8 MB/s eta 0:00:31\n",
      "   ---------------- ----------------------- 83.9/198.6 MB 3.9 MB/s eta 0:00:30\n",
      "   ---------------- ----------------------- 83.9/198.6 MB 3.9 MB/s eta 0:00:30\n",
      "   ---------------- ----------------------- 84.0/198.6 MB 3.7 MB/s eta 0:00:31\n",
      "   ---------------- ----------------------- 84.2/198.6 MB 3.7 MB/s eta 0:00:31\n",
      "   ----------------- ---------------------- 84.6/198.6 MB 3.8 MB/s eta 0:00:31\n",
      "   ----------------- ---------------------- 84.7/198.6 MB 3.8 MB/s eta 0:00:31\n",
      "   ----------------- ---------------------- 85.0/198.6 MB 3.7 MB/s eta 0:00:31\n",
      "   ----------------- ---------------------- 85.1/198.6 MB 3.7 MB/s eta 0:00:31\n",
      "   ----------------- ---------------------- 85.5/198.6 MB 3.8 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 85.7/198.6 MB 3.8 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 86.0/198.6 MB 3.8 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 86.1/198.6 MB 3.8 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 86.5/198.6 MB 3.8 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 86.5/198.6 MB 3.8 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 86.6/198.6 MB 3.7 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 86.7/198.6 MB 3.7 MB/s eta 0:00:31\n",
      "   ----------------- ---------------------- 86.9/198.6 MB 3.7 MB/s eta 0:00:31\n",
      "   ----------------- ---------------------- 87.3/198.6 MB 3.8 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 87.4/198.6 MB 3.8 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 87.5/198.6 MB 3.7 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 87.6/198.6 MB 3.7 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 87.8/198.6 MB 3.7 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 87.8/198.6 MB 3.7 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 87.8/198.6 MB 3.7 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 87.8/198.6 MB 3.7 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 88.0/198.6 MB 3.5 MB/s eta 0:00:32\n",
      "   ----------------- ---------------------- 88.1/198.6 MB 3.5 MB/s eta 0:00:32\n",
      "   ----------------- ---------------------- 88.2/198.6 MB 3.4 MB/s eta 0:00:33\n",
      "   ----------------- ---------------------- 88.2/198.6 MB 3.4 MB/s eta 0:00:33\n",
      "   ----------------- ---------------------- 88.2/198.6 MB 3.4 MB/s eta 0:00:33\n",
      "   ----------------- ---------------------- 88.2/198.6 MB 3.4 MB/s eta 0:00:33\n",
      "   ----------------- ---------------------- 88.4/198.6 MB 3.3 MB/s eta 0:00:34\n",
      "   ----------------- ---------------------- 89.1/198.6 MB 3.4 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 89.4/198.6 MB 3.4 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 89.5/198.6 MB 3.5 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 89.8/198.6 MB 3.5 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 89.9/198.6 MB 3.5 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 90.1/198.6 MB 3.5 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 90.2/198.6 MB 3.5 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 90.4/198.6 MB 3.5 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 90.7/198.6 MB 3.5 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 90.7/198.6 MB 3.5 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 90.7/198.6 MB 3.5 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 91.0/198.6 MB 3.4 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 91.2/198.6 MB 3.4 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 91.3/198.6 MB 3.4 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 91.5/198.6 MB 3.4 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 91.7/198.6 MB 3.4 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 91.9/198.6 MB 3.4 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 92.0/198.6 MB 3.3 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 92.2/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 92.3/198.6 MB 3.4 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 92.6/198.6 MB 3.4 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 92.7/198.6 MB 3.4 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 92.8/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 92.8/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 92.9/198.6 MB 3.3 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 93.1/198.6 MB 3.3 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 93.2/198.6 MB 3.3 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 93.3/198.6 MB 3.4 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 93.5/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 93.6/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 93.7/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 93.9/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 94.1/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 94.3/198.6 MB 3.4 MB/s eta 0:00:31\n",
      "   ------------------- -------------------- 94.5/198.6 MB 3.4 MB/s eta 0:00:31\n",
      "   ------------------- -------------------- 94.8/198.6 MB 3.4 MB/s eta 0:00:31\n",
      "   ------------------- -------------------- 94.8/198.6 MB 3.4 MB/s eta 0:00:31\n",
      "   ------------------- -------------------- 94.8/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 94.9/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 95.2/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 95.3/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 95.5/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 95.7/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 95.9/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 96.0/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 96.3/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 96.5/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 96.7/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 96.7/198.6 MB 3.2 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 96.8/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 96.9/198.6 MB 3.2 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 97.1/198.6 MB 3.2 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 97.2/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 97.2/198.6 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 97.2/198.6 MB 3.1 MB/s eta 0:00:33\n",
      "   ------------------- -------------------- 97.6/198.6 MB 3.1 MB/s eta 0:00:33\n",
      "   ------------------- -------------------- 97.8/198.6 MB 3.2 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 97.9/198.6 MB 3.2 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 98.0/198.6 MB 3.2 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 98.2/198.6 MB 3.3 MB/s eta 0:00:31\n",
      "   ------------------- -------------------- 98.4/198.6 MB 3.5 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 98.5/198.6 MB 3.5 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 98.7/198.6 MB 3.5 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 98.8/198.6 MB 3.5 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 98.9/198.6 MB 3.5 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 99.0/198.6 MB 3.4 MB/s eta 0:00:30\n",
      "   ------------------- -------------------- 99.1/198.6 MB 3.3 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 99.3/198.6 MB 3.3 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 99.5/198.6 MB 3.2 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 99.7/198.6 MB 3.2 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 99.8/198.6 MB 3.2 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 100.0/198.6 MB 3.2 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 100.3/198.6 MB 3.2 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 100.4/198.6 MB 3.3 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 100.6/198.6 MB 3.3 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 100.7/198.6 MB 3.2 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 100.8/198.6 MB 3.2 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 100.9/198.6 MB 3.2 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 101.0/198.6 MB 3.3 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 101.2/198.6 MB 3.2 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 101.4/198.6 MB 3.2 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 101.6/198.6 MB 3.2 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 101.7/198.6 MB 3.2 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 101.9/198.6 MB 3.2 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 102.1/198.6 MB 3.2 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 102.3/198.6 MB 3.2 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 102.5/198.6 MB 3.2 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 102.7/198.6 MB 3.2 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 102.7/198.6 MB 3.2 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 103.0/198.6 MB 3.3 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 103.1/198.6 MB 3.3 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 103.2/198.6 MB 3.3 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 103.3/198.6 MB 3.3 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 103.5/198.6 MB 3.3 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 103.7/198.6 MB 3.3 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 103.9/198.6 MB 3.3 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 104.1/198.6 MB 3.4 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 104.2/198.6 MB 3.3 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 104.5/198.6 MB 3.4 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 104.6/198.6 MB 3.3 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 104.8/198.6 MB 3.3 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 104.9/198.6 MB 3.3 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 105.0/198.6 MB 3.3 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 105.2/198.6 MB 3.4 MB/s eta 0:00:28\n",
      "   --------------------- ------------------ 105.2/198.6 MB 3.3 MB/s eta 0:00:28\n",
      "   --------------------- ------------------ 105.2/198.6 MB 3.3 MB/s eta 0:00:28\n",
      "   --------------------- ------------------ 105.2/198.6 MB 3.3 MB/s eta 0:00:28\n",
      "   --------------------- ------------------ 105.5/198.6 MB 3.2 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 105.6/198.6 MB 3.3 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 105.6/198.6 MB 3.3 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 105.6/198.6 MB 3.1 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 105.9/198.6 MB 3.2 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 105.9/198.6 MB 3.1 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 106.2/198.6 MB 3.1 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 106.3/198.6 MB 3.1 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 106.5/198.6 MB 3.1 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 106.7/198.6 MB 3.1 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 106.9/198.6 MB 3.1 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 107.0/198.6 MB 3.2 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 107.0/198.6 MB 3.2 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 107.0/198.6 MB 3.2 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 107.1/198.6 MB 3.1 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 107.2/198.6 MB 3.1 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 107.3/198.6 MB 3.1 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 107.5/198.6 MB 3.2 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 107.6/198.6 MB 3.1 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 107.7/198.6 MB 3.1 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 107.8/198.6 MB 3.0 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 108.0/198.6 MB 3.1 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 108.1/198.6 MB 3.0 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 108.3/198.6 MB 3.0 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 108.4/198.6 MB 3.0 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 108.5/198.6 MB 3.0 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 108.7/198.6 MB 3.0 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 108.8/198.6 MB 3.0 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 109.0/198.6 MB 3.0 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 109.1/198.6 MB 3.0 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 109.3/198.6 MB 3.1 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 109.5/198.6 MB 3.1 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 109.6/198.6 MB 3.0 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 109.9/198.6 MB 3.1 MB/s eta 0:00:29\n",
      "   ---------------------- ----------------- 109.9/198.6 MB 3.0 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 110.1/198.6 MB 3.0 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 110.3/198.6 MB 3.0 MB/s eta 0:00:29\n",
      "   ---------------------- ----------------- 110.4/198.6 MB 3.0 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 110.5/198.6 MB 3.0 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 110.6/198.6 MB 3.0 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 110.7/198.6 MB 3.0 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 110.9/198.6 MB 2.9 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 111.0/198.6 MB 2.9 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 111.1/198.6 MB 3.0 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 111.2/198.6 MB 3.0 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 111.3/198.6 MB 3.0 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 111.4/198.6 MB 2.9 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 111.6/198.6 MB 2.9 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 111.7/198.6 MB 2.9 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 111.9/198.6 MB 2.9 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 112.1/198.6 MB 2.9 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 112.2/198.6 MB 2.9 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 112.3/198.6 MB 2.9 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 112.4/198.6 MB 2.9 MB/s eta 0:00:31\n",
      "   ---------------------- ----------------- 112.6/198.6 MB 2.9 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 112.8/198.6 MB 2.9 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 112.9/198.6 MB 2.9 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 113.2/198.6 MB 2.9 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 113.4/198.6 MB 2.9 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 113.6/198.6 MB 2.9 MB/s eta 0:00:29\n",
      "   ---------------------- ----------------- 113.7/198.6 MB 2.9 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 113.9/198.6 MB 2.9 MB/s eta 0:00:29\n",
      "   ---------------------- ----------------- 114.2/198.6 MB 2.9 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 114.3/198.6 MB 2.9 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 114.5/198.6 MB 2.9 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 114.5/198.6 MB 2.9 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 114.7/198.6 MB 2.9 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 114.8/198.6 MB 2.9 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 115.0/198.6 MB 2.9 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 115.1/198.6 MB 2.9 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 115.3/198.6 MB 2.9 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 115.4/198.6 MB 2.9 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 115.6/198.6 MB 3.0 MB/s eta 0:00:28\n",
      "   ----------------------- ---------------- 115.9/198.6 MB 3.1 MB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 116.0/198.6 MB 3.1 MB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 116.2/198.6 MB 3.1 MB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 116.3/198.6 MB 3.0 MB/s eta 0:00:28\n",
      "   ----------------------- ---------------- 116.3/198.6 MB 3.0 MB/s eta 0:00:28\n",
      "   ----------------------- ---------------- 116.3/198.6 MB 3.0 MB/s eta 0:00:28\n",
      "   ----------------------- ---------------- 116.3/198.6 MB 3.0 MB/s eta 0:00:28\n",
      "   ----------------------- ---------------- 116.6/198.6 MB 3.0 MB/s eta 0:00:28\n",
      "   ----------------------- ---------------- 116.6/198.6 MB 2.9 MB/s eta 0:00:28\n",
      "   ----------------------- ---------------- 116.8/198.6 MB 2.9 MB/s eta 0:00:28\n",
      "   ----------------------- ---------------- 116.9/198.6 MB 2.9 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 117.2/198.6 MB 2.9 MB/s eta 0:00:28\n",
      "   ----------------------- ---------------- 117.3/198.6 MB 3.0 MB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 117.6/198.6 MB 3.1 MB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 117.7/198.6 MB 3.0 MB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 117.9/198.6 MB 3.1 MB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 118.0/198.6 MB 3.1 MB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 118.3/198.6 MB 3.1 MB/s eta 0:00:26\n",
      "   ----------------------- ---------------- 118.4/198.6 MB 3.1 MB/s eta 0:00:26\n",
      "   ----------------------- ---------------- 118.5/198.6 MB 3.1 MB/s eta 0:00:26\n",
      "   ----------------------- ---------------- 118.6/198.6 MB 3.1 MB/s eta 0:00:26\n",
      "   ----------------------- ---------------- 118.7/198.6 MB 3.1 MB/s eta 0:00:26\n",
      "   ----------------------- ---------------- 118.9/198.6 MB 3.1 MB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 119.0/198.6 MB 3.1 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 119.2/198.6 MB 3.1 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 119.4/198.6 MB 3.1 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 119.6/198.6 MB 3.1 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 119.6/198.6 MB 3.1 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 119.8/198.6 MB 3.1 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 120.0/198.6 MB 3.0 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 120.2/198.6 MB 3.1 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 120.4/198.6 MB 3.1 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 120.5/198.6 MB 3.1 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 120.5/198.6 MB 3.1 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 120.7/198.6 MB 3.1 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 120.8/198.6 MB 3.1 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 120.9/198.6 MB 3.0 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 121.0/198.6 MB 3.0 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 121.2/198.6 MB 3.1 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 121.4/198.6 MB 3.1 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 121.5/198.6 MB 3.1 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 121.7/198.6 MB 3.1 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 121.8/198.6 MB 3.1 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 122.0/198.6 MB 3.1 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 122.1/198.6 MB 3.1 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 122.1/198.6 MB 3.1 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 122.4/198.6 MB 3.1 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 122.5/198.6 MB 3.1 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 122.7/198.6 MB 3.1 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 122.8/198.6 MB 3.1 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 123.0/198.6 MB 3.1 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 123.2/198.6 MB 3.1 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 123.4/198.6 MB 3.1 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 123.5/198.6 MB 3.1 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 123.8/198.6 MB 3.1 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 123.9/198.6 MB 3.1 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 124.1/198.6 MB 3.1 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 124.3/198.6 MB 3.1 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 124.3/198.6 MB 3.0 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 124.5/198.6 MB 3.1 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 124.7/198.6 MB 3.0 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 124.8/198.6 MB 3.1 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 125.0/198.6 MB 3.1 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 125.2/198.6 MB 3.1 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 125.4/198.6 MB 3.1 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 125.6/198.6 MB 3.1 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 125.8/198.6 MB 3.1 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 126.0/198.6 MB 3.1 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 126.2/198.6 MB 3.1 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 126.4/198.6 MB 3.1 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 126.6/198.6 MB 3.3 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 126.7/198.6 MB 3.2 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 126.9/198.6 MB 3.2 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 127.0/198.6 MB 3.3 MB/s eta 0:00:22\n",
      "   ------------------------- -------------- 127.2/198.6 MB 3.2 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 127.2/198.6 MB 3.2 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 127.3/198.6 MB 3.2 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 127.3/198.6 MB 3.2 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 127.3/198.6 MB 3.2 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 127.3/198.6 MB 3.0 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 127.5/198.6 MB 3.0 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 127.7/198.6 MB 3.1 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 127.8/198.6 MB 3.0 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 128.0/198.6 MB 3.0 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 128.0/198.6 MB 3.0 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 128.2/198.6 MB 3.0 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 128.3/198.6 MB 3.0 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 128.5/198.6 MB 3.0 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 128.7/198.6 MB 3.0 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 128.8/198.6 MB 3.0 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 129.0/198.6 MB 3.1 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 129.0/198.6 MB 3.0 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 129.3/198.6 MB 3.1 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 129.4/198.6 MB 3.0 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 129.5/198.6 MB 3.0 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 129.6/198.6 MB 3.0 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 129.7/198.6 MB 3.0 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 129.7/198.6 MB 3.0 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 129.8/198.6 MB 3.0 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 129.9/198.6 MB 3.0 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 130.0/198.6 MB 3.0 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 130.1/198.6 MB 2.9 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 130.3/198.6 MB 2.9 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 130.5/198.6 MB 2.9 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 130.6/198.6 MB 2.9 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 130.9/198.6 MB 3.0 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 130.9/198.6 MB 3.0 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 131.1/198.6 MB 3.0 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 131.3/198.6 MB 3.0 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 131.5/198.6 MB 3.0 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 131.6/198.6 MB 3.0 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 131.7/198.6 MB 3.0 MB/s eta 0:00:22\n",
      "   -------------------------- ------------- 131.8/198.6 MB 3.0 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 131.9/198.6 MB 3.0 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 132.1/198.6 MB 3.0 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 132.2/198.6 MB 3.0 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 132.4/198.6 MB 3.0 MB/s eta 0:00:22\n",
      "   -------------------------- ------------- 132.5/198.6 MB 3.0 MB/s eta 0:00:22\n",
      "   -------------------------- ------------- 132.7/198.6 MB 3.0 MB/s eta 0:00:22\n",
      "   -------------------------- ------------- 132.7/198.6 MB 3.0 MB/s eta 0:00:22\n",
      "   -------------------------- ------------- 133.0/198.6 MB 3.0 MB/s eta 0:00:22\n",
      "   -------------------------- ------------- 133.0/198.6 MB 3.0 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 133.2/198.6 MB 3.0 MB/s eta 0:00:22\n",
      "   -------------------------- ------------- 133.3/198.6 MB 2.9 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 133.5/198.6 MB 3.0 MB/s eta 0:00:22\n",
      "   -------------------------- ------------- 133.6/198.6 MB 2.9 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 133.7/198.6 MB 2.9 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 133.8/198.6 MB 2.9 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 133.8/198.6 MB 2.9 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 133.8/198.6 MB 2.9 MB/s eta 0:00:23\n",
      "   --------------------------- ------------ 134.1/198.6 MB 2.9 MB/s eta 0:00:23\n",
      "   --------------------------- ------------ 134.2/198.6 MB 2.9 MB/s eta 0:00:23\n",
      "   --------------------------- ------------ 134.2/198.6 MB 2.9 MB/s eta 0:00:23\n",
      "   --------------------------- ------------ 134.4/198.6 MB 2.8 MB/s eta 0:00:23\n",
      "   --------------------------- ------------ 134.4/198.6 MB 2.8 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 134.5/198.6 MB 2.8 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 134.7/198.6 MB 2.8 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 134.7/198.6 MB 2.8 MB/s eta 0:00:23\n",
      "   --------------------------- ------------ 134.9/198.6 MB 2.8 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 134.9/198.6 MB 2.7 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 135.0/198.6 MB 2.7 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 135.1/198.6 MB 2.7 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 135.1/198.6 MB 2.7 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 135.2/198.6 MB 2.7 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 135.4/198.6 MB 2.7 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 135.5/198.6 MB 2.6 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 135.6/198.6 MB 2.6 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 135.8/198.6 MB 2.6 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 135.9/198.6 MB 2.6 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 136.0/198.6 MB 2.6 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 136.0/198.6 MB 2.6 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 136.2/198.6 MB 2.6 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 136.3/198.6 MB 2.6 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 136.3/198.6 MB 2.6 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 136.4/198.6 MB 2.5 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 136.6/198.6 MB 2.5 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 136.6/198.6 MB 2.5 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 136.7/198.6 MB 2.5 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 136.8/198.6 MB 2.5 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 136.9/198.6 MB 2.5 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 137.1/198.6 MB 2.5 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 137.2/198.6 MB 2.5 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 137.3/198.6 MB 2.5 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 137.4/198.6 MB 2.5 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 137.5/198.6 MB 2.5 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 137.5/198.6 MB 2.5 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 137.7/198.6 MB 2.6 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 137.8/198.6 MB 2.5 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 138.0/198.6 MB 2.5 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 138.2/198.6 MB 2.5 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 138.3/198.6 MB 2.5 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 138.5/198.6 MB 2.5 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 138.6/198.6 MB 2.5 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 138.7/198.6 MB 2.5 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 138.9/198.6 MB 2.5 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 139.0/198.6 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 139.1/198.6 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 139.3/198.6 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 139.4/198.6 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 139.5/198.6 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 139.6/198.6 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 139.7/198.6 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 139.8/198.6 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 140.0/198.6 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 140.1/198.6 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 140.3/198.6 MB 2.6 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 140.4/198.6 MB 2.6 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 140.6/198.6 MB 2.6 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 140.6/198.6 MB 2.5 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 140.7/198.6 MB 2.5 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 140.8/198.6 MB 2.5 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 140.8/198.6 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 140.9/198.6 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 140.9/198.6 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 141.1/198.6 MB 2.4 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 141.1/198.6 MB 2.4 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 141.2/198.6 MB 2.4 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 141.3/198.6 MB 2.4 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 141.5/198.6 MB 2.4 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 141.6/198.6 MB 2.4 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 141.8/198.6 MB 2.4 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 141.9/198.6 MB 2.4 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 142.1/198.6 MB 2.4 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 142.1/198.6 MB 2.4 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 142.1/198.6 MB 2.4 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 142.1/198.6 MB 2.4 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 142.1/198.6 MB 2.3 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 142.2/198.6 MB 2.3 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 142.3/198.6 MB 2.3 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 142.5/198.6 MB 2.3 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 142.6/198.6 MB 2.3 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 142.8/198.6 MB 2.3 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 142.9/198.6 MB 2.3 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 143.0/198.6 MB 2.3 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 143.2/198.6 MB 2.3 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 143.2/198.6 MB 2.3 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 143.4/198.6 MB 2.3 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 143.5/198.6 MB 2.3 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 143.6/198.6 MB 2.3 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 143.7/198.6 MB 2.3 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 143.7/198.6 MB 2.2 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 143.8/198.6 MB 2.3 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 143.9/198.6 MB 2.3 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 144.0/198.6 MB 2.2 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 144.1/198.6 MB 2.3 MB/s eta 0:00:24\n",
      "   ----------------------------- ---------- 144.2/198.6 MB 2.3 MB/s eta 0:00:24\n",
      "   ----------------------------- ---------- 144.4/198.6 MB 2.3 MB/s eta 0:00:24\n",
      "   ----------------------------- ---------- 144.5/198.6 MB 2.3 MB/s eta 0:00:24\n",
      "   ----------------------------- ---------- 144.5/198.6 MB 2.3 MB/s eta 0:00:24\n",
      "   ----------------------------- ---------- 144.7/198.6 MB 2.3 MB/s eta 0:00:24\n",
      "   ----------------------------- ---------- 144.8/198.6 MB 2.3 MB/s eta 0:00:24\n",
      "   ----------------------------- ---------- 145.0/198.6 MB 2.3 MB/s eta 0:00:24\n",
      "   ----------------------------- ---------- 145.1/198.6 MB 2.3 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 145.3/198.6 MB 2.4 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 145.3/198.6 MB 2.4 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 145.4/198.6 MB 2.3 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 145.5/198.6 MB 2.3 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 145.6/198.6 MB 2.3 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 145.7/198.6 MB 2.3 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 145.8/198.6 MB 2.3 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 146.0/198.6 MB 2.4 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 146.2/198.6 MB 2.4 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 146.4/198.6 MB 2.4 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 146.5/198.6 MB 2.4 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 146.7/198.6 MB 2.4 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 146.9/198.6 MB 2.5 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 147.0/198.6 MB 2.5 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 147.1/198.6 MB 2.5 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 147.3/198.6 MB 2.5 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 147.3/198.6 MB 2.5 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 147.5/198.6 MB 2.5 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 147.6/198.6 MB 2.5 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 147.8/198.6 MB 2.5 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 147.9/198.6 MB 2.5 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 148.1/198.6 MB 2.5 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 148.2/198.6 MB 2.5 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 148.3/198.6 MB 2.5 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 148.4/198.6 MB 2.5 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 148.6/198.6 MB 2.5 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 148.7/198.6 MB 2.5 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 148.8/198.6 MB 2.5 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 149.0/198.6 MB 2.5 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 149.0/198.6 MB 2.5 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 149.1/198.6 MB 2.5 MB/s eta 0:00:21\n",
      "   ------------------------------ --------- 149.2/198.6 MB 2.5 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 149.3/198.6 MB 2.5 MB/s eta 0:00:21\n",
      "   ------------------------------ --------- 149.5/198.6 MB 2.5 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 149.5/198.6 MB 2.4 MB/s eta 0:00:21\n",
      "   ------------------------------ --------- 149.7/198.6 MB 2.4 MB/s eta 0:00:21\n",
      "   ------------------------------ --------- 149.8/198.6 MB 2.5 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 150.0/198.6 MB 2.5 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 150.1/198.6 MB 2.5 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 150.3/198.6 MB 2.5 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 150.4/198.6 MB 2.5 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 150.5/198.6 MB 2.5 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 150.6/198.6 MB 2.5 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 150.7/198.6 MB 2.4 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 150.9/198.6 MB 2.5 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 151.1/198.6 MB 2.5 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 151.2/198.6 MB 2.6 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 151.4/198.6 MB 2.6 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 151.6/198.6 MB 2.6 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 151.6/198.6 MB 2.6 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 151.7/198.6 MB 2.6 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 151.9/198.6 MB 2.6 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 151.9/198.6 MB 2.6 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 152.1/198.6 MB 2.6 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 152.2/198.6 MB 2.6 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 152.3/198.6 MB 2.6 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 152.5/198.6 MB 2.7 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 152.5/198.6 MB 2.7 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 152.7/198.6 MB 2.7 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 152.8/198.6 MB 2.7 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 152.8/198.6 MB 2.7 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 152.9/198.6 MB 2.6 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 153.1/198.6 MB 2.7 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 153.1/198.6 MB 2.6 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 153.3/198.6 MB 2.6 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 153.5/198.6 MB 2.6 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 153.6/198.6 MB 2.6 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 153.7/198.6 MB 2.6 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 153.9/198.6 MB 2.7 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 154.0/198.6 MB 2.7 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 154.1/198.6 MB 2.7 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 154.2/198.6 MB 2.7 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 154.3/198.6 MB 2.7 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 154.4/198.6 MB 2.7 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 154.5/198.6 MB 2.7 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 154.6/198.6 MB 2.7 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 154.8/198.6 MB 2.7 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 154.9/198.6 MB 2.7 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 155.3/198.6 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 155.4/198.6 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 155.5/198.6 MB 2.8 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 155.6/198.6 MB 2.8 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 155.8/198.6 MB 2.8 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 155.8/198.6 MB 2.8 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 155.9/198.6 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 156.1/198.6 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 156.1/198.6 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 156.3/198.6 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 156.4/198.6 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 156.6/198.6 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 156.8/198.6 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 157.0/198.6 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 157.0/198.6 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 157.1/198.6 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 157.3/198.6 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 157.5/198.6 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 157.6/198.6 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 157.8/198.6 MB 2.7 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 157.9/198.6 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 158.0/198.6 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 158.2/198.6 MB 2.7 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 158.3/198.6 MB 2.7 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 158.5/198.6 MB 2.7 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 158.7/198.6 MB 2.8 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 158.9/198.6 MB 2.8 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 159.1/198.6 MB 2.8 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 159.2/198.6 MB 2.8 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 159.5/198.6 MB 2.9 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 159.6/198.6 MB 2.9 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 159.7/198.6 MB 2.9 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 159.8/198.6 MB 2.9 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 159.9/198.6 MB 2.8 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 160.0/198.6 MB 2.8 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 160.2/198.6 MB 2.8 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 160.4/198.6 MB 2.8 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 160.9/198.6 MB 2.9 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 161.1/198.6 MB 2.9 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 161.3/198.6 MB 2.9 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 161.4/198.6 MB 2.9 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 161.4/198.6 MB 2.9 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 161.6/198.6 MB 2.9 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 161.6/198.6 MB 2.9 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 161.7/198.6 MB 2.8 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 162.0/198.6 MB 2.8 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 162.1/198.6 MB 2.9 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 162.2/198.6 MB 2.8 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 162.4/198.6 MB 2.8 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 162.5/198.6 MB 2.8 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 162.8/198.6 MB 2.9 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 162.9/198.6 MB 2.9 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 163.2/198.6 MB 3.0 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 163.5/198.6 MB 3.0 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 163.5/198.6 MB 3.0 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 163.5/198.6 MB 3.0 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 163.7/198.6 MB 2.9 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 164.0/198.6 MB 3.0 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 164.2/198.6 MB 3.0 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 164.4/198.6 MB 3.0 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 164.6/198.6 MB 3.1 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 164.6/198.6 MB 3.0 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 164.8/198.6 MB 3.1 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 165.0/198.6 MB 3.1 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 165.2/198.6 MB 3.1 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 165.3/198.6 MB 3.1 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 165.5/198.6 MB 3.1 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 165.5/198.6 MB 3.1 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 165.6/198.6 MB 3.1 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 165.8/198.6 MB 3.1 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 165.9/198.6 MB 3.1 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 166.1/198.6 MB 3.1 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 166.3/198.6 MB 3.1 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 166.5/198.6 MB 3.2 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 166.6/198.6 MB 3.2 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 166.9/198.6 MB 3.2 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 167.0/198.6 MB 3.2 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 167.2/198.6 MB 3.2 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 167.2/198.6 MB 3.2 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 167.2/198.6 MB 3.1 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 167.4/198.6 MB 3.1 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 167.5/198.6 MB 3.1 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 167.6/198.6 MB 3.1 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 167.7/198.6 MB 3.1 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 167.8/198.6 MB 3.1 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 168.0/198.6 MB 3.1 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 168.4/198.6 MB 3.1 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 168.5/198.6 MB 3.1 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 168.7/198.6 MB 3.1 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 168.8/198.6 MB 3.1 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 169.0/198.6 MB 3.1 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 169.2/198.6 MB 3.1 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 169.4/198.6 MB 3.1 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 169.4/198.6 MB 3.1 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 169.7/198.6 MB 3.1 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 169.7/198.6 MB 3.1 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 169.7/198.6 MB 3.0 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 169.9/198.6 MB 3.0 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 170.0/198.6 MB 3.0 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 170.1/198.6 MB 3.1 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 170.2/198.6 MB 3.1 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 170.4/198.6 MB 3.1 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 170.7/198.6 MB 3.1 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 170.8/198.6 MB 3.1 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 171.0/198.6 MB 3.1 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 171.3/198.6 MB 3.1 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 171.3/198.6 MB 3.1 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 171.5/198.6 MB 3.1 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 171.7/198.6 MB 3.1 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 171.8/198.6 MB 3.1 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 172.0/198.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 172.2/198.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 172.4/198.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 172.6/198.6 MB 3.3 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 172.8/198.6 MB 3.3 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 173.1/198.6 MB 3.3 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 173.1/198.6 MB 3.3 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 173.2/198.6 MB 3.2 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 173.5/198.6 MB 3.2 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 173.7/198.6 MB 3.2 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 173.8/198.6 MB 3.2 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 174.0/198.6 MB 3.3 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 174.0/198.6 MB 3.3 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 174.0/198.6 MB 3.3 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 174.0/198.6 MB 3.3 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 174.7/198.6 MB 3.3 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 174.7/198.6 MB 3.3 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 174.9/198.6 MB 3.3 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 175.0/198.6 MB 3.3 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 175.2/198.6 MB 3.3 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 175.3/198.6 MB 3.3 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 175.5/198.6 MB 3.2 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 175.6/198.6 MB 3.2 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 175.7/198.6 MB 3.3 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 175.9/198.6 MB 3.3 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 175.9/198.6 MB 3.3 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 176.1/198.6 MB 3.3 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 176.1/198.6 MB 3.3 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 176.1/198.6 MB 3.3 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 176.5/198.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 176.7/198.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 176.8/198.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 177.0/198.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 177.1/198.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 177.3/198.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 177.4/198.6 MB 3.3 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 177.5/198.6 MB 3.3 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 177.7/198.6 MB 3.3 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 177.8/198.6 MB 3.3 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 177.9/198.6 MB 3.3 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 178.0/198.6 MB 3.3 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 178.1/198.6 MB 3.3 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 178.2/198.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 178.4/198.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 178.5/198.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 178.6/198.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 178.7/198.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 178.9/198.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 179.0/198.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 179.1/198.6 MB 3.1 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 179.3/198.6 MB 3.1 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 179.5/198.6 MB 3.1 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 179.6/198.6 MB 3.1 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 179.6/198.6 MB 3.1 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 179.7/198.6 MB 3.1 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 179.9/198.6 MB 3.1 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 179.9/198.6 MB 3.1 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 180.1/198.6 MB 3.1 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 180.2/198.6 MB 3.1 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 180.4/198.6 MB 3.2 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 180.5/198.6 MB 3.2 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 180.6/198.6 MB 3.1 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 180.8/198.6 MB 3.1 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 180.9/198.6 MB 3.1 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 181.1/198.6 MB 3.1 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 181.2/198.6 MB 3.1 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 181.3/198.6 MB 3.1 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 181.4/198.6 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 181.5/198.6 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 181.7/198.6 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 181.8/198.6 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 182.0/198.6 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 182.1/198.6 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 182.3/198.6 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 182.4/198.6 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 182.6/198.6 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 182.7/198.6 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 182.9/198.6 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 183.0/198.6 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 183.2/198.6 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 183.3/198.6 MB 2.9 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 183.3/198.6 MB 2.9 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 183.4/198.6 MB 2.9 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 183.5/198.6 MB 2.9 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 183.5/198.6 MB 2.9 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 183.5/198.6 MB 2.9 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 183.5/198.6 MB 2.9 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 183.5/198.6 MB 2.9 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 183.7/198.6 MB 2.7 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 183.8/198.6 MB 2.7 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 183.9/198.6 MB 2.7 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 184.1/198.6 MB 2.7 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 184.1/198.6 MB 2.7 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 184.1/198.6 MB 2.7 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 184.1/198.6 MB 2.7 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 184.2/198.6 MB 2.6 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 184.2/198.6 MB 2.6 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 184.2/198.6 MB 2.6 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 184.5/198.6 MB 2.6 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 184.6/198.6 MB 2.6 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 184.8/198.6 MB 2.6 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 184.9/198.6 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 185.0/198.6 MB 2.6 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 185.1/198.6 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 185.2/198.6 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 185.3/198.6 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 185.4/198.6 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 185.5/198.6 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 185.6/198.6 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 185.7/198.6 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 185.8/198.6 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 185.9/198.6 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 186.1/198.6 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 186.2/198.6 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 186.3/198.6 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 186.5/198.6 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 186.6/198.6 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 186.6/198.6 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 186.7/198.6 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 186.8/198.6 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 187.0/198.6 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 187.0/198.6 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 187.2/198.6 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 187.3/198.6 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 187.4/198.6 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 187.5/198.6 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 187.7/198.6 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 187.8/198.6 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 188.0/198.6 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 188.1/198.6 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 188.3/198.6 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 188.4/198.6 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 188.6/198.6 MB 2.5 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 188.7/198.6 MB 2.5 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 188.9/198.6 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 188.9/198.6 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 189.1/198.6 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 189.1/198.6 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 189.3/198.6 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 189.3/198.6 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 189.5/198.6 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 189.5/198.6 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 189.5/198.6 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 189.5/198.6 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 189.6/198.6 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 189.7/198.6 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 189.8/198.6 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 189.9/198.6 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 190.0/198.6 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 190.0/198.6 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 190.0/198.6 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 190.1/198.6 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 190.2/198.6 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 190.3/198.6 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 190.4/198.6 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 190.5/198.6 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 190.6/198.6 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 190.7/198.6 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 190.8/198.6 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 191.0/198.6 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 191.0/198.6 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 191.0/198.6 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 191.0/198.6 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 191.1/198.6 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 191.1/198.6 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 191.1/198.6 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 191.4/198.6 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 191.5/198.6 MB 2.1 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 191.6/198.6 MB 2.1 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 191.7/198.6 MB 2.1 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 191.8/198.6 MB 2.1 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 191.8/198.6 MB 2.1 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 191.9/198.6 MB 2.1 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 192.1/198.6 MB 2.1 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 192.2/198.6 MB 2.1 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 192.2/198.6 MB 2.1 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 192.4/198.6 MB 2.1 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 192.5/198.6 MB 2.1 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 192.5/198.6 MB 2.1 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 192.6/198.6 MB 2.1 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 192.7/198.6 MB 2.1 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 192.7/198.6 MB 2.1 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 192.8/198.6 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 192.8/198.6 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 193.0/198.6 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 193.1/198.6 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 193.2/198.6 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 193.3/198.6 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 193.4/198.6 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 193.4/198.6 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 193.5/198.6 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 193.6/198.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------------------------------------  193.7/198.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------------------------------------  193.8/198.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------------------------------------  193.9/198.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------------------------------------  194.0/198.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------------------------------------  194.1/198.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------------------------------------  194.2/198.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------------------------------------  194.3/198.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------------------------------------  194.4/198.6 MB 2.1 MB/s eta 0:00:03\n",
      "   ---------------------------------------  194.5/198.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------------------------  194.6/198.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------------------------  194.7/198.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------------------------  194.7/198.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------------------------  194.8/198.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------------------------  194.9/198.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------------------------  195.1/198.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------------------------  195.2/198.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  195.4/198.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  195.4/198.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  195.4/198.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  195.6/198.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  195.6/198.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  195.7/198.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  195.7/198.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  195.7/198.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  195.7/198.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  195.9/198.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  196.0/198.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  196.1/198.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  196.2/198.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  196.3/198.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  196.3/198.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  196.4/198.6 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  196.4/198.6 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  196.5/198.6 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  196.6/198.6 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  196.6/198.6 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  196.7/198.6 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  196.8/198.6 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  196.9/198.6 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  197.0/198.6 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  197.1/198.6 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  197.2/198.6 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  197.3/198.6 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  197.4/198.6 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  197.5/198.6 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  197.6/198.6 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  197.7/198.6 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  197.8/198.6 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  197.9/198.6 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.0/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.0/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.0/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.1/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.2/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.3/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.3/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.4/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.5/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/198.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 198.6/198.6 MB 1.4 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "   ---------------------------------------- 0.0/170.9 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 71.7/170.9 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 122.9/170.9 kB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 163.8/170.9 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 170.9/170.9 kB 1.0 MB/s eta 0:00:00\n",
      "Installing collected packages: typing-extensions, fsspec, torch\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "Successfully installed fsspec-2024.2.0 torch-2.2.1 typing-extensions-4.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8b9f037",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [[1,2,3], [4,5,6]]\n",
    "tensor = torch.tensor(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b419bbd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "230c4a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array([[1,2,3], [4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4407622f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]], dtype=torch.int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_tensor = torch.from_numpy(np_array)\n",
    "np_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82d3d236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e14d94b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb7a6751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displays which device the tensor is loaded on, such as a CPU or GPU\n",
    "tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7edb815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  4,  6],\n",
       "        [ 8, 10, 12]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor+np_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ac44547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  4,  9],\n",
       "        [16, 25, 36]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor*np_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce41574c",
   "metadata": {},
   "source": [
    "# First neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67295bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f5607c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4950, -0.2503], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creat tensor\n",
    "input_tensor = torch.tensor([0.3471, 0.4547, -0.2356])\n",
    "\n",
    "# creat first linear layer\n",
    "linear_layer = nn.Linear(in_features = 3, out_features =2)\n",
    "\n",
    "# pass input through linear layer\n",
    "output = linear_layer(input_tensor)\n",
    "output\n",
    "\n",
    "# networks with only linear layers are called \"fully connected networks\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85da6a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.4593, -0.0739, -0.4664],\n",
       "        [ 0.0051, -0.5005,  0.1787]], requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1dba27d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.1629,  0.4813], requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f75e183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights and biases are initialized randomly, \n",
    "# later these weights and biases are tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af349380",
   "metadata": {},
   "source": [
    "# Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5fe4e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(10,18),\n",
    "    nn.Linear(18,20),\n",
    "    nn.Linear(20,5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a33a3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7042, 0.1507, 0.2062, 0.5406, 0.9572, 0.5336, 0.0259, 0.4324, 0.3293,\n",
       "        0.0463])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr =np.random.random(10)\n",
    "r = arr.astype('float32')\n",
    "input_tensor2 = torch.from_numpy(r)\n",
    "input_tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b6f07da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1005, -0.0660, -0.1944,  0.2997,  0.2181], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2 = model(input_tensor2)\n",
    "output2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae83c853",
   "metadata": {},
   "source": [
    "# Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4e1abb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9975]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor4 = torch.tensor([[6.0]])\n",
    "sigmoid = nn.Sigmoid()\n",
    "output = sigmoid(input_tensor4)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e23be22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last step in a neural network when performing binary classification\n",
    "# sigmoid as the last step in a network of only linear layers is equivalent to a logistic regression \n",
    "model = nn.Sequential(\n",
    "    nn.Linear(6,4),\n",
    "    nn.Linear(4,1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3354b27f",
   "metadata": {},
   "source": [
    "# Softmax - multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0d6a32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1392, 0.8420, 0.0188]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor5 = torch.tensor([[4.3, 6.1, 2.3]])\n",
    "# used to the last dimensio = -1\n",
    "probabilities = nn.Softmax(dim=-1)\n",
    "output = probabilities(input_tensor5)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a261bdb4",
   "metadata": {},
   "source": [
    "# Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac039d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6611, 0.4581, 0.7533, 0.7126, 0.1199, 0.9594],\n",
       "        [0.1514, 0.8072, 0.9929, 0.0569, 0.2109, 0.7071],\n",
       "        [0.7837, 0.7540, 0.5261, 0.0243, 0.7320, 0.5334],\n",
       "        [0.3689, 0.7743, 0.9581, 0.8208, 0.4180, 0.0111],\n",
       "        [0.4173, 0.4929, 0.6583, 0.4849, 0.2056, 0.6849]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr =np.random.random(30)\n",
    "arr = arr.reshape(5,6)\n",
    "r = arr.astype('float32')\n",
    "input_tensor6 = torch.from_numpy(r)\n",
    "input_tensor6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8520cb",
   "metadata": {},
   "source": [
    "### Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "020d1655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3473],\n",
       "        [0.3450],\n",
       "        [0.3050],\n",
       "        [0.3790],\n",
       "        [0.3638]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(6,4), # first argumment is equal the number of feauter in one row\n",
    "    nn.Linear(4,1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "output = model(input_tensor6)\n",
    "output\n",
    "# The output of our binary classification is a single probability between zero and one for each of our five samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78348712",
   "metadata": {},
   "source": [
    "###  Multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a8dcddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are predicting three classes: mammal, bird or reptile\n",
    "n_classes = 3\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(6,4), # first argumment is equal the number of feauter in one row\n",
    "    nn.Linear(4,n_classes),\n",
    "    nn.Softmax(dim = -1) # dim equals minus one to indicate the five samples have the same \n",
    "                         # last dimension as the last linear layer's output\n",
    ")\n",
    "output = model(input_tensor6)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3422753d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3957, 0.2238, 0.3804],\n",
       "        [0.3707, 0.2751, 0.3542],\n",
       "        [0.3623, 0.2467, 0.3910],\n",
       "        [0.3973, 0.2253, 0.3774],\n",
       "        [0.3811, 0.2501, 0.3688]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816476f6",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b13f7bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8555],\n",
       "        [-0.8856],\n",
       "        [-0.8127],\n",
       "        [-0.7990],\n",
       "        [-0.8147]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(6,4), \n",
    "    nn.Linear(4,1)\n",
    ")\n",
    "output = model(input_tensor6)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1fe1ea",
   "metadata": {},
   "source": [
    "# Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b10f56",
   "metadata": {},
   "source": [
    "### one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "46d61f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_array = np.array([1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39fadfa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "F.one_hot(torch.tensor(0), num_classes = 3) # the correct class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b31246d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(1), num_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e6db5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(2), num_classes = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7201b165",
   "metadata": {},
   "source": [
    "### Cross entropy loss in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c4bba48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8136, dtype=torch.float64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the most used loss function for classification problems\n",
    "from torch.nn import CrossEntropyLoss\n",
    "score = torch.tensor([[-0.1221, 0.1059]])\n",
    "ohe = torch.tensor([[1, 0]])\n",
    "criterion = CrossEntropyLoss()\n",
    "criterion(score.double(), ohe.double())\n",
    "# this casts the tensors to a specific float data type that is accepted by the CrossEntropyLoss() function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efa1322",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d254dbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1646, 0.0916, 0.8040, 0.8046, 0.8735, 0.8920],\n",
       "        [0.1848, 0.4480, 0.5242, 0.7147, 0.1553, 0.1821],\n",
       "        [0.8431, 0.7805, 0.7956, 0.2143, 0.4482, 0.1153],\n",
       "        [0.1009, 0.2607, 0.9396, 0.9960, 0.4097, 0.8597],\n",
       "        [0.4722, 0.1675, 0.2877, 0.9116, 0.6867, 0.2121]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr =np.random.random(30)\n",
    "arr = arr.reshape(5,6)\n",
    "r = arr.astype('float32')\n",
    "input_tensor6 = torch.from_numpy(r)\n",
    "input_tensor6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "59227ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3116],\n",
       "        [0.5787],\n",
       "        [0.1133],\n",
       "        [0.7600],\n",
       "        [0.1388]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr =np.random.random(5)\n",
    "arr = arr.reshape(5,1)\n",
    "arr = arr.astype('float32')\n",
    "one_hot = torch.from_numpy(arr)\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e58d96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0286],\n",
       "        [-0.0004],\n",
       "        [ 0.0612],\n",
       "        [-0.0442],\n",
       "        [ 0.0433]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(6,4), \n",
    "    nn.Linear(4,8),\n",
    "    nn.Linear(8,1)\n",
    ")\n",
    "prediction = model(input_tensor6)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6407e4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0., dtype=torch.float64, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = CrossEntropyLoss()\n",
    "loss = criterion(prediction.double(), one_hot.double())\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0bb3a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e92285b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight.grad, model[0].bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dd6e351f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1].weight.grad, model[1].bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "05c154d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[2].weight.grad, model[2].bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40c8641",
   "metadata": {},
   "source": [
    "# Updating model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134b265e",
   "metadata": {},
   "source": [
    "### manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a48aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "lr = 0.001\n",
    "\n",
    "weight = model[0].weight\n",
    "weight_grad = model[0].weight.grad\n",
    "weight = weight - lr*weight_grad\n",
    "\n",
    "bias = model[0].bias\n",
    "bias_grad = model[0].bias.grad\n",
    "bias = bias - lr*wbias_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98021d1",
   "metadata": {},
   "source": [
    "# Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eac7fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stochastic gradient descent (SGD)\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7d8f93",
   "metadata": {},
   "source": [
    "# Mean Square Error Loss - for linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5de68b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_loss(prediction,target):\n",
    "    return np.mean((prediction - target)**2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab90cad4",
   "metadata": {},
   "source": [
    "criterion = nn.MSELoss()\n",
    "loss = criterion(prediction,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bfde9d",
   "metadata": {},
   "source": [
    "# All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49246b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(torch.tensor(features).float(), torch.tensor(target).float())\n",
    "dataloader = DataLoader(dataset, batch_size = 4, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b3f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(4,2), \n",
    "    nn.Linear(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730fcef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e56d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the number of epochs and the dataloader\n",
    "for i in range(num_epochs):\n",
    "  for data in dataloader:\n",
    "    # Set the gradients to zero\n",
    "    optimizer.zero_grad()\n",
    "    # Run a forward pass\n",
    "    feature, target = data\n",
    "    prediction = model(feature)    \n",
    "    # Calculate the loss\n",
    "    loss = criterion(prediction, target)    \n",
    "    # Compute the gradients\n",
    "    loss.backward()\n",
    "    # Update the model's parameters\n",
    "    optimizer.step()\n",
    "show_results(model, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66882395",
   "metadata": {},
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "13e2405c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.587349</td>\n",
       "      <td>0.577747</td>\n",
       "      <td>0.386298</td>\n",
       "      <td>0.568199</td>\n",
       "      <td>0.647347</td>\n",
       "      <td>0.292985</td>\n",
       "      <td>0.654522</td>\n",
       "      <td>0.795029</td>\n",
       "      <td>0.630115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643654</td>\n",
       "      <td>0.441300</td>\n",
       "      <td>0.314381</td>\n",
       "      <td>0.439304</td>\n",
       "      <td>0.514545</td>\n",
       "      <td>0.356685</td>\n",
       "      <td>0.377248</td>\n",
       "      <td>0.202914</td>\n",
       "      <td>0.520358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.388934</td>\n",
       "      <td>0.470876</td>\n",
       "      <td>0.506122</td>\n",
       "      <td>0.524364</td>\n",
       "      <td>0.561537</td>\n",
       "      <td>0.142913</td>\n",
       "      <td>0.249922</td>\n",
       "      <td>0.401487</td>\n",
       "      <td>0.219973</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.725820</td>\n",
       "      <td>0.715942</td>\n",
       "      <td>0.506141</td>\n",
       "      <td>0.521683</td>\n",
       "      <td>0.751819</td>\n",
       "      <td>0.148683</td>\n",
       "      <td>0.467200</td>\n",
       "      <td>0.658678</td>\n",
       "      <td>0.242428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.610517</td>\n",
       "      <td>0.532588</td>\n",
       "      <td>0.237701</td>\n",
       "      <td>0.270288</td>\n",
       "      <td>0.495155</td>\n",
       "      <td>0.494792</td>\n",
       "      <td>0.409721</td>\n",
       "      <td>0.469762</td>\n",
       "      <td>0.585049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>0.636224</td>\n",
       "      <td>0.580511</td>\n",
       "      <td>0.277748</td>\n",
       "      <td>0.418063</td>\n",
       "      <td>0.522486</td>\n",
       "      <td>0.342184</td>\n",
       "      <td>0.310364</td>\n",
       "      <td>0.402799</td>\n",
       "      <td>0.627156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>0.470143</td>\n",
       "      <td>0.548826</td>\n",
       "      <td>0.301347</td>\n",
       "      <td>0.538273</td>\n",
       "      <td>0.498565</td>\n",
       "      <td>0.231359</td>\n",
       "      <td>0.565061</td>\n",
       "      <td>0.175889</td>\n",
       "      <td>0.395061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>0.817826</td>\n",
       "      <td>0.087434</td>\n",
       "      <td>0.656389</td>\n",
       "      <td>0.670774</td>\n",
       "      <td>0.369089</td>\n",
       "      <td>0.431872</td>\n",
       "      <td>0.563265</td>\n",
       "      <td>0.285745</td>\n",
       "      <td>0.578674</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0.424187</td>\n",
       "      <td>0.464092</td>\n",
       "      <td>0.459656</td>\n",
       "      <td>0.541633</td>\n",
       "      <td>0.615572</td>\n",
       "      <td>0.388360</td>\n",
       "      <td>0.397780</td>\n",
       "      <td>0.449156</td>\n",
       "      <td>0.440004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>0.322425</td>\n",
       "      <td>0.492891</td>\n",
       "      <td>0.841409</td>\n",
       "      <td>0.492136</td>\n",
       "      <td>0.656047</td>\n",
       "      <td>0.588709</td>\n",
       "      <td>0.471422</td>\n",
       "      <td>0.503458</td>\n",
       "      <td>0.591867</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2011 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ph  Hardness    Solids  Chloramines   Sulfate  Conductivity  \\\n",
       "0     0.587349  0.577747  0.386298     0.568199  0.647347      0.292985   \n",
       "1     0.643654  0.441300  0.314381     0.439304  0.514545      0.356685   \n",
       "2     0.388934  0.470876  0.506122     0.524364  0.561537      0.142913   \n",
       "3     0.725820  0.715942  0.506141     0.521683  0.751819      0.148683   \n",
       "4     0.610517  0.532588  0.237701     0.270288  0.495155      0.494792   \n",
       "...        ...       ...       ...          ...       ...           ...   \n",
       "2006  0.636224  0.580511  0.277748     0.418063  0.522486      0.342184   \n",
       "2007  0.470143  0.548826  0.301347     0.538273  0.498565      0.231359   \n",
       "2008  0.817826  0.087434  0.656389     0.670774  0.369089      0.431872   \n",
       "2009  0.424187  0.464092  0.459656     0.541633  0.615572      0.388360   \n",
       "2010  0.322425  0.492891  0.841409     0.492136  0.656047      0.588709   \n",
       "\n",
       "      Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0           0.654522         0.795029   0.630115           0  \n",
       "1           0.377248         0.202914   0.520358           0  \n",
       "2           0.249922         0.401487   0.219973           0  \n",
       "3           0.467200         0.658678   0.242428           0  \n",
       "4           0.409721         0.469762   0.585049           0  \n",
       "...              ...              ...        ...         ...  \n",
       "2006        0.310364         0.402799   0.627156           1  \n",
       "2007        0.565061         0.175889   0.395061           1  \n",
       "2008        0.563265         0.285745   0.578674           1  \n",
       "2009        0.397780         0.449156   0.440004           1  \n",
       "2010        0.471422         0.503458   0.591867           1  \n",
       "\n",
       "[2011 rows x 10 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "water = pd.read_csv('water_potability.csv')\n",
    "water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4e52ec76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water['Potability'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3785dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = water.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbd3d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features2 = torch.tensor(water[['ph', 'Sulfate', 'Conductivity', 'Organic_carbon']].to_numpy()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3acfd417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58734916, 0.57774671, 0.38629788, ..., 0.65452157, 0.79502934,\n",
       "        0.63011476],\n",
       "       [0.64365393, 0.44130035, 0.31438058, ..., 0.37724796, 0.20291434,\n",
       "        0.52035803],\n",
       "       [0.38893354, 0.47087564, 0.50612238, ..., 0.24992171, 0.40148717,\n",
       "        0.21997295],\n",
       "       ...,\n",
       "       [0.81782618, 0.08743355, 0.65638906, ..., 0.56326524, 0.28574454,\n",
       "        0.5786739 ],\n",
       "       [0.42418706, 0.4640915 , 0.45965606, ..., 0.39778031, 0.44915584,\n",
       "        0.44000443],\n",
       "       [0.32242529, 0.49289123, 0.84140928, ..., 0.47142165, 0.50345848,\n",
       "        0.59186714]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = features.to_numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c6d31cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = water.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5ceca4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = target.to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3cf8d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "dataset = TensorDataset(torch.tensor(X).float(), torch.tensor(y).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7c6868b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.5873, 0.5777, 0.3863, 0.5682, 0.6473, 0.2930, 0.6545, 0.7950, 0.6301]),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dataset[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ed5b6918",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sample, label_sample = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1bbeb8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_sample:  tensor([0.5873, 0.5777, 0.3863, 0.5682, 0.6473, 0.2930, 0.6545, 0.7950, 0.6301])\n",
      "label_sample:  tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print('input_sample: ', input_sample )\n",
    "print('label_sample: ', label_sample )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e054bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size = 4, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f0a1cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1d3a3648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4885, 0.3538, 0.3841, 0.2644, 0.5916, 0.5093, 0.3412, 0.6081, 0.3409],\n",
      "        [0.3383, 0.8178, 0.2702, 0.4767, 0.3908, 0.6669, 0.6088, 0.6153, 0.3230],\n",
      "        [0.5358, 0.4525, 0.5166, 0.3675, 0.3708, 0.4085, 0.4760, 0.7192, 0.6174],\n",
      "        [0.5864, 0.3366, 0.3193, 0.8570, 0.5684, 0.3239, 0.4658, 0.2294, 0.5414]]) tensor([0., 0., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "print(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a400d236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_imputs:  tensor([[0.5458, 0.5327, 0.3753, 0.5310, 0.5801, 0.4037, 0.5946, 0.3452, 0.4286],\n",
      "        [0.4933, 0.6228, 0.4057, 0.3848, 0.5441, 0.4681, 0.4624, 0.5957, 0.4412],\n",
      "        [0.5064, 0.3044, 0.6585, 0.3652, 0.4266, 0.3523, 0.4485, 0.4769, 0.4823],\n",
      "        [0.4173, 0.5069, 0.3956, 0.3640, 0.5947, 0.3791, 0.3616, 0.4440, 0.4504]])\n",
      "batch_labels:  tensor([1., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4092, 0.4576, 0.7789, 0.2549, 0.8059, 0.2355, 0.5283, 0.4421, 0.8043],\n",
      "        [0.4644, 0.5019, 0.2418, 0.4237, 0.7339, 0.1980, 0.3853, 0.3797, 0.8245],\n",
      "        [0.4537, 0.4257, 0.2886, 0.7418, 0.5007, 0.4804, 0.1845, 0.4901, 0.5662],\n",
      "        [0.3859, 0.4600, 0.3529, 0.7537, 0.2286, 0.5733, 0.6556, 0.3534, 0.4407]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.3399, 0.3599, 0.2349, 0.5807, 0.6088, 0.6047, 0.4900, 0.5447, 0.5444],\n",
      "        [0.4275, 0.6258, 0.4340, 0.4530, 0.4810, 0.4134, 0.4973, 0.5412, 0.4442],\n",
      "        [0.5285, 0.4705, 0.5626, 0.3684, 0.5830, 0.4255, 0.5249, 0.3014, 0.6530],\n",
      "        [0.4605, 0.5546, 0.5128, 0.4579, 0.5644, 0.1930, 0.4096, 0.4953, 0.5461]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4913, 0.5871, 0.4043, 0.7162, 0.7191, 0.3042, 0.6759, 0.4425, 0.5845],\n",
      "        [0.4439, 0.2726, 0.3158, 0.5939, 0.8198, 0.2643, 0.4480, 0.4301, 0.5092],\n",
      "        [0.6166, 0.5999, 0.5405, 0.5008, 0.6020, 0.5079, 0.2802, 0.3604, 0.2850],\n",
      "        [0.5771, 0.5252, 0.3834, 0.3281, 0.5433, 0.4770, 0.5413, 0.4599, 0.5277]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4423, 0.4407, 0.6402, 0.7302, 0.4164, 0.1923, 0.6449, 0.7366, 0.2385],\n",
      "        [0.4131, 0.4611, 0.4924, 0.4587, 0.5699, 0.4118, 0.7433, 0.5390, 0.3385],\n",
      "        [0.3875, 0.7493, 0.1945, 0.4960, 0.5691, 0.3044, 0.5418, 0.3688, 0.1657],\n",
      "        [0.4293, 0.3894, 0.4197, 0.6905, 0.5370, 0.5302, 0.6819, 0.4478, 0.4740]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4936, 0.3054, 0.3722, 0.5071, 0.7340, 0.3978, 0.4755, 0.3691, 0.6534],\n",
      "        [0.3928, 0.3512, 0.4800, 0.4710, 0.5679, 0.2106, 0.4600, 0.2405, 0.3087],\n",
      "        [0.5287, 0.4879, 0.2978, 0.6327, 0.6185, 0.1173, 0.5535, 0.6471, 0.5693],\n",
      "        [0.4710, 0.4610, 0.6096, 0.4400, 0.6576, 0.1855, 0.3236, 0.3607, 0.6412]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5758, 0.6678, 0.4916, 0.4101, 0.5577, 0.5618, 0.4507, 0.6247, 0.5985],\n",
      "        [0.4575, 0.4242, 0.3243, 0.3998, 0.5889, 0.5254, 0.4568, 0.7656, 0.5180],\n",
      "        [0.6956, 0.6010, 0.6020, 0.7125, 0.2979, 0.2998, 0.4555, 0.4711, 0.6009],\n",
      "        [0.4177, 0.4419, 0.2048, 0.1958, 0.6453, 0.6194, 0.2672, 0.4473, 0.5545]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5561, 0.5723, 0.6860, 0.8333, 0.4338, 0.2256, 0.3300, 0.4859, 0.6224],\n",
      "        [0.3379, 0.2604, 0.3344, 0.5005, 0.8258, 0.2835, 0.4515, 0.5836, 0.3172],\n",
      "        [0.3408, 0.3642, 0.2458, 0.4274, 0.6500, 0.2468, 0.7674, 0.4949, 0.3638],\n",
      "        [0.5301, 0.6227, 0.1390, 0.4188, 0.5120, 0.3221, 0.5951, 0.4825, 0.4350]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.3290, 0.5333, 0.4145, 0.5348, 0.5542, 0.1582, 0.6395, 0.6701, 0.5859],\n",
      "        [0.4302, 0.4004, 0.4390, 0.5816, 0.5534, 0.3706, 0.3500, 0.4950, 0.5854],\n",
      "        [0.3892, 0.6042, 0.1497, 0.5906, 0.4864, 0.3826, 0.1725, 0.6243, 0.3401],\n",
      "        [0.5918, 0.5127, 0.5012, 0.4334, 0.5411, 0.5406, 0.5317, 0.2308, 0.6095]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5612, 0.5151, 0.3579, 0.5778, 0.7132, 0.2384, 0.4974, 0.4650, 0.4519],\n",
      "        [0.5465, 0.6012, 0.3000, 0.5618, 0.6111, 0.3325, 0.5905, 0.3329, 0.6706],\n",
      "        [0.5940, 0.5631, 0.4868, 0.4468, 0.4621, 0.6416, 0.4090, 0.5067, 0.1829],\n",
      "        [0.5163, 0.4731, 0.5292, 0.5178, 0.5131, 0.4783, 0.3569, 0.3345, 0.4532]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5816, 0.4780, 0.3506, 0.5960, 0.6451, 0.3191, 0.6265, 0.2524, 0.6916],\n",
      "        [0.5756, 0.5283, 0.4504, 0.5335, 0.6767, 0.7182, 0.3871, 0.5528, 0.4453],\n",
      "        [0.5430, 0.4324, 0.3232, 0.5824, 0.5849, 0.5735, 0.3402, 0.4729, 0.4781],\n",
      "        [0.6109, 0.5252, 0.4656, 0.4751, 0.6343, 0.1964, 0.6234, 0.5206, 0.7559]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5085, 0.4268, 0.3123, 0.3772, 0.6096, 0.3010, 0.7140, 0.4395, 0.8270],\n",
      "        [0.4007, 0.4510, 0.6287, 0.3984, 0.5640, 0.2765, 0.4172, 0.5367, 0.4675],\n",
      "        [0.5775, 0.4289, 0.4505, 0.5269, 0.7469, 0.2753, 0.7074, 0.5694, 0.4748],\n",
      "        [0.6313, 0.5496, 0.2309, 0.6109, 0.6504, 0.4838, 0.5439, 0.8552, 0.5217]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.6172, 0.5287, 0.4487, 0.2079, 0.5622, 0.4719, 0.5810, 0.8300, 0.4721],\n",
      "        [0.4645, 0.5366, 0.3761, 0.3911, 0.5207, 0.3831, 0.3936, 0.4674, 0.2757],\n",
      "        [0.6028, 0.3453, 0.3184, 0.6421, 0.5129, 0.5384, 0.4067, 0.3765, 0.4611],\n",
      "        [0.5163, 0.6417, 0.2187, 0.3906, 0.6315, 0.3067, 0.6929, 0.6185, 0.5089]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4650, 0.6531, 0.1689, 0.5918, 0.4924, 0.4654, 0.4477, 0.4916, 0.3952],\n",
      "        [0.4598, 0.3224, 0.3971, 0.5428, 0.7344, 0.3484, 0.3188, 0.4047, 0.4390],\n",
      "        [0.4857, 0.5633, 0.5153, 0.3937, 0.3501, 0.3457, 0.4310, 0.5935, 0.6241],\n",
      "        [0.5004, 0.3413, 0.3278, 0.1887, 0.4356, 0.2648, 0.5535, 0.6145, 0.3956]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4731, 0.5566, 0.2700, 0.5165, 0.6308, 0.3756, 0.4725, 0.5339, 0.6967],\n",
      "        [0.5506, 0.4668, 0.3578, 0.4962, 0.5574, 0.2711, 0.5886, 0.5190, 0.5122],\n",
      "        [0.4311, 0.4739, 0.4805, 0.4628, 0.5424, 0.5821, 0.4556, 0.3909, 0.6708],\n",
      "        [0.3823, 0.4215, 0.4647, 0.5694, 0.6751, 0.5425, 0.2181, 0.4403, 0.3656]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4717, 0.6138, 0.7341, 0.5414, 0.4038, 0.4754, 0.4420, 0.4547, 0.2917],\n",
      "        [0.5033, 0.4032, 0.5098, 0.3771, 0.6486, 0.5961, 0.6416, 0.6109, 0.3578],\n",
      "        [0.4309, 0.5301, 0.2120, 0.8634, 0.5541, 0.2587, 0.5033, 0.3398, 0.5062],\n",
      "        [0.3312, 0.6619, 0.4959, 0.8060, 0.1660, 0.4409, 0.3864, 0.6969, 0.2868]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.3676, 0.4944, 0.3820, 0.4164, 0.6536, 0.2758, 0.4830, 0.2167, 0.6141],\n",
      "        [0.4767, 0.6899, 0.1562, 0.4299, 0.5952, 0.2891, 0.4959, 0.3193, 0.0927],\n",
      "        [0.5098, 0.4535, 0.5840, 0.4938, 0.5493, 0.2605, 0.5226, 0.5222, 0.5562],\n",
      "        [0.4741, 0.5706, 0.3880, 0.5915, 0.4154, 0.3370, 0.4827, 0.5869, 0.5421]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5796, 0.3839, 0.2423, 0.7696, 0.3252, 0.3434, 0.4655, 0.4547, 0.6990],\n",
      "        [0.5441, 0.5326, 0.6317, 0.5362, 0.5225, 0.4048, 0.6407, 0.7612, 0.5389],\n",
      "        [0.4612, 0.5074, 0.3086, 0.2655, 0.4582, 0.0957, 0.3083, 0.5646, 0.6196],\n",
      "        [0.4658, 0.4733, 0.5796, 0.4602, 0.5819, 0.2446, 0.5042, 0.5135, 0.6169]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4215, 0.5205, 0.5797, 0.4367, 0.6335, 0.2689, 0.4799, 0.3015, 0.3913],\n",
      "        [0.2957, 0.5939, 0.3083, 0.5229, 0.5762, 0.4034, 0.5162, 0.5326, 0.6217],\n",
      "        [0.3495, 0.4908, 0.3030, 0.5498, 0.5486, 0.4401, 0.6157, 0.5022, 0.6132],\n",
      "        [0.4465, 0.3967, 0.2806, 0.3445, 0.5762, 0.1997, 0.5444, 0.3936, 0.5618]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4004, 0.4488, 0.3734, 0.4631, 0.5043, 0.4234, 0.3606, 0.5201, 0.5594],\n",
      "        [0.3686, 0.6460, 0.1131, 0.4013, 0.7380, 0.4789, 0.4971, 0.5986, 0.5103],\n",
      "        [0.3459, 0.2794, 0.7866, 0.5854, 0.5866, 0.6037, 0.5301, 0.4706, 0.4909],\n",
      "        [0.6499, 0.3682, 0.3658, 0.5398, 0.5438, 0.4085, 0.3231, 0.4666, 0.3288]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4578, 0.3687, 0.1410, 0.4474, 0.7779, 0.7239, 0.6327, 0.4024, 0.6243],\n",
      "        [0.5312, 0.3614, 0.3346, 0.6052, 0.4572, 0.4326, 0.4489, 0.6209, 0.4322],\n",
      "        [0.4844, 0.6369, 0.8122, 0.6964, 0.7068, 0.3458, 0.4706, 0.5060, 0.4703],\n",
      "        [0.5023, 0.6775, 0.5067, 0.4621, 0.7300, 0.2364, 0.3585, 0.4987, 0.7399]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5186, 0.3369, 0.3376, 0.3446, 0.7697, 0.3438, 0.6429, 0.4776, 0.4701],\n",
      "        [0.4702, 0.4455, 0.4272, 0.4788, 0.6032, 0.5037, 0.7211, 0.3929, 0.5499],\n",
      "        [0.3941, 0.3005, 0.3374, 0.4261, 0.5326, 0.4863, 0.3939, 0.4629, 0.5850],\n",
      "        [0.4899, 0.4180, 0.6299, 0.3496, 0.4575, 0.3615, 0.3259, 0.5011, 0.7545]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5348, 0.5232, 0.3364, 0.5384, 0.6317, 0.4524, 0.0876, 0.5727, 0.4147],\n",
      "        [0.4319, 0.4913, 0.5796, 0.8100, 0.5923, 0.3866, 0.4353, 0.5310, 0.3749],\n",
      "        [0.1995, 0.3021, 0.3028, 0.0944, 0.7504, 0.3150, 0.4272, 0.5877, 0.2636],\n",
      "        [0.5458, 0.5554, 0.4865, 0.3606, 0.5790, 0.3542, 0.4147, 0.5597, 0.7069]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5495, 0.6799, 0.4901, 0.4333, 0.6453, 0.5120, 0.6648, 0.3600, 0.5554],\n",
      "        [0.6317, 0.6905, 0.4006, 0.6100, 0.6788, 0.3237, 0.3491, 0.5829, 0.6248],\n",
      "        [0.5361, 0.5550, 0.6092, 0.3587, 0.4908, 0.4878, 0.5430, 0.2321, 0.6427],\n",
      "        [0.6704, 0.6127, 0.2516, 0.4601, 0.4680, 0.4196, 0.2769, 0.5140, 0.3713]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4644, 0.5312, 0.2999, 0.3970, 0.5191, 0.3781, 0.5529, 0.4890, 0.2904],\n",
      "        [0.4422, 0.2863, 0.3963, 0.3663, 0.5962, 0.6746, 0.5287, 0.3500, 0.3864],\n",
      "        [0.5923, 0.3830, 0.5276, 0.7147, 0.5067, 0.6251, 0.6115, 0.2535, 0.4426],\n",
      "        [0.5111, 0.4239, 0.2588, 0.5854, 0.5629, 0.4412, 0.7145, 0.6800, 0.3781]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4987, 0.5054, 0.5326, 0.3914, 0.5091, 0.4574, 0.5588, 0.1991, 0.6762],\n",
      "        [0.4686, 0.6767, 0.4595, 0.4187, 0.5120, 0.2255, 0.2394, 0.3250, 0.2987],\n",
      "        [0.5646, 0.4633, 0.2615, 0.5374, 0.6441, 0.6525, 0.3206, 0.5062, 0.3345],\n",
      "        [0.7462, 0.2882, 0.5519, 0.5400, 0.7782, 0.5249, 0.3952, 0.5810, 0.6405]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.7068, 0.8333, 0.3280, 0.6620, 0.6597, 0.4639, 0.7806, 0.7378, 0.7464],\n",
      "        [0.3881, 0.6384, 0.2723, 0.2358, 0.7229, 0.3760, 0.3447, 0.4781, 0.4261],\n",
      "        [0.3367, 0.4124, 0.2653, 0.3790, 0.8040, 0.2390, 0.5267, 0.5229, 0.5005],\n",
      "        [0.4202, 0.5413, 0.4085, 0.6514, 0.4384, 0.3077, 0.5911, 0.5583, 0.2450]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.2121, 0.2821, 0.4084, 0.5869, 0.4663, 0.3448, 0.2710, 0.5176, 0.3996],\n",
      "        [0.6778, 0.5271, 0.2265, 0.3774, 0.5628, 0.4201, 0.4813, 0.4763, 0.4584],\n",
      "        [0.5267, 0.5937, 0.2095, 0.2965, 0.7905, 0.5741, 0.6015, 0.4170, 0.5574],\n",
      "        [0.5300, 0.4867, 0.6792, 0.4452, 0.4592, 0.4490, 0.4376, 0.4348, 0.5349]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4902, 0.4501, 0.4058, 0.4354, 0.5515, 0.4866, 0.5596, 0.4975, 0.6575],\n",
      "        [0.4917, 0.5973, 0.2805, 0.5335, 0.6439, 0.1466, 0.6086, 0.4894, 0.3786],\n",
      "        [0.4843, 0.4097, 0.2901, 0.4228, 0.5691, 0.2462, 0.4131, 0.4469, 0.6026],\n",
      "        [0.5841, 0.5361, 0.4251, 0.6014, 0.5792, 0.5421, 0.5223, 0.5410, 0.7315]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4982, 0.5449, 0.2407, 0.5707, 0.5462, 0.3051, 0.5118, 0.5033, 0.8348],\n",
      "        [0.4378, 0.4384, 0.2404, 0.4843, 0.6182, 0.4005, 0.3885, 0.6001, 0.5044],\n",
      "        [0.4529, 0.6880, 0.7769, 0.5137, 0.5029, 0.6217, 0.7485, 0.7024, 0.4640],\n",
      "        [0.3777, 0.4509, 0.2661, 0.3684, 0.7528, 0.4445, 0.6201, 0.3612, 0.3235]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4721, 0.6917, 0.3143, 0.7173, 0.5489, 0.4336, 0.4584, 0.4644, 0.5062],\n",
      "        [0.6478, 0.6441, 0.5367, 0.5348, 0.5924, 0.6126, 0.5617, 0.4294, 0.7903],\n",
      "        [0.6415, 0.7100, 0.4921, 0.3629, 0.5107, 0.4219, 0.7636, 0.3082, 0.4520],\n",
      "        [0.4155, 0.3566, 0.2951, 0.3966, 0.6770, 0.4520, 0.5708, 0.4660, 0.5198]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5822, 0.5482, 0.5476, 0.4009, 0.5788, 0.3034, 0.6181, 0.4025, 0.5914],\n",
      "        [0.4682, 0.4888, 0.4833, 0.3765, 0.4329, 0.1781, 0.4046, 0.3248, 0.5722],\n",
      "        [0.5127, 0.6581, 0.5572, 0.6086, 0.5762, 0.5228, 0.4041, 0.2012, 0.4126],\n",
      "        [0.4730, 0.5058, 0.4138, 0.5286, 0.5300, 0.5411, 0.3815, 0.2010, 0.4066]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.3828, 0.7430, 0.3696, 0.5946, 0.6216, 0.4861, 0.4554, 0.4459, 0.5409],\n",
      "        [0.5119, 0.4978, 0.3196, 0.4031, 0.6132, 0.3644, 0.5345, 0.5927, 0.6901],\n",
      "        [0.6747, 0.5355, 0.3015, 0.4059, 0.5162, 0.3518, 0.5991, 0.3093, 0.5044],\n",
      "        [0.4180, 0.6072, 0.3226, 0.4485, 0.5334, 0.4385, 0.6827, 0.3906, 0.4756]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.2181, 0.1939, 0.2380, 0.4640, 0.5660, 0.1084, 0.6533, 0.4009, 0.3631],\n",
      "        [0.5428, 0.5653, 0.2233, 0.6693, 0.6211, 0.7196, 0.3363, 0.7151, 0.6506],\n",
      "        [0.3922, 0.6288, 0.4987, 0.5642, 0.4685, 0.2710, 0.5168, 0.2305, 0.7137],\n",
      "        [0.5124, 0.5090, 0.4058, 0.6912, 0.5776, 0.4490, 0.4942, 0.5322, 0.4206]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4510, 0.5292, 0.4652, 0.3736, 0.5495, 0.6626, 0.4209, 0.4083, 0.3826],\n",
      "        [0.5653, 0.6220, 0.3571, 0.5493, 0.5102, 0.3270, 0.4219, 0.6081, 0.5937],\n",
      "        [0.5328, 0.5739, 0.1945, 0.5809, 0.7051, 0.2539, 0.5430, 0.5082, 0.7404],\n",
      "        [0.5848, 0.6322, 0.3147, 0.5200, 0.5522, 0.4681, 0.4903, 0.0668, 0.4436]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4744, 0.5866, 0.5668, 0.6248, 0.6096, 0.5885, 0.7302, 0.4500, 0.5749],\n",
      "        [0.5092, 0.5237, 0.4177, 0.5420, 0.6022, 0.6844, 0.4550, 0.4685, 0.4175],\n",
      "        [0.6150, 0.3812, 0.4884, 0.3374, 0.6910, 0.3479, 0.4655, 0.5757, 0.5413],\n",
      "        [0.4380, 0.5532, 0.6594, 0.6113, 0.3621, 0.3238, 0.1358, 0.5187, 0.5478]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4901, 0.6143, 0.3555, 0.3309, 0.4349, 0.3179, 0.4775, 0.5116, 0.1818],\n",
      "        [0.5763, 0.8401, 0.5114, 0.5625, 0.5839, 0.3320, 0.6130, 0.4820, 0.5377],\n",
      "        [0.4564, 0.4587, 0.4619, 0.4560, 0.4545, 0.3779, 0.4323, 0.6504, 0.4519],\n",
      "        [0.4962, 0.5842, 0.4392, 0.6601, 0.5468, 0.4165, 0.4334, 0.4804, 0.5647]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4828, 0.4813, 0.3856, 0.3613, 0.6671, 0.2675, 0.2964, 0.5184, 0.6136],\n",
      "        [0.4720, 0.5234, 0.4018, 0.5345, 0.5410, 0.2246, 0.5881, 0.4365, 0.5869],\n",
      "        [0.5003, 0.5849, 0.3516, 0.7000, 0.6252, 0.2363, 0.6183, 0.6537, 0.5478],\n",
      "        [0.2965, 0.2663, 0.2051, 0.3593, 0.6689, 0.4074, 0.7010, 0.3426, 0.3414]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5141, 0.8252, 0.2542, 0.5722, 0.7260, 0.3879, 0.5870, 0.5229, 0.4452],\n",
      "        [0.5415, 0.6432, 0.1247, 0.5624, 0.5753, 0.5279, 0.4851, 0.5674, 0.5410],\n",
      "        [0.3679, 0.6593, 0.4716, 0.1892, 0.6835, 0.6695, 0.4263, 0.3128, 0.4108],\n",
      "        [0.5521, 0.4811, 0.1313, 0.2943, 0.4645, 0.5543, 0.5372, 0.6622, 0.6222]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.7999, 0.3933, 0.7694, 0.3832, 0.6023, 0.2444, 0.5599, 0.4411, 0.2934],\n",
      "        [0.4880, 0.6223, 0.1167, 0.7435, 0.8523, 0.3352, 0.5501, 0.4410, 0.5244],\n",
      "        [0.6451, 0.5432, 0.3658, 0.4748, 0.5736, 0.3995, 0.5615, 0.5997, 0.6179],\n",
      "        [0.5860, 0.4516, 0.3560, 0.4872, 0.5485, 0.1704, 0.4557, 0.4648, 0.5529]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.2939, 0.6395, 0.4589, 0.4375, 0.4343, 0.5568, 0.5617, 0.5032, 0.4525],\n",
      "        [0.6126, 0.5472, 0.5204, 0.3953, 0.5966, 0.2322, 0.2798, 0.4781, 0.4439],\n",
      "        [0.4520, 0.4327, 0.4061, 0.4229, 0.5620, 0.3086, 0.4426, 0.2855, 0.3946],\n",
      "        [0.4612, 0.5123, 0.3929, 0.5050, 0.6820, 0.3744, 0.1556, 0.8389, 0.4442]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.7552, 0.4919, 0.2445, 0.7615, 0.5626, 0.5035, 0.4787, 0.5007, 0.7315],\n",
      "        [0.7043, 0.5536, 0.3444, 0.5639, 0.6001, 0.5097, 0.3693, 0.6693, 0.5157],\n",
      "        [0.4901, 0.3828, 0.3258, 0.4447, 0.6373, 0.2399, 0.4166, 0.3456, 0.4124],\n",
      "        [0.6043, 0.6470, 0.5091, 0.5480, 0.6825, 0.4181, 0.5670, 0.5594, 0.4605]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4301, 0.5714, 0.2617, 0.3539, 0.5411, 0.1411, 0.4293, 0.5757, 0.6661],\n",
      "        [0.6371, 0.5311, 0.3419, 0.4988, 0.5720, 0.2988, 0.5438, 0.4082, 0.6848],\n",
      "        [0.4072, 0.8348, 0.3096, 0.1762, 0.7703, 0.4624, 0.6189, 0.5500, 0.4537],\n",
      "        [0.5116, 0.4163, 0.2472, 0.5494, 0.5927, 0.2191, 0.6413, 0.4298, 0.5444]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.3093, 0.5149, 0.6505, 0.7124, 0.5938, 0.3425, 0.2388, 0.5813, 0.2608],\n",
      "        [0.3362, 0.6107, 0.2732, 0.5547, 0.5437, 0.3918, 0.5374, 0.6554, 0.4988],\n",
      "        [0.5759, 0.5830, 0.2982, 0.6287, 0.5404, 0.4675, 0.4834, 0.4488, 0.2988],\n",
      "        [0.4117, 0.4041, 0.5386, 0.6185, 0.7515, 0.4076, 0.5689, 0.5715, 0.2996]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4887, 0.5977, 0.3542, 0.4825, 0.5046, 0.4164, 0.6138, 0.4146, 0.6220],\n",
      "        [0.3718, 0.6528, 0.2043, 0.5475, 0.5226, 0.3087, 0.3941, 0.4957, 0.3689],\n",
      "        [0.5008, 0.5588, 0.2916, 0.5170, 0.5440, 0.3681, 0.6753, 0.7258, 0.4873],\n",
      "        [0.3221, 0.3997, 0.7323, 0.6250, 0.6631, 0.3200, 0.5673, 0.4509, 0.4544]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4980, 0.4743, 0.0709, 0.1896, 0.3703, 0.3612, 0.4351, 0.4793, 0.3898],\n",
      "        [0.3674, 0.7034, 0.4881, 0.4894, 0.3120, 0.4757, 0.4536, 0.4078, 0.3689],\n",
      "        [0.2295, 0.5681, 0.3545, 0.6117, 0.6254, 0.2760, 0.6453, 0.6395, 0.2673],\n",
      "        [0.5489, 0.4867, 0.4943, 0.4914, 0.5701, 0.2279, 0.3419, 0.3798, 0.1014]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3292, 0.3141, 0.3361, 0.5577, 0.6973, 0.3604, 0.3601, 0.5257, 0.6207],\n",
      "        [0.4950, 0.6402, 0.2182, 0.5493, 0.7427, 0.6463, 0.5464, 0.2399, 0.5603],\n",
      "        [0.5793, 0.5379, 0.3043, 0.4643, 0.4198, 0.2627, 0.4154, 0.6527, 0.7294],\n",
      "        [0.5636, 0.4857, 0.2924, 0.6111, 0.5219, 0.4167, 0.4906, 0.6009, 0.4358]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.6480, 0.6399, 0.4316, 0.4815, 0.6923, 0.3512, 0.4859, 0.2807, 0.4644],\n",
      "        [0.4475, 0.5722, 0.3676, 0.3395, 0.5643, 0.3040, 0.4659, 0.0809, 0.4904],\n",
      "        [0.4897, 0.4610, 0.4921, 0.4962, 0.6271, 0.3851, 0.7128, 0.2391, 0.3521],\n",
      "        [0.3706, 0.3136, 0.3449, 0.4904, 0.5881, 0.1529, 0.4877, 0.3252, 0.6511]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4448, 0.5949, 0.3266, 0.4516, 0.5210, 0.5470, 0.5330, 0.7434, 0.4779],\n",
      "        [0.3580, 0.4749, 0.6190, 0.4555, 0.6019, 0.2356, 0.4317, 0.4572, 0.6335],\n",
      "        [0.6193, 0.5952, 0.3816, 0.4315, 0.4184, 0.2800, 0.5447, 0.5066, 0.2965],\n",
      "        [0.6023, 0.5522, 0.2871, 0.4549, 0.6917, 0.2624, 0.3951, 0.6254, 0.3783]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5563, 0.3284, 0.7280, 0.6021, 0.4694, 0.2771, 0.3665, 0.5092, 0.3523],\n",
      "        [0.4152, 0.3207, 0.2143, 0.5541, 0.6051, 0.4885, 0.5452, 0.4254, 0.4645],\n",
      "        [0.4670, 0.5867, 0.4425, 0.4597, 0.5724, 0.7591, 0.6811, 0.6382, 0.3867],\n",
      "        [0.5208, 0.6409, 0.5040, 0.6238, 0.4923, 0.4273, 0.3921, 0.6065, 0.4666]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5825, 0.6457, 0.5800, 0.4796, 0.4309, 0.2960, 0.5987, 0.5303, 0.5619],\n",
      "        [0.5108, 0.5702, 0.6835, 0.3789, 0.3781, 0.2371, 0.4797, 0.5348, 0.6732],\n",
      "        [0.4269, 0.5658, 0.6963, 0.5901, 0.6243, 0.3407, 0.4312, 0.6652, 0.4906],\n",
      "        [0.5276, 0.5860, 0.1628, 0.3031, 0.6035, 0.5433, 0.3647, 0.3844, 0.4557]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4675, 0.3372, 0.5393, 0.5778, 0.5914, 0.4061, 0.5201, 0.6169, 0.6846],\n",
      "        [0.5056, 0.4182, 0.6162, 0.3440, 0.5772, 0.3801, 0.3816, 0.4480, 0.5690],\n",
      "        [0.5082, 0.5734, 0.4061, 0.4092, 0.4987, 0.7660, 0.5959, 0.5645, 0.5359],\n",
      "        [0.4387, 0.4602, 0.4353, 0.4539, 0.5375, 0.6034, 0.4607, 0.5247, 0.6392]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4711, 0.4991, 0.3498, 0.5414, 0.6397, 0.3809, 0.6096, 0.5147, 0.1968],\n",
      "        [0.4818, 0.6014, 0.4141, 0.4448, 0.4437, 0.2249, 0.4544, 0.7003, 0.4670],\n",
      "        [0.5878, 0.5485, 0.4937, 0.6336, 0.4795, 0.2848, 0.6655, 0.4534, 0.5158],\n",
      "        [0.6827, 0.3255, 0.4152, 0.4716, 0.5799, 0.3907, 0.5833, 0.7054, 0.6879]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5560, 0.5509, 0.2143, 0.5101, 0.6022, 0.5397, 0.4775, 0.7715, 0.7890],\n",
      "        [0.4052, 0.5004, 0.7618, 0.5094, 0.4344, 0.2251, 0.5179, 0.3701, 0.6678],\n",
      "        [0.5152, 0.5028, 0.3421, 0.4491, 0.4796, 0.3923, 0.6031, 0.5275, 0.3036],\n",
      "        [0.3612, 0.4996, 0.4047, 0.4745, 0.3316, 0.4929, 0.3813, 0.3547, 0.4912]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.6369, 0.6617, 0.3670, 0.5615, 0.6706, 0.4395, 0.4019, 0.3970, 0.4450],\n",
      "        [0.5654, 0.6997, 0.5385, 0.5388, 0.5084, 0.1963, 0.8240, 0.4592, 0.3899],\n",
      "        [0.5501, 0.5872, 0.2464, 0.3979, 0.4328, 0.4832, 0.5219, 0.4703, 0.5205],\n",
      "        [0.3672, 0.3091, 0.1924, 0.4626, 0.5871, 0.5151, 0.4665, 0.4537, 0.5035]])\n",
      "batch_labels:  tensor([0., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4838, 0.4603, 0.2118, 0.5651, 0.6297, 0.3495, 0.5992, 0.6763, 0.5254],\n",
      "        [0.6259, 0.7180, 0.3467, 0.7064, 0.5521, 0.3798, 0.6425, 0.5214, 0.3221],\n",
      "        [0.5017, 0.5619, 0.3060, 0.5039, 0.4904, 0.1860, 0.4384, 0.4822, 0.3002],\n",
      "        [0.5604, 0.5672, 0.2780, 0.4470, 0.7291, 0.3454, 0.2991, 0.2743, 0.7887]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.2723, 0.3581, 0.2513, 0.5982, 0.5178, 0.3855, 0.7486, 0.6038, 0.4562],\n",
      "        [0.4859, 0.4977, 0.6274, 0.4244, 0.4851, 0.3502, 0.3944, 0.5309, 0.5294],\n",
      "        [0.6345, 0.6365, 0.2928, 0.4897, 0.5441, 0.4618, 0.4192, 0.5957, 0.4370],\n",
      "        [0.5312, 0.4870, 0.4256, 0.4985, 0.5884, 0.3042, 0.6445, 0.5373, 0.4466]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4318, 0.4902, 0.4039, 0.5715, 0.6001, 0.1731, 0.4545, 0.6043, 0.4308],\n",
      "        [0.4385, 0.4689, 0.4853, 0.6604, 0.5509, 0.1367, 0.4471, 0.4408, 0.4367],\n",
      "        [0.5267, 0.4617, 0.2397, 0.2776, 0.7055, 0.2214, 0.3824, 0.5000, 0.5134],\n",
      "        [0.6412, 0.3357, 0.2745, 0.4994, 0.6086, 0.4745, 0.6311, 0.6463, 0.4365]])\n",
      "batch_labels:  tensor([0., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.3995, 0.3665, 0.6098, 0.3633, 0.8132, 0.1740, 0.4753, 0.5906, 0.4175],\n",
      "        [0.5984, 0.3218, 0.3352, 0.8980, 0.7437, 0.3142, 0.3105, 0.5345, 0.5799],\n",
      "        [0.4870, 0.6344, 0.2418, 0.3966, 0.4333, 0.3654, 0.6293, 0.5043, 0.5473],\n",
      "        [0.4479, 0.2173, 0.3524, 0.5430, 0.8476, 0.4235, 0.3903, 0.3906, 0.5939]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4583, 0.5952, 0.4093, 0.4931, 0.6433, 0.6952, 0.3443, 0.2789, 0.5474],\n",
      "        [0.3490, 0.3356, 0.6169, 0.4883, 0.5429, 0.5420, 0.6495, 0.4732, 0.3558],\n",
      "        [0.5048, 0.4403, 0.1876, 0.5856, 0.6031, 0.2835, 0.3977, 0.6476, 0.4814],\n",
      "        [0.6114, 0.4515, 0.2257, 0.4094, 0.7197, 0.5223, 0.6400, 0.7350, 0.4310]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.2800, 0.5268, 0.3603, 0.0451, 0.6039, 0.4239, 0.4042, 0.5260, 0.3023],\n",
      "        [0.5951, 0.3262, 0.2778, 0.8274, 0.5685, 0.4161, 0.4080, 0.3817, 0.4973],\n",
      "        [0.4978, 0.1613, 0.1470, 0.2402, 0.3007, 0.4225, 0.8546, 0.7415, 0.4832],\n",
      "        [0.3507, 0.2633, 0.1942, 0.4278, 1.0000, 0.6860, 0.5317, 0.3059, 0.3397]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5118, 0.3785, 0.5355, 0.5491, 0.4343, 0.4967, 0.4082, 0.6482, 0.9185],\n",
      "        [0.4380, 0.5663, 0.3250, 0.4911, 0.6016, 0.2818, 0.2335, 0.6393, 0.7837],\n",
      "        [0.6393, 0.1966, 0.2723, 0.4061, 0.6929, 0.3426, 0.5172, 0.4726, 0.6893],\n",
      "        [0.4257, 0.5874, 0.2179, 0.6737, 0.5368, 0.3767, 0.3449, 0.1940, 0.2961]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.3126, 0.3947, 0.5338, 0.4843, 0.8070, 0.3336, 0.5991, 0.5347, 0.3446],\n",
      "        [0.3807, 0.4852, 0.6430, 0.5094, 0.5514, 0.3303, 0.5515, 0.3828, 0.4746],\n",
      "        [0.4026, 0.5736, 0.4594, 0.6169, 0.4098, 0.4784, 0.2341, 0.4452, 0.9999],\n",
      "        [0.5350, 0.4711, 0.5795, 0.4563, 0.6710, 0.2266, 0.4710, 0.5619, 0.4059]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.6016, 0.3452, 0.5835, 0.4580, 0.5024, 0.3190, 0.4478, 0.2984, 0.5108],\n",
      "        [0.4296, 0.5638, 0.3500, 0.6657, 0.4036, 0.2374, 0.6042, 0.6156, 0.3235],\n",
      "        [0.5163, 0.4729, 0.4263, 0.4647, 0.5603, 0.5415, 0.4504, 0.4967, 0.4927],\n",
      "        [0.4870, 0.4244, 0.2671, 0.3643, 0.6827, 0.4247, 0.7906, 0.8332, 0.4807]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4887, 0.4686, 0.2339, 0.5089, 0.5731, 0.2700, 0.5853, 0.5986, 0.5441],\n",
      "        [0.4114, 0.6798, 0.3597, 0.4225, 0.6029, 0.3661, 0.6758, 0.4788, 0.5829],\n",
      "        [0.6212, 0.5928, 0.2824, 0.5112, 0.5825, 0.3397, 0.5706, 0.3338, 0.5598],\n",
      "        [0.5357, 0.5613, 0.1649, 0.6065, 0.6888, 0.2249, 0.3862, 0.6752, 0.8135]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5450, 0.4758, 0.8315, 0.5825, 0.4491, 0.6636, 0.5152, 0.5426, 0.4085],\n",
      "        [0.4894, 0.5433, 0.3362, 0.5023, 0.4388, 0.4668, 0.6336, 0.3665, 0.3134],\n",
      "        [0.6601, 1.0000, 0.4304, 0.5288, 0.6481, 0.4982, 0.3964, 0.5200, 0.6329],\n",
      "        [0.5403, 0.5417, 0.2004, 0.2447, 0.6452, 0.3736, 0.3479, 0.6469, 0.6223]])\n",
      "batch_labels:  tensor([1., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4766, 0.4199, 0.3765, 0.4866, 0.6263, 0.4089, 0.4175, 0.4044, 0.2711],\n",
      "        [0.6848, 0.6843, 0.3552, 0.4823, 0.6965, 0.6637, 0.5397, 0.4094, 0.6322],\n",
      "        [0.3789, 0.5245, 0.4928, 0.4957, 0.5755, 0.2963, 0.3865, 0.4970, 0.4950],\n",
      "        [0.3321, 0.4400, 0.2356, 0.6464, 0.5484, 0.6992, 0.4112, 0.4631, 0.5885]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5147, 0.5907, 0.5623, 0.7221, 0.7043, 0.4065, 0.2738, 0.5279, 0.4080],\n",
      "        [0.2953, 0.4875, 0.4323, 0.5854, 0.3760, 0.4971, 0.3467, 0.3902, 0.7245],\n",
      "        [0.5851, 0.5047, 0.3343, 0.5084, 0.6077, 0.3395, 0.4818, 0.5598, 0.7906],\n",
      "        [0.5839, 0.4860, 0.2060, 0.5953, 0.6164, 0.3692, 0.6126, 0.6660, 0.3224]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4711, 0.5929, 0.3002, 0.6412, 0.7507, 0.2671, 0.4900, 0.4217, 0.1893],\n",
      "        [0.4836, 0.4094, 0.3494, 0.5196, 0.5826, 0.4339, 0.3459, 0.6968, 0.7938],\n",
      "        [0.5324, 0.6141, 0.2567, 0.4551, 0.6904, 0.5070, 0.2701, 0.4640, 0.5566],\n",
      "        [0.6823, 0.5900, 0.4425, 0.7237, 0.5686, 0.3488, 0.7287, 0.6694, 0.2310]])\n",
      "batch_labels:  tensor([1., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.7107, 0.5603, 0.1557, 0.4948, 0.6663, 0.2230, 0.3230, 0.7283, 0.4751],\n",
      "        [0.3863, 0.4476, 0.4824, 0.6983, 0.7088, 0.7160, 0.3775, 0.6091, 0.5944],\n",
      "        [0.2671, 0.3253, 0.3122, 0.5089, 0.5550, 0.2552, 0.2192, 0.5772, 0.3478],\n",
      "        [0.6334, 0.5430, 0.2647, 0.1385, 0.4399, 0.3710, 0.6823, 0.4944, 0.0782]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.3146, 0.3784, 0.4027, 0.5621, 0.6357, 0.2214, 0.4581, 0.6129, 0.5300],\n",
      "        [0.5584, 0.6178, 0.3506, 0.6491, 0.4926, 0.3992, 0.8057, 0.5558, 0.6570],\n",
      "        [0.5325, 0.3965, 0.4083, 0.5276, 0.5673, 0.3552, 0.5620, 0.5040, 0.5118],\n",
      "        [0.4314, 0.6759, 0.4363, 0.5393, 0.3991, 0.5094, 0.8019, 0.6116, 0.5919]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4965, 0.5490, 0.3953, 0.5687, 0.6087, 0.5467, 0.4018, 0.6505, 0.5308],\n",
      "        [0.3883, 0.4766, 0.1993, 0.6246, 0.5708, 0.2351, 0.6376, 0.4991, 0.5792],\n",
      "        [0.2651, 0.4274, 0.3849, 0.5094, 0.4836, 0.4453, 0.4133, 0.4729, 0.6894],\n",
      "        [0.4846, 0.4087, 0.1781, 0.5152, 0.7039, 0.6108, 0.3306, 0.2441, 0.3143]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3686, 0.3587, 0.4447, 0.4171, 0.4872, 0.5368, 0.5165, 0.4552, 0.5383],\n",
      "        [0.6463, 0.4560, 0.1798, 0.4652, 0.7359, 0.3079, 0.3323, 0.5164, 0.4583],\n",
      "        [0.5560, 0.6387, 0.3812, 0.5549, 0.5289, 0.3030, 0.3804, 0.3572, 0.6307],\n",
      "        [0.4614, 0.5975, 0.3853, 0.4769, 0.6247, 0.2530, 0.5232, 0.5233, 0.4398]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5914, 0.4348, 0.3864, 0.3258, 0.5979, 0.3536, 0.4635, 0.8824, 0.2649],\n",
      "        [0.6077, 0.5284, 0.2644, 0.4991, 0.6950, 0.2064, 0.5163, 0.5918, 0.3546],\n",
      "        [0.6108, 0.3901, 0.1191, 0.6016, 0.6426, 0.3954, 0.6341, 0.2172, 0.5437],\n",
      "        [0.2329, 0.4587, 0.3983, 0.5760, 0.5119, 0.3566, 0.3158, 0.4104, 0.7809]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5641, 0.5796, 0.3606, 0.4090, 0.5199, 0.5654, 0.6250, 0.5347, 0.6676],\n",
      "        [0.3507, 0.6770, 0.6152, 0.6469, 0.6972, 0.8484, 0.4496, 0.5887, 0.7248],\n",
      "        [0.4711, 0.4908, 0.2793, 0.4242, 0.5268, 0.2078, 0.6315, 0.6638, 0.7037],\n",
      "        [0.5196, 0.3068, 0.2510, 0.6556, 0.6220, 0.2084, 0.4553, 0.4357, 0.7707]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5968, 0.3710, 0.3429, 0.4296, 0.5842, 0.6260, 0.6465, 0.3214, 0.7470],\n",
      "        [0.4998, 0.5757, 0.4402, 0.3969, 0.3322, 0.5512, 0.5717, 0.7200, 0.8450],\n",
      "        [0.4766, 0.5615, 0.5368, 0.4451, 0.5613, 0.5285, 0.7170, 0.4552, 0.2902],\n",
      "        [0.5574, 0.5917, 0.4140, 0.5199, 0.4265, 0.6281, 0.3277, 0.4904, 0.3345]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.3899, 0.6389, 0.7893, 0.4354, 0.5539, 0.4035, 0.4096, 0.2758, 0.4710],\n",
      "        [0.5276, 0.5612, 0.5151, 0.3861, 0.5989, 0.4412, 0.5933, 0.6610, 0.8014],\n",
      "        [0.4221, 0.2718, 0.3588, 0.4618, 0.6494, 0.5196, 0.5516, 0.3873, 0.8547],\n",
      "        [0.5466, 0.5628, 0.3300, 0.3666, 0.7030, 0.3155, 0.5042, 0.3008, 0.7292]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5113, 0.3349, 0.5491, 0.1525, 0.3289, 0.5517, 0.6122, 0.5591, 0.4637],\n",
      "        [0.2696, 0.3678, 0.4556, 0.2341, 0.6902, 0.5190, 0.6269, 0.4768, 0.4020],\n",
      "        [0.7038, 0.5304, 0.1719, 0.4679, 0.5919, 0.2385, 0.8755, 0.5480, 0.6424],\n",
      "        [0.3156, 0.2490, 0.3952, 0.5795, 0.7793, 0.3092, 0.3653, 0.5239, 0.3244]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5137, 0.6191, 0.4138, 0.5251, 0.4293, 0.5179, 0.2550, 0.5230, 0.3926],\n",
      "        [0.6062, 0.6055, 0.4376, 0.4117, 0.6045, 0.3402, 0.5544, 0.2383, 0.4888],\n",
      "        [0.4879, 0.3912, 0.3066, 0.4276, 0.7337, 0.3089, 0.5240, 0.5669, 0.2280],\n",
      "        [0.4945, 0.5390, 0.4324, 0.5700, 0.4311, 0.2977, 0.3470, 0.4448, 0.5526]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5854, 0.6110, 0.4195, 0.3530, 0.6419, 0.5675, 0.3630, 0.4222, 0.5628],\n",
      "        [0.6292, 0.6175, 0.4031, 0.6468, 0.4139, 0.4796, 0.3021, 0.4419, 0.4300],\n",
      "        [0.6032, 0.7180, 0.3926, 0.1366, 0.6737, 0.2540, 0.5036, 0.6076, 0.2170],\n",
      "        [0.5462, 0.6397, 0.3859, 0.5418, 0.5438, 0.3569, 0.6451, 0.2815, 0.5684]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.6646, 0.7856, 0.2641, 0.2455, 0.5804, 0.5466, 0.3663, 0.7835, 0.5123],\n",
      "        [0.4639, 0.5261, 0.2981, 0.5933, 0.6579, 0.5258, 0.3287, 0.4456, 0.4820],\n",
      "        [0.3099, 0.6590, 0.2450, 0.4218, 0.4753, 0.3277, 0.6109, 0.4369, 0.6963],\n",
      "        [0.4768, 0.6305, 0.2519, 0.6033, 0.4132, 0.2884, 0.6934, 0.2748, 0.6686]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5366, 0.4351, 0.5339, 0.4739, 0.5693, 0.2788, 0.4515, 0.4994, 0.4457],\n",
      "        [0.4687, 0.6349, 0.1315, 0.3882, 0.6662, 0.0957, 0.4410, 0.4870, 0.3964],\n",
      "        [0.5221, 0.6964, 0.0000, 0.2733, 0.5883, 0.2891, 0.7345, 0.6799, 0.4006],\n",
      "        [0.5598, 0.3976, 0.1123, 0.3175, 0.6921, 0.2074, 0.8440, 0.5650, 0.5592]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.2479, 0.4528, 0.4350, 0.3534, 0.4462, 0.4626, 0.2755, 0.5633, 0.3993],\n",
      "        [0.4192, 0.3589, 0.3702, 0.2512, 0.4895, 0.3319, 0.2847, 0.5408, 0.5404],\n",
      "        [0.4613, 0.5907, 0.4301, 0.3789, 0.5160, 0.4981, 0.3722, 0.3463, 0.4086],\n",
      "        [0.5241, 0.4333, 0.3105, 0.7230, 0.5666, 0.2946, 0.4347, 0.3507, 0.2971]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.6065, 0.4143, 0.1099, 0.4814, 0.7965, 0.3661, 0.5612, 0.3777, 0.3460],\n",
      "        [0.3934, 0.5981, 0.3941, 0.5873, 0.7302, 0.3618, 0.5825, 0.1958, 0.4933],\n",
      "        [0.3033, 0.3947, 0.2621, 0.4190, 0.6361, 0.4035, 0.4935, 0.6116, 0.5227],\n",
      "        [0.3850, 0.5516, 0.6872, 0.4390, 0.6564, 0.4097, 0.6697, 0.4560, 0.3722]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4610, 0.3393, 0.2217, 0.7131, 0.6043, 0.3940, 0.3298, 0.6041, 0.4601],\n",
      "        [0.5380, 0.6785, 0.3172, 0.8261, 0.6322, 0.5679, 0.2595, 0.4074, 0.3732],\n",
      "        [0.3812, 0.3771, 0.5114, 0.3521, 0.6871, 0.5205, 0.6073, 0.6208, 0.9728],\n",
      "        [0.4130, 0.5013, 0.2156, 0.4491, 0.7151, 0.3013, 0.7700, 0.7089, 0.6072]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5130, 0.4141, 0.5995, 0.6920, 0.3698, 0.4232, 0.5681, 0.6334, 0.5980],\n",
      "        [0.4170, 0.5301, 0.3495, 0.5522, 0.5175, 0.3814, 0.6624, 0.5596, 0.7063],\n",
      "        [0.6176, 0.5327, 0.4319, 0.4434, 0.4536, 0.2451, 0.5846, 0.5217, 0.3368],\n",
      "        [0.4296, 0.4174, 0.5119, 0.9093, 0.4508, 0.4864, 0.4411, 0.6472, 0.4016]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.7015, 0.6034, 0.3484, 0.5620, 0.5598, 0.4698, 0.5131, 0.4421, 0.4560],\n",
      "        [0.4992, 0.6968, 0.4126, 0.2899, 0.4384, 0.2534, 0.5592, 0.3210, 0.3202],\n",
      "        [0.5523, 0.6863, 0.4518, 0.2479, 0.4908, 0.4370, 0.5921, 0.7652, 0.6670],\n",
      "        [0.5509, 0.4791, 0.3544, 0.6643, 0.5870, 0.3219, 0.5152, 0.5618, 0.3263]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5633, 0.4400, 0.4343, 0.3661, 0.4504, 0.4229, 0.2597, 0.6585, 0.3376],\n",
      "        [0.3903, 0.5512, 0.6508, 0.5317, 0.7831, 0.5615, 0.4561, 0.6651, 0.4857],\n",
      "        [0.4884, 0.5583, 0.1826, 0.2617, 0.5301, 0.3436, 0.4469, 0.6828, 0.3460],\n",
      "        [0.5379, 0.5396, 0.3111, 0.4913, 0.5051, 0.3062, 0.6162, 0.2109, 0.4952]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5444, 0.7331, 0.6437, 0.5961, 0.8452, 0.2497, 0.6162, 0.4497, 0.4509],\n",
      "        [0.4022, 0.8160, 0.2688, 0.5400, 0.5295, 0.4039, 0.5274, 0.4526, 0.4849],\n",
      "        [0.3061, 0.4325, 0.4395, 0.3032, 0.4817, 0.4131, 0.6260, 0.4139, 0.3604],\n",
      "        [0.5125, 0.3923, 0.3036, 0.6828, 0.7530, 0.3110, 0.5265, 0.6257, 0.4449]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5111, 0.4296, 0.4833, 0.3965, 0.5266, 0.3607, 0.4622, 0.6806, 0.4896],\n",
      "        [0.3797, 0.5989, 0.3676, 0.4632, 0.6422, 0.2001, 0.4769, 0.4269, 0.4657],\n",
      "        [0.6018, 0.5693, 0.5026, 0.4971, 0.6068, 0.2540, 0.2743, 0.4518, 0.1419],\n",
      "        [0.4896, 0.4486, 0.5647, 0.5131, 0.7043, 0.2251, 0.4898, 0.5326, 0.5600]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4951, 0.2255, 0.5385, 0.2606, 0.4338, 0.2658, 0.5217, 0.4296, 0.2813],\n",
      "        [0.5115, 0.6381, 0.2864, 0.5282, 0.4070, 0.5745, 0.6320, 0.5071, 0.5048],\n",
      "        [0.6087, 0.2119, 0.5654, 0.7203, 0.3836, 0.2548, 0.4332, 0.3931, 0.6273],\n",
      "        [0.3986, 0.5069, 0.2194, 0.6230, 0.4489, 0.2600, 0.6077, 0.4318, 0.5215]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5764, 0.5328, 0.2956, 0.3565, 0.5916, 0.5914, 0.6515, 0.4489, 0.4896],\n",
      "        [0.6639, 0.3454, 0.2632, 0.5429, 0.5323, 0.4047, 0.5420, 0.8632, 0.5810],\n",
      "        [0.6294, 0.1390, 0.4861, 0.4066, 0.9406, 0.4410, 0.4755, 0.6045, 0.6550],\n",
      "        [0.4662, 0.5761, 0.2861, 0.5339, 0.6497, 0.3101, 0.5313, 0.2020, 0.7311]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5311, 0.6424, 0.3304, 0.2517, 0.4240, 0.4452, 0.6190, 0.3878, 0.5684],\n",
      "        [0.5164, 0.5603, 0.2224, 0.6370, 0.5132, 0.3826, 0.4107, 0.5626, 0.4894],\n",
      "        [0.4076, 0.4967, 0.3098, 0.3626, 0.7992, 0.7637, 0.6220, 0.7320, 0.5526],\n",
      "        [0.6055, 0.3557, 0.4159, 0.2468, 0.6570, 0.5236, 0.2752, 0.5103, 0.2686]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3820, 0.2555, 0.3768, 0.5791, 0.4307, 0.4345, 0.5104, 0.6906, 0.7169],\n",
      "        [0.4887, 0.5778, 0.2615, 0.4777, 0.5676, 0.4838, 0.6130, 0.8285, 0.6823],\n",
      "        [0.4477, 0.3514, 0.3720, 0.3330, 0.5348, 0.1878, 0.5912, 0.4642, 0.3610],\n",
      "        [0.5626, 0.3782, 0.3002, 0.4781, 0.7223, 0.2940, 0.6635, 0.5844, 0.3679]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5850, 0.3202, 0.2507, 0.6526, 0.4945, 0.2191, 0.4617, 0.9137, 0.5599],\n",
      "        [0.4231, 0.6344, 0.1762, 0.3914, 0.5051, 0.4348, 0.6059, 0.4918, 0.6817],\n",
      "        [0.4796, 0.3723, 0.2438, 0.3975, 0.4337, 0.3414, 0.5094, 0.3101, 0.3361],\n",
      "        [0.3621, 0.4887, 0.6029, 0.3743, 0.4374, 0.3241, 0.5510, 0.6231, 0.5954]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4339, 0.5797, 0.5182, 0.5661, 0.6838, 0.2141, 0.3244, 0.4915, 0.4040],\n",
      "        [0.3701, 0.8472, 0.6236, 0.9929, 0.1455, 0.3458, 0.3348, 0.4029, 0.5901],\n",
      "        [0.6020, 0.2246, 0.5643, 0.3977, 0.9358, 0.6389, 0.5553, 0.6835, 0.5346],\n",
      "        [0.3958, 0.2858, 0.3215, 0.4903, 0.8217, 0.2867, 0.6657, 0.5967, 0.7889]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4116, 0.3758, 0.4042, 0.5237, 0.6470, 0.3627, 0.6516, 0.6199, 0.5611],\n",
      "        [0.8474, 0.6342, 0.1420, 0.7250, 0.6183, 0.5411, 0.5356, 0.4761, 0.3122],\n",
      "        [0.6916, 0.8044, 0.1758, 0.5613, 0.4803, 0.6858, 0.4177, 0.3706, 0.3909],\n",
      "        [0.3162, 0.4618, 0.5978, 0.4233, 0.5328, 0.3711, 0.7054, 0.4656, 0.6046]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.6286, 0.2944, 0.3080, 0.5860, 0.6036, 0.1546, 0.5238, 0.2921, 0.6470],\n",
      "        [0.5188, 0.6024, 0.3078, 0.6847, 0.4125, 0.6335, 0.5090, 0.5088, 0.3434],\n",
      "        [0.5474, 0.5693, 0.4242, 0.5568, 0.6678, 0.4758, 0.5347, 0.5331, 0.5847],\n",
      "        [0.4851, 0.5643, 0.3366, 0.4251, 0.5059, 0.2216, 0.7663, 0.5488, 0.7841]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5853, 0.5658, 0.1943, 0.4256, 0.6586, 0.5863, 0.5200, 0.4715, 0.4223],\n",
      "        [0.6843, 0.5402, 0.1458, 0.3029, 0.7316, 0.3465, 0.4131, 0.3927, 0.3454],\n",
      "        [0.4272, 0.3820, 0.3739, 0.5360, 0.5177, 0.2520, 0.4605, 0.7530, 0.9147],\n",
      "        [0.3985, 0.4541, 0.3396, 0.3330, 0.4581, 0.5462, 0.7032, 0.5169, 0.3931]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4721, 0.6394, 0.4058, 0.7108, 0.5459, 0.5804, 0.4410, 0.5170, 0.6491],\n",
      "        [0.6182, 0.4344, 0.1669, 0.4419, 0.6804, 0.2214, 0.4727, 0.6689, 0.2760],\n",
      "        [0.3653, 0.5636, 0.5147, 0.2082, 0.6040, 0.2935, 0.6395, 0.2389, 0.4521],\n",
      "        [0.4248, 0.5086, 0.6345, 0.5743, 0.7117, 0.2872, 0.7215, 0.2884, 0.5454]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4858, 0.5217, 0.4866, 0.4379, 0.5474, 0.4568, 0.3662, 0.7223, 0.8116],\n",
      "        [0.7279, 0.5915, 0.1661, 0.2511, 0.6826, 0.5918, 0.6636, 0.3948, 0.3648],\n",
      "        [0.6040, 0.4280, 0.4100, 0.5335, 0.6358, 0.3837, 0.4095, 0.8687, 0.4074],\n",
      "        [0.4514, 0.5049, 0.4526, 0.0932, 0.8712, 0.2732, 0.5936, 0.2120, 0.6043]])\n",
      "batch_labels:  tensor([1., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4750, 0.4252, 0.6102, 0.1257, 0.6833, 0.3406, 0.6074, 0.4877, 0.4372],\n",
      "        [0.3950, 0.6415, 0.2961, 0.6291, 0.4675, 0.6389, 0.4859, 0.3973, 0.4328],\n",
      "        [0.3949, 0.2816, 0.4284, 0.7327, 0.5433, 0.5625, 0.8628, 0.5931, 0.4731],\n",
      "        [0.4989, 0.5497, 0.3979, 0.4170, 0.4732, 0.1731, 0.6009, 0.5410, 0.6858]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5208, 0.7567, 0.3243, 0.3499, 0.5989, 0.2774, 0.5151, 0.5582, 0.4649],\n",
      "        [0.4911, 0.3260, 0.3573, 0.1071, 0.5745, 0.4686, 0.5356, 0.5293, 0.4509],\n",
      "        [0.5745, 0.3291, 0.8986, 0.5498, 0.5034, 0.4021, 0.4887, 0.4895, 0.5774],\n",
      "        [0.5880, 0.5757, 0.6259, 0.5942, 0.6187, 0.6661, 0.6154, 0.4697, 0.5838]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4659, 0.5287, 0.2455, 0.6274, 0.6022, 0.1622, 0.5545, 0.4833, 0.4897],\n",
      "        [0.4172, 0.4456, 0.4715, 0.3704, 0.7677, 0.5080, 0.2826, 0.3497, 0.5469],\n",
      "        [0.5276, 0.5401, 0.4404, 0.4679, 0.5651, 0.2020, 0.5800, 0.5579, 0.4222],\n",
      "        [0.4614, 0.5218, 0.4166, 0.6114, 0.6363, 0.4653, 0.4354, 0.6147, 0.5356]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4000, 0.4380, 0.2201, 0.5553, 0.8376, 0.3868, 0.4109, 0.6509, 0.2561],\n",
      "        [0.5306, 0.6082, 0.2583, 0.4525, 0.6744, 0.6920, 0.6261, 0.4428, 0.5468],\n",
      "        [0.5737, 0.6466, 0.3496, 0.3194, 0.6251, 0.3343, 0.5167, 0.4745, 0.6400],\n",
      "        [0.5509, 0.5327, 0.4299, 0.5317, 0.5482, 0.5710, 0.6064, 0.6244, 0.5262]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5107, 0.4740, 0.3751, 0.4419, 0.6466, 0.3420, 0.4915, 0.6282, 0.5816],\n",
      "        [0.5413, 0.4397, 0.2098, 0.3413, 0.4751, 0.4861, 0.5495, 0.4611, 0.4616],\n",
      "        [0.6233, 0.8067, 0.2104, 0.7779, 0.6570, 0.4276, 0.5544, 0.5138, 0.8201],\n",
      "        [0.6432, 0.6755, 0.1545, 0.7182, 0.5571, 0.3258, 0.6851, 0.7790, 0.2169]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4448, 0.6305, 0.2823, 0.5263, 0.8019, 0.2790, 0.3132, 0.6404, 0.6909],\n",
      "        [0.6796, 0.5017, 0.1964, 0.4155, 0.6745, 0.2214, 0.4381, 0.2493, 0.6377],\n",
      "        [0.5633, 0.5194, 0.3073, 0.4585, 0.4760, 0.3189, 0.3261, 0.5052, 0.6546],\n",
      "        [0.5809, 0.4458, 0.3171, 0.4534, 0.5874, 0.6676, 0.5208, 0.4746, 0.2640]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5777, 0.3820, 0.3138, 0.2256, 0.5765, 0.2929, 0.4167, 0.4136, 0.6242],\n",
      "        [0.6267, 0.7428, 0.1656, 0.5592, 0.6233, 0.2586, 0.2312, 0.6024, 0.8079],\n",
      "        [0.4077, 0.5899, 0.5221, 0.2376, 0.5667, 0.1978, 0.4892, 0.4685, 0.4788],\n",
      "        [0.5826, 0.3851, 0.3080, 0.4817, 0.5522, 0.1374, 0.4149, 0.4566, 0.4054]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.5168, 0.4462, 0.0956, 0.4579, 0.6956, 0.2874, 0.7371, 0.5624, 0.3903],\n",
      "        [0.4381, 0.8078, 0.1469, 0.7269, 0.4469, 0.5244, 0.4324, 0.1182, 0.6547],\n",
      "        [0.4384, 0.3519, 0.3274, 0.4640, 0.5262, 0.5401, 0.5185, 0.5158, 0.3600],\n",
      "        [0.1561, 0.2312, 0.2023, 0.7314, 0.4898, 0.5479, 0.2637, 0.5868, 0.4320]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4575, 0.4549, 0.1872, 0.4631, 0.7095, 0.4147, 0.4604, 0.7992, 0.6216],\n",
      "        [0.4790, 0.2979, 0.2341, 0.4288, 0.4561, 0.3828, 0.4881, 0.6320, 0.5087],\n",
      "        [0.4878, 0.6048, 0.6430, 0.3545, 0.5936, 0.3016, 0.7240, 0.3849, 0.6686],\n",
      "        [0.6780, 0.7313, 0.2997, 0.4143, 0.6184, 0.3783, 0.6622, 0.6444, 0.3435]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_imputs:  tensor([[0.4701, 0.5488, 0.3013, 0.5383, 0.4986, 0.2314, 0.5651, 0.1759, 0.3951],\n",
      "        [0.3356, 0.4642, 0.5784, 0.5202, 0.4680, 0.3463, 0.3399, 0.6635, 0.4828],\n",
      "        [0.3948, 0.4640, 0.3268, 0.3206, 0.5229, 0.2427, 0.6188, 0.4418, 0.4203],\n",
      "        [0.8235, 0.4898, 0.6928, 0.6365, 0.3039, 0.4745, 0.7026, 0.6318, 0.4582]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4943, 0.6029, 0.3458, 0.4830, 0.6900, 0.6064, 0.5282, 0.5140, 0.6159],\n",
      "        [0.6486, 0.5000, 0.2912, 0.7430, 0.4907, 0.3680, 0.1208, 0.4062, 0.7934],\n",
      "        [0.2904, 0.5247, 0.2279, 0.4722, 0.6984, 0.3644, 0.8314, 0.5882, 0.6006],\n",
      "        [0.6300, 0.4951, 0.2314, 0.3558, 0.5523, 0.2098, 0.6019, 0.4579, 0.5779]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3266, 0.7225, 0.3652, 0.3106, 0.7102, 0.3797, 0.6276, 0.6085, 0.3382],\n",
      "        [0.4907, 0.5991, 0.2875, 0.4307, 0.5967, 0.5280, 0.5484, 0.5374, 0.3235],\n",
      "        [0.8183, 0.4619, 0.2124, 0.5689, 0.5579, 0.1068, 0.3013, 0.5155, 0.7047],\n",
      "        [0.7001, 0.6163, 0.5204, 0.5390, 0.4321, 0.2801, 0.4838, 0.6536, 0.6515]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.6987, 0.5546, 0.6226, 0.5930, 0.5915, 0.4728, 0.3187, 0.3666, 0.6089],\n",
      "        [0.5668, 0.5090, 0.4430, 0.4354, 0.5725, 0.5242, 0.5203, 0.7037, 0.1986],\n",
      "        [0.5036, 0.5343, 0.6036, 0.6835, 0.5433, 0.3878, 0.5652, 0.7070, 0.3775],\n",
      "        [0.3834, 0.4869, 0.2104, 0.3272, 0.8636, 0.3695, 0.2545, 0.4015, 0.6187]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5136, 0.5423, 0.4176, 0.5785, 0.5805, 0.5945, 0.4093, 0.2812, 0.4941],\n",
      "        [0.4688, 0.8145, 0.3324, 0.3362, 0.5896, 0.1923, 0.7248, 0.5790, 0.7449],\n",
      "        [0.5050, 0.6218, 0.0850, 0.3997, 0.6608, 0.1692, 0.1345, 0.6314, 0.5067],\n",
      "        [0.4830, 0.3695, 0.7881, 0.1151, 0.2561, 0.6388, 0.5773, 0.5108, 0.8401]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.2969, 0.6234, 0.4779, 0.4684, 0.5594, 0.4436, 0.6028, 0.3016, 0.5210],\n",
      "        [0.3264, 0.7332, 0.4008, 0.3861, 0.7089, 0.3800, 0.5799, 0.5038, 0.4891],\n",
      "        [0.5225, 0.4386, 0.6077, 0.5572, 0.4965, 0.4137, 0.2203, 0.5036, 0.3797],\n",
      "        [0.4275, 0.6868, 0.2750, 0.7411, 0.5977, 0.3728, 0.7702, 0.4721, 0.4507]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.3388, 0.4555, 0.1887, 0.5173, 0.6358, 0.2484, 0.7830, 0.7142, 0.4252],\n",
      "        [0.3008, 0.4723, 0.5203, 0.5731, 0.4887, 0.4616, 0.5703, 0.3303, 0.6342],\n",
      "        [0.3061, 0.6835, 0.4228, 0.7138, 0.5938, 0.6024, 0.3901, 0.5238, 0.7113],\n",
      "        [0.5690, 0.5796, 0.4781, 0.4242, 0.3536, 0.5232, 0.4136, 0.4923, 0.3715]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.6147, 0.5975, 0.2891, 0.6379, 0.6429, 0.6228, 0.2049, 0.5610, 0.6418],\n",
      "        [0.6393, 0.3394, 0.4376, 0.5324, 0.8168, 0.2558, 0.4595, 0.4672, 0.4314],\n",
      "        [0.5271, 0.5175, 0.4464, 0.3042, 0.6063, 0.4405, 0.5610, 0.2995, 0.7134],\n",
      "        [0.4750, 0.3914, 0.1913, 0.4883, 0.5022, 0.1594, 0.6589, 0.4629, 0.7474]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4974, 0.6036, 0.4193, 0.4082, 0.6050, 0.2382, 0.3411, 0.7080, 0.6570],\n",
      "        [0.4785, 0.5981, 0.4848, 0.4181, 0.6020, 0.5965, 0.6969, 0.5198, 0.3168],\n",
      "        [0.5743, 0.4541, 0.5290, 0.4111, 0.6950, 0.3607, 0.5276, 0.2531, 0.5460],\n",
      "        [0.5664, 0.5384, 0.3576, 0.2676, 0.7878, 0.5690, 0.7804, 0.5369, 0.4888]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5927, 0.5815, 0.4756, 0.4399, 0.4371, 0.4383, 0.4290, 0.3274, 0.5353],\n",
      "        [0.5793, 0.4487, 0.3317, 0.4492, 0.6196, 0.2379, 0.6502, 0.5035, 0.5501],\n",
      "        [0.6904, 0.5588, 0.1883, 0.4018, 0.6511, 0.4490, 0.4721, 0.3338, 0.8173],\n",
      "        [0.5905, 0.5932, 0.5057, 0.3533, 0.5150, 0.4893, 0.3404, 0.3569, 0.4492]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4853, 0.6914, 0.1325, 0.5671, 0.8853, 0.5189, 0.6521, 0.3182, 0.5729],\n",
      "        [0.5509, 0.4382, 0.3062, 0.5196, 0.6343, 0.3052, 0.4873, 0.6264, 0.2878],\n",
      "        [0.6389, 0.7370, 0.4922, 0.4429, 0.6947, 0.7009, 0.5622, 0.4379, 0.1128],\n",
      "        [0.5472, 0.4931, 0.3507, 0.5925, 0.6948, 0.3144, 0.3723, 0.1769, 0.5280]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4380, 0.2333, 0.1676, 0.7576, 0.5436, 0.3584, 0.3486, 0.3019, 0.4920],\n",
      "        [0.4807, 0.3786, 0.1023, 0.4040, 0.6937, 0.4371, 0.3595, 0.4804, 0.5564],\n",
      "        [0.3863, 0.5886, 0.5997, 0.4479, 0.5750, 0.4144, 0.5421, 0.4887, 0.6243],\n",
      "        [0.3192, 0.1950, 0.4034, 0.5885, 0.6904, 0.1068, 0.4375, 0.5023, 0.3913]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.6279, 0.6374, 0.5015, 0.3347, 0.6334, 0.4951, 0.5032, 0.3812, 0.5069],\n",
      "        [0.3940, 0.2998, 0.2874, 0.4355, 0.4847, 0.1284, 0.4674, 0.6866, 0.7431],\n",
      "        [0.4861, 0.5246, 0.2883, 0.6026, 0.6503, 0.2436, 0.7550, 0.4500, 0.5536],\n",
      "        [0.4618, 0.7031, 0.4198, 0.4593, 0.4111, 0.2343, 0.2842, 0.3363, 0.5484]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3527, 0.4104, 0.5899, 0.3956, 0.6314, 0.5544, 0.6287, 0.4669, 0.4979],\n",
      "        [0.2442, 0.5750, 0.5895, 0.3537, 0.5096, 0.4785, 0.6420, 0.3596, 0.5342],\n",
      "        [0.4907, 0.2458, 0.3850, 0.6124, 0.6029, 0.6066, 0.5634, 0.7202, 0.5543],\n",
      "        [0.5842, 0.4702, 0.1923, 0.5129, 0.6173, 0.2583, 0.5287, 0.7006, 0.3730]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4903, 0.3717, 0.3081, 0.4336, 0.6924, 0.5276, 0.3816, 0.3477, 0.4994],\n",
      "        [0.3759, 0.7604, 0.1753, 0.7036, 0.3401, 0.3540, 0.5366, 0.4958, 0.5051],\n",
      "        [0.6947, 0.7420, 0.2167, 0.3921, 0.4607, 0.6786, 0.3816, 0.6248, 0.2690],\n",
      "        [0.6665, 0.5875, 0.4919, 0.4060, 0.6433, 0.2653, 0.5700, 0.2039, 0.3265]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.6699, 0.6206, 0.3749, 0.3423, 0.2803, 0.4169, 0.5471, 0.3765, 0.5171],\n",
      "        [0.5681, 0.4030, 0.4988, 0.4261, 0.5397, 0.5352, 0.5641, 0.7152, 0.4594],\n",
      "        [0.4390, 0.4854, 0.2637, 0.3171, 0.6276, 0.6101, 0.4105, 0.3771, 0.6067],\n",
      "        [0.3276, 0.3640, 0.4788, 0.1254, 0.6926, 0.4270, 0.5212, 0.4896, 0.2958]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4821, 0.4129, 0.4236, 0.3527, 0.4791, 0.5120, 0.3742, 0.4915, 0.4705],\n",
      "        [0.4628, 0.5419, 0.3439, 0.4927, 0.6108, 0.4150, 0.4020, 0.4226, 0.5002],\n",
      "        [0.4900, 0.5432, 0.3982, 0.3866, 0.4973, 0.4353, 0.4562, 0.6013, 0.6901],\n",
      "        [0.5923, 0.6145, 0.4832, 0.4334, 0.6362, 0.2110, 0.3404, 0.4820, 0.3986]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4894, 0.5959, 0.5984, 0.6464, 0.6590, 0.4299, 0.6624, 0.5488, 0.3613],\n",
      "        [0.5078, 0.5314, 0.2383, 0.5481, 0.6338, 0.3819, 0.5614, 0.6193, 0.3391],\n",
      "        [0.4666, 0.4064, 0.6142, 0.5878, 0.4676, 0.3405, 0.5512, 0.5146, 0.6782],\n",
      "        [0.5125, 0.5534, 0.5441, 0.4657, 0.5882, 0.2737, 0.3373, 0.4804, 0.6415]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.7035, 0.5049, 0.6569, 0.5127, 0.3379, 0.5817, 0.1335, 0.6000, 0.3852],\n",
      "        [0.3719, 0.4934, 0.5604, 0.5817, 0.5631, 0.4166, 0.3860, 0.4093, 0.4735],\n",
      "        [0.5781, 0.3397, 0.3225, 0.9250, 0.6849, 0.1572, 0.3899, 0.6168, 0.4479],\n",
      "        [0.5564, 0.4374, 0.5669, 0.5438, 0.6570, 0.2591, 0.3647, 0.4480, 0.3488]])\n",
      "batch_labels:  tensor([1., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4237, 0.3579, 0.2573, 0.5192, 0.5023, 0.2277, 0.4075, 0.5238, 0.3999],\n",
      "        [0.6102, 0.3727, 0.2592, 0.5016, 0.6305, 0.4395, 0.5909, 0.4297, 0.4343],\n",
      "        [0.4079, 0.3022, 0.2367, 0.6382, 0.7546, 0.6007, 0.4844, 0.7194, 0.5725],\n",
      "        [0.4170, 0.6437, 0.2849, 0.3326, 0.5289, 0.2287, 0.4485, 0.2684, 0.7887]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5551, 0.4476, 0.4454, 0.1980, 0.6633, 0.2058, 0.4004, 0.4932, 0.3680],\n",
      "        [0.4300, 0.4713, 0.1440, 0.5414, 0.6522, 0.4490, 0.4442, 0.3845, 0.3954],\n",
      "        [0.4329, 0.6190, 0.2654, 0.3824, 0.6747, 0.8123, 0.3248, 0.5476, 0.3127],\n",
      "        [0.7291, 0.5935, 0.2392, 0.5216, 0.5828, 0.2537, 0.5431, 0.6594, 0.5659]])\n",
      "batch_labels:  tensor([0., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.5454, 0.5506, 0.5357, 0.5473, 0.4557, 0.1306, 0.6818, 0.3786, 0.4353],\n",
      "        [0.2982, 0.3377, 0.2320, 0.6146, 0.5476, 0.3369, 0.2261, 0.6004, 0.2306],\n",
      "        [0.4024, 0.4548, 0.5490, 0.5966, 0.6464, 0.3235, 0.3318, 0.7941, 0.3256],\n",
      "        [0.4766, 0.5562, 0.3530, 0.3760, 0.4527, 0.1626, 0.4082, 0.4222, 0.3239]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.6691, 0.0000, 0.3582, 0.5653, 0.5307, 0.4659, 0.4168, 0.3663, 0.4037],\n",
      "        [0.5690, 0.5592, 0.1494, 0.6135, 0.6433, 0.2487, 0.6660, 0.8462, 0.3560],\n",
      "        [0.4632, 0.6483, 0.4647, 0.6976, 0.8216, 0.4381, 0.5430, 0.4573, 0.3959],\n",
      "        [0.4640, 0.4133, 0.5862, 0.4798, 0.5601, 0.5044, 0.5530, 0.4485, 0.6247]])\n",
      "batch_labels:  tensor([1., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.5082, 0.5509, 0.3877, 0.3810, 0.6412, 0.2756, 0.3306, 0.5050, 0.5723],\n",
      "        [0.5355, 0.5161, 0.1963, 0.4694, 0.4999, 0.0158, 0.6339, 0.4702, 0.4458],\n",
      "        [0.6378, 0.8005, 0.2269, 0.5312, 0.6515, 0.6311, 0.3957, 0.4776, 0.6962],\n",
      "        [0.3676, 0.3565, 0.1592, 0.6715, 0.6521, 0.4766, 0.3636, 0.5118, 0.4124]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5947, 0.4854, 0.5162, 0.3591, 0.5037, 0.6256, 0.4408, 0.7585, 0.3950],\n",
      "        [0.1692, 0.3035, 0.3738, 0.6605, 0.5200, 0.3711, 0.3757, 0.6472, 0.2710],\n",
      "        [0.2311, 0.5491, 0.8680, 0.3644, 0.4914, 0.2717, 0.5558, 0.6763, 0.4503],\n",
      "        [0.5523, 0.6047, 0.4988, 0.6799, 0.5320, 0.4722, 0.5294, 0.4198, 0.8188]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5932, 0.5167, 0.2929, 0.5731, 0.6090, 0.3640, 0.6061, 0.5829, 0.2747],\n",
      "        [0.3733, 0.4816, 0.5750, 0.5716, 0.6316, 0.4242, 0.3944, 0.8605, 0.1098],\n",
      "        [0.4818, 0.4966, 0.4146, 0.5796, 0.6186, 0.4307, 0.5023, 0.6970, 0.5689],\n",
      "        [0.6026, 0.5901, 0.0551, 0.3646, 0.5927, 0.7504, 0.5130, 0.6412, 0.2378]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3974, 0.3978, 0.2991, 0.6940, 0.6982, 0.3213, 0.3536, 0.4741, 0.8934],\n",
      "        [0.6353, 0.5147, 0.3544, 0.5265, 0.6354, 0.5265, 0.7023, 0.4817, 0.3469],\n",
      "        [0.7592, 0.4096, 0.2749, 0.3562, 0.5066, 0.2215, 0.3181, 0.6056, 0.5054],\n",
      "        [0.4937, 0.4586, 0.5460, 0.6143, 0.5638, 0.2259, 0.3137, 0.3824, 0.7737]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5283, 0.4643, 0.5640, 0.5326, 0.5311, 0.4928, 0.3970, 0.3007, 0.5660],\n",
      "        [0.2543, 0.6431, 0.2950, 0.4777, 0.5526, 0.4627, 0.3282, 0.3337, 0.6924],\n",
      "        [0.7515, 0.8388, 0.5044, 0.1189, 0.7110, 0.2403, 0.5165, 0.4906, 0.3175],\n",
      "        [0.3339, 0.6614, 0.1927, 0.4305, 0.6858, 0.3055, 0.4372, 0.3270, 0.3990]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4265, 0.5814, 0.2787, 0.6362, 0.5098, 0.3919, 0.4413, 0.4672, 0.4134],\n",
      "        [0.4806, 0.4279, 0.2883, 0.4053, 0.5110, 0.6187, 0.4203, 0.4533, 0.6461],\n",
      "        [0.6100, 0.4640, 0.2380, 0.4174, 0.3561, 0.3463, 0.4107, 0.3862, 0.3214],\n",
      "        [0.4558, 0.6271, 0.2966, 0.4727, 0.5376, 0.5120, 0.6582, 0.6228, 0.2856]])\n",
      "batch_labels:  tensor([1., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.5302, 0.4032, 0.4761, 0.3100, 0.7080, 0.2238, 0.4671, 0.7682, 0.6215],\n",
      "        [0.5347, 0.5157, 0.4462, 0.5567, 0.5386, 0.3894, 0.7223, 0.3439, 0.6076],\n",
      "        [0.4204, 0.5435, 0.2641, 0.5275, 0.5076, 0.4172, 0.4846, 0.3876, 0.5903],\n",
      "        [0.5432, 0.4737, 0.2695, 0.3116, 0.5504, 0.5826, 0.5599, 0.4220, 0.6832]])\n",
      "batch_labels:  tensor([0., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.2536, 0.7192, 0.4143, 0.5362, 0.6322, 0.4094, 0.7334, 0.2602, 0.2514],\n",
      "        [0.5309, 0.7587, 0.4750, 0.4781, 0.3915, 0.2729, 0.5019, 0.4382, 0.7884],\n",
      "        [0.5698, 0.5016, 0.5192, 0.7756, 0.4822, 0.2177, 0.3044, 0.5558, 0.4426],\n",
      "        [0.4942, 0.7100, 0.2690, 0.5266, 0.5017, 0.5702, 0.6178, 0.7193, 0.4919]])\n",
      "batch_labels:  tensor([0., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4212, 0.7764, 0.2996, 0.6806, 0.7139, 0.5672, 0.7433, 0.5887, 0.5215],\n",
      "        [0.4134, 0.5227, 0.3040, 0.4572, 0.4267, 0.3242, 0.3650, 0.2026, 0.4553],\n",
      "        [0.5471, 0.4107, 0.2711, 0.3091, 0.5721, 0.5782, 0.3607, 0.6836, 0.3581],\n",
      "        [0.4005, 0.4116, 0.4998, 0.4794, 0.6433, 0.2437, 0.5924, 0.4927, 0.3413]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3983, 0.5034, 0.1965, 0.5655, 0.6209, 0.1785, 0.6543, 0.3144, 0.6187],\n",
      "        [0.4199, 0.4555, 0.2781, 0.5772, 0.8309, 0.2046, 0.7302, 0.6509, 0.6774],\n",
      "        [0.5808, 0.8237, 0.7162, 0.4890, 0.3194, 0.3916, 0.3068, 0.6136, 0.4300],\n",
      "        [0.4397, 0.6698, 0.4605, 0.6794, 0.5667, 0.4879, 0.5705, 0.5227, 0.2406]])\n",
      "batch_labels:  tensor([1., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4206, 0.5084, 0.1817, 0.3335, 0.8167, 0.3813, 0.3108, 0.4383, 0.7467],\n",
      "        [0.5106, 0.4952, 0.1390, 0.4502, 0.7544, 0.2007, 0.5565, 0.4890, 0.5614],\n",
      "        [0.5507, 0.7603, 0.3666, 0.4236, 0.4549, 0.3979, 0.2996, 0.5469, 0.6137],\n",
      "        [0.4856, 0.5444, 0.1784, 0.5436, 0.5550, 0.5795, 0.5633, 0.5170, 0.3050]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5753, 0.5428, 0.2731, 0.4787, 0.5869, 0.6416, 0.5104, 0.5561, 0.2676],\n",
      "        [0.5127, 0.5869, 0.3322, 0.5349, 0.6533, 0.3318, 0.4823, 0.3876, 0.4315],\n",
      "        [0.4242, 0.5226, 0.1603, 0.6814, 0.5581, 0.4510, 0.4121, 0.5661, 0.6868],\n",
      "        [0.8727, 0.5900, 0.1958, 0.6028, 0.7013, 0.2647, 0.3049, 0.5654, 0.4130]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4283, 0.6888, 0.1512, 0.3706, 0.6818, 0.3015, 0.5892, 0.3386, 0.6944],\n",
      "        [0.3426, 0.3976, 0.4038, 0.2593, 0.6012, 0.2629, 0.4465, 0.6582, 0.4624],\n",
      "        [0.3995, 0.4121, 0.2490, 0.3365, 0.6822, 0.4895, 0.5734, 0.4296, 0.7236],\n",
      "        [0.4616, 0.5029, 0.2900, 0.4502, 0.5521, 0.1869, 0.4153, 0.6680, 0.4896]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4180, 0.3193, 0.3531, 0.5396, 0.4150, 0.5015, 0.6376, 0.7839, 0.4587],\n",
      "        [0.5244, 0.4903, 0.5685, 0.4001, 0.5912, 0.6728, 0.6394, 0.4230, 0.5789],\n",
      "        [0.5942, 0.6618, 0.4849, 0.3656, 0.6633, 0.5753, 0.4951, 0.4076, 0.3028],\n",
      "        [0.5210, 0.4491, 0.3372, 0.5318, 0.4742, 0.2503, 0.3344, 0.6458, 0.9468]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.2496, 0.5233, 0.4946, 0.3656, 0.5710, 0.1623, 0.6156, 0.5764, 0.3699],\n",
      "        [0.7376, 0.5225, 0.3144, 0.3796, 0.5965, 0.2441, 0.4886, 0.4642, 0.6881],\n",
      "        [0.4851, 0.4571, 0.2963, 0.4272, 0.6316, 0.4218, 0.3875, 0.5960, 0.6430],\n",
      "        [0.4657, 0.5806, 0.2878, 0.4475, 0.4993, 0.5537, 0.3942, 0.0818, 0.6459]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4129, 0.4176, 0.2087, 0.5946, 0.6218, 0.3251, 0.4165, 0.4905, 0.5102],\n",
      "        [0.5746, 0.5614, 0.4471, 0.5964, 0.7279, 0.2179, 0.3742, 0.6647, 0.5326],\n",
      "        [0.5191, 0.4163, 0.2674, 0.4051, 0.6875, 0.6848, 0.3917, 0.6030, 0.6109],\n",
      "        [0.3888, 0.4053, 0.4129, 0.5641, 0.6689, 0.4540, 0.5753, 0.7491, 0.5150]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5024, 0.5047, 0.2954, 0.4686, 0.5429, 0.5773, 0.4295, 0.5046, 0.5106],\n",
      "        [0.4728, 0.3403, 0.5453, 0.4390, 0.6652, 0.4054, 0.3811, 0.5353, 0.7462],\n",
      "        [0.4306, 0.4205, 0.4638, 0.7141, 0.6218, 0.4569, 0.4456, 0.4547, 0.7197],\n",
      "        [0.3890, 0.2871, 0.3901, 0.6699, 0.6800, 0.4269, 0.3779, 0.3799, 0.5349]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5627, 0.7070, 0.5670, 0.7025, 0.7686, 0.4931, 0.3841, 0.1320, 0.4167],\n",
      "        [0.4634, 0.5862, 0.3141, 0.5397, 0.6172, 0.4794, 0.3736, 0.2831, 0.4240],\n",
      "        [0.7689, 0.2788, 0.4214, 0.5599, 0.7397, 0.2900, 0.5123, 0.4210, 0.4244],\n",
      "        [0.3329, 0.3156, 0.4847, 0.5265, 0.4744, 0.5799, 0.5682, 0.3094, 0.2797]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3715, 0.5122, 0.2345, 0.4404, 0.5671, 0.7064, 0.4791, 0.4576, 0.5262],\n",
      "        [0.6199, 0.5633, 0.2788, 0.5668, 0.5675, 0.2219, 0.4002, 0.4437, 0.8605],\n",
      "        [0.6178, 0.4970, 0.4266, 0.6360, 0.5681, 0.2393, 0.5771, 0.5083, 0.4663],\n",
      "        [0.3765, 0.6278, 0.8045, 0.4839, 0.5074, 0.3960, 0.7958, 0.4356, 0.5236]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4122, 0.5035, 0.3397, 0.5326, 0.5661, 0.2219, 0.6573, 0.5942, 0.4698],\n",
      "        [0.7261, 0.6251, 0.1642, 0.3842, 0.5255, 0.3098, 0.5274, 0.4564, 0.6613],\n",
      "        [0.4734, 0.7256, 0.4312, 0.0858, 0.6512, 0.2496, 0.5304, 0.4454, 0.3821],\n",
      "        [0.3603, 0.4009, 0.2131, 0.8006, 0.4892, 0.5436, 0.4065, 0.3976, 0.6792]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.3902, 0.4514, 0.3577, 0.7126, 0.5892, 0.3022, 0.3586, 0.5046, 0.5772],\n",
      "        [0.4846, 0.3741, 0.3582, 0.3215, 0.6037, 0.4836, 0.3290, 0.4949, 0.5150],\n",
      "        [0.2505, 0.4109, 0.3963, 0.9596, 0.4549, 0.7216, 0.2494, 0.3559, 0.7952],\n",
      "        [0.4745, 0.6503, 0.4778, 0.5533, 0.6291, 0.4781, 0.4702, 0.4872, 0.6872]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4821, 0.4477, 0.3548, 0.4666, 0.5733, 0.3964, 0.6350, 0.4461, 0.6714],\n",
      "        [0.4885, 0.3538, 0.3841, 0.2644, 0.5916, 0.5093, 0.3412, 0.6081, 0.3409],\n",
      "        [0.5439, 0.5024, 0.2425, 0.4724, 0.6154, 0.4016, 0.5900, 0.6997, 0.2844],\n",
      "        [0.2806, 0.3006, 0.4261, 0.4997, 0.4366, 0.5087, 0.3391, 0.5328, 0.8925]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3086, 0.6676, 0.4722, 0.2941, 0.2241, 0.4628, 0.5654, 0.5671, 0.5704],\n",
      "        [0.4836, 0.6156, 0.5140, 0.7774, 0.3546, 0.3353, 0.3673, 0.5141, 0.6173],\n",
      "        [0.3714, 0.5666, 0.7984, 0.4483, 0.4283, 0.5154, 0.7047, 0.5369, 0.5531],\n",
      "        [0.4377, 0.3287, 0.4272, 0.5812, 0.6771, 0.1693, 0.4154, 0.7164, 0.3363]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.6567, 0.8224, 0.6866, 0.5671, 0.3269, 0.5492, 0.5555, 0.4656, 0.4162],\n",
      "        [0.6322, 0.5942, 0.4176, 0.4281, 0.5563, 0.3831, 0.4535, 0.4765, 0.7371],\n",
      "        [0.4946, 0.4353, 0.5075, 0.3029, 0.7411, 0.7101, 0.3982, 0.4313, 0.5780],\n",
      "        [0.4846, 0.3321, 0.3700, 0.5571, 0.7016, 0.4506, 0.5016, 0.5436, 0.4295]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5675, 0.3945, 0.1527, 0.5493, 0.5680, 0.4155, 0.4057, 0.5870, 0.3390],\n",
      "        [0.7202, 0.6917, 0.4331, 0.2908, 0.6195, 0.2662, 0.6214, 0.5582, 0.6009],\n",
      "        [0.5579, 0.4795, 0.2874, 0.3462, 0.7536, 0.1678, 0.6232, 0.6397, 0.4830],\n",
      "        [0.4047, 0.5266, 0.2672, 0.4661, 0.5679, 0.1440, 0.7100, 0.4056, 0.5898]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3882, 0.4907, 0.3067, 0.6671, 0.6738, 0.6107, 0.4737, 0.5074, 0.7339],\n",
      "        [0.4025, 0.3345, 0.4378, 0.4380, 0.4773, 0.2031, 0.3832, 0.6681, 0.6420],\n",
      "        [0.4764, 0.4451, 0.4512, 0.4728, 0.6344, 0.3956, 0.3884, 0.5446, 0.5562],\n",
      "        [0.2906, 0.5503, 0.3720, 0.4647, 0.4979, 0.5199, 0.4551, 0.4915, 0.4526]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4704, 0.6538, 0.4907, 0.5530, 0.5912, 0.4379, 0.4968, 0.4812, 0.5792],\n",
      "        [0.4630, 0.5472, 0.2542, 0.4313, 0.5319, 0.6896, 0.4161, 0.5224, 0.3873],\n",
      "        [0.5329, 0.5409, 0.5431, 0.5475, 0.6396, 0.3510, 0.3989, 0.4782, 0.3618],\n",
      "        [0.6269, 0.2384, 0.3047, 0.5324, 0.5998, 0.3586, 0.5850, 0.3900, 0.6948]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4522, 0.4232, 0.4299, 0.3720, 0.5278, 0.5002, 0.5662, 0.4258, 0.1672],\n",
      "        [0.4554, 0.4112, 0.4169, 0.6491, 0.5714, 0.7104, 0.4751, 0.4775, 0.5760],\n",
      "        [0.5031, 0.5106, 0.4754, 0.4553, 0.6554, 0.4474, 0.4157, 0.3528, 0.2990],\n",
      "        [0.4491, 0.5367, 0.5700, 0.3249, 0.6156, 0.3400, 0.3606, 0.7159, 0.7065]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4669, 0.5415, 0.3298, 0.4553, 0.6658, 0.6421, 0.2341, 0.5056, 0.4795],\n",
      "        [0.4480, 0.7237, 0.3870, 0.2984, 0.7002, 0.2404, 0.4817, 0.7663, 0.4973],\n",
      "        [0.4330, 0.6473, 0.5245, 0.2548, 0.3389, 0.5208, 0.4363, 0.3941, 0.3697],\n",
      "        [0.4158, 0.4633, 0.5683, 0.6006, 0.6213, 0.3887, 0.5014, 0.5227, 0.5197]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5569, 0.5090, 0.1618, 0.7003, 0.7706, 0.1254, 0.3669, 0.3866, 0.6818],\n",
      "        [0.3605, 0.5643, 0.2590, 0.4983, 0.5514, 0.3391, 0.6281, 0.6492, 0.4777],\n",
      "        [0.4019, 0.4567, 0.3888, 0.4185, 0.6215, 0.4492, 0.4334, 0.4961, 0.2887],\n",
      "        [0.4861, 0.4606, 0.2557, 0.7239, 0.6024, 0.6510, 0.8170, 0.4836, 0.2829]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.7325, 0.5896, 0.1844, 0.1751, 0.7634, 0.5267, 0.4278, 0.5519, 0.3880],\n",
      "        [0.4706, 0.6272, 0.1410, 0.5369, 0.4571, 0.1507, 0.3898, 0.3751, 0.5202],\n",
      "        [0.4436, 0.4601, 0.4559, 0.5801, 0.5477, 0.5245, 0.3413, 0.3723, 0.6167],\n",
      "        [0.4992, 0.7222, 0.0731, 0.5812, 0.4661, 0.1211, 0.6540, 0.5189, 0.5882]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4755, 0.4755, 0.3444, 0.5961, 0.7001, 0.3965, 0.5092, 0.4546, 0.3711],\n",
      "        [0.5736, 0.5314, 0.2298, 0.4192, 0.6627, 0.3772, 0.6481, 0.6095, 0.5539],\n",
      "        [0.3302, 0.6500, 0.2432, 0.6843, 0.7392, 0.5881, 0.6050, 0.5663, 0.3515],\n",
      "        [0.6038, 0.4528, 0.5825, 0.1138, 0.6521, 0.7792, 0.6100, 0.5164, 0.2771]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4477, 0.4607, 0.3015, 0.5061, 0.5713, 0.2262, 0.3810, 0.3384, 0.4350],\n",
      "        [0.4834, 0.2663, 0.2594, 0.7068, 0.5401, 0.1546, 0.4831, 0.3984, 0.6213],\n",
      "        [0.6895, 0.4815, 0.1559, 0.7124, 0.6488, 0.4376, 0.4478, 0.4700, 0.5198],\n",
      "        [0.4844, 0.5583, 0.2689, 0.4681, 0.4675, 0.3538, 0.5431, 0.5027, 0.4437]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.6268, 0.4965, 0.3545, 0.4370, 0.5776, 0.4977, 0.6325, 0.3841, 0.6195],\n",
      "        [0.4937, 0.4607, 0.5489, 0.5312, 0.5631, 0.3572, 0.6958, 0.6248, 0.3851],\n",
      "        [0.2993, 0.3446, 0.4278, 0.3900, 0.4490, 0.4187, 0.3413, 0.3094, 0.5932],\n",
      "        [0.4776, 0.6172, 0.3004, 0.4875, 0.6968, 0.2594, 0.5344, 0.4468, 0.6734]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.2954, 0.8393, 0.3445, 0.3037, 0.8114, 0.2328, 0.3666, 0.5379, 0.5379],\n",
      "        [0.3583, 0.4353, 0.3266, 0.3242, 0.7724, 0.5142, 0.4781, 0.5826, 0.5689],\n",
      "        [0.5194, 0.4709, 0.2136, 0.3496, 0.6086, 0.4961, 0.6299, 0.2578, 0.5734],\n",
      "        [0.4292, 0.3483, 0.3527, 0.4619, 0.6341, 0.3122, 0.4522, 0.6251, 0.6397]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.6260, 0.4734, 0.5646, 1.0000, 0.1517, 0.5042, 0.3979, 0.5986, 0.5084],\n",
      "        [0.5268, 0.4618, 0.3436, 0.5778, 0.6823, 0.4959, 0.4002, 0.8368, 0.5243],\n",
      "        [0.4408, 0.5771, 0.3686, 0.5000, 0.5761, 0.4213, 0.5511, 0.4875, 0.0457],\n",
      "        [0.3567, 0.5572, 0.3754, 0.2578, 0.2885, 0.3213, 0.0000, 0.6772, 0.5436]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.3681, 0.6012, 0.6982, 0.6682, 0.5495, 0.3476, 0.3379, 0.4351, 0.4893],\n",
      "        [0.6485, 0.4641, 0.2755, 0.5760, 0.5818, 0.4062, 0.4024, 0.9014, 0.6096],\n",
      "        [0.4645, 0.4042, 0.2592, 0.4847, 0.5950, 0.3701, 0.5424, 0.4330, 0.5716],\n",
      "        [0.4082, 0.6416, 0.4827, 0.4417, 0.4205, 0.7155, 0.5123, 0.5117, 0.4349]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3743, 0.6829, 0.3181, 0.3546, 0.7633, 0.6341, 0.4281, 0.6169, 0.5398],\n",
      "        [0.8148, 0.4641, 0.2143, 0.4835, 0.5478, 0.5480, 0.5677, 0.5941, 0.7368],\n",
      "        [0.6184, 0.5096, 0.7215, 0.4242, 0.5161, 0.2259, 0.4153, 0.5012, 0.5291],\n",
      "        [0.4081, 0.5616, 0.5835, 0.4009, 0.5209, 0.5090, 0.3875, 0.4623, 0.6788]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5480, 0.5875, 0.3916, 0.5587, 0.7273, 0.1567, 0.4812, 0.5223, 0.4839],\n",
      "        [0.3250, 0.3955, 0.1194, 0.6472, 0.5364, 0.1594, 0.2366, 0.4773, 0.5330],\n",
      "        [0.3609, 0.4086, 0.1933, 0.3837, 0.6085, 0.3416, 0.4822, 0.4926, 0.4673],\n",
      "        [0.4933, 0.5319, 0.2142, 0.4648, 0.7153, 0.4242, 0.4961, 0.5168, 0.4769]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4850, 0.5876, 0.3502, 0.5037, 0.5997, 0.2806, 0.2989, 0.4552, 0.1338],\n",
      "        [0.4168, 0.4658, 0.5435, 0.5019, 0.5967, 0.2217, 0.4213, 0.5519, 0.4885],\n",
      "        [0.7067, 0.3955, 0.2762, 0.4902, 0.4908, 0.3394, 0.4581, 0.5460, 0.3934],\n",
      "        [0.5611, 0.7009, 0.5712, 0.1642, 0.5075, 0.4210, 0.5666, 0.5121, 0.4967]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.6592, 0.3709, 0.6975, 0.4707, 0.5592, 0.2611, 0.4238, 0.4669, 0.6016],\n",
      "        [0.2841, 0.7386, 0.7176, 0.5422, 0.3877, 0.4185, 0.6823, 0.4587, 0.3405],\n",
      "        [0.4255, 0.3641, 0.4139, 0.5375, 0.6927, 0.3378, 0.4621, 0.5778, 0.5398],\n",
      "        [0.4185, 0.4644, 0.5053, 0.3861, 0.5938, 0.4143, 0.6234, 0.5198, 0.6124]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.7008, 0.5553, 0.2555, 0.4132, 0.6756, 0.4363, 0.7025, 0.5046, 0.5489],\n",
      "        [0.5542, 0.4452, 0.6101, 0.4087, 0.4495, 0.1515, 0.4904, 0.5745, 0.4063],\n",
      "        [0.3417, 0.3637, 0.4887, 0.5425, 0.5367, 0.5287, 0.4862, 0.5940, 0.0000],\n",
      "        [0.7601, 0.6027, 0.1825, 0.4372, 0.4743, 0.3854, 0.5069, 0.4346, 0.5362]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5838, 0.3904, 0.2290, 0.4254, 0.4809, 0.1680, 0.4098, 0.6119, 0.5858],\n",
      "        [0.4807, 0.6621, 0.4297, 0.3583, 0.5848, 0.2464, 0.2949, 0.5954, 0.6881],\n",
      "        [0.4736, 0.5486, 0.4152, 0.5368, 0.4681, 0.4442, 0.1532, 0.1934, 0.2632],\n",
      "        [0.4303, 0.6711, 0.3869, 0.5709, 0.5035, 0.5138, 0.5996, 0.4291, 0.5115]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4848, 0.1533, 0.5815, 0.1048, 0.6800, 0.3908, 0.3998, 0.2159, 0.7154],\n",
      "        [0.5133, 0.5092, 0.3955, 0.6729, 0.5524, 0.2745, 0.1548, 0.6408, 0.6401],\n",
      "        [0.4488, 0.5152, 0.5010, 0.2746, 0.5736, 0.4481, 0.3812, 0.5336, 0.2982],\n",
      "        [0.6553, 0.3877, 0.8894, 0.3846, 0.8137, 0.3596, 0.3930, 0.4651, 0.3668]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5619, 0.4628, 0.3760, 0.5489, 0.7521, 0.4708, 0.4722, 0.6718, 0.7266],\n",
      "        [0.6760, 0.5211, 0.3511, 0.4846, 0.4969, 0.2428, 0.5819, 0.5435, 0.3121],\n",
      "        [0.3276, 0.4231, 0.4228, 0.2235, 0.6784, 0.1570, 0.4436, 0.6004, 0.7965],\n",
      "        [0.5126, 0.5996, 0.3163, 0.3936, 0.4214, 0.3715, 0.5618, 0.3907, 0.4072]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5370, 0.3975, 0.6400, 0.3962, 0.4892, 0.3677, 0.4150, 0.6183, 0.6571],\n",
      "        [0.5455, 0.4472, 0.3453, 0.6359, 0.7197, 0.5210, 0.2688, 0.4271, 0.4146],\n",
      "        [0.4559, 0.6840, 0.5201, 0.4588, 0.6043, 0.1153, 0.4584, 0.7329, 0.6041],\n",
      "        [0.6212, 0.5185, 0.3410, 0.5133, 0.5418, 0.2235, 0.5689, 0.5718, 0.4006]])\n",
      "batch_labels:  tensor([1., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.7503, 0.4445, 0.3821, 0.4772, 0.6005, 0.4621, 0.5758, 0.2224, 0.4985],\n",
      "        [0.4495, 0.4586, 0.5882, 0.3564, 0.6980, 0.5586, 0.6308, 0.8208, 0.5147],\n",
      "        [0.4261, 0.5190, 0.2864, 0.4261, 0.6733, 0.4401, 0.5575, 0.5521, 0.5653],\n",
      "        [0.4436, 0.1349, 0.2715, 0.4653, 0.8880, 0.3241, 0.1217, 0.3479, 0.5762]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4502, 0.3829, 0.2118, 0.5373, 0.7024, 0.2739, 0.7228, 0.5039, 0.2883],\n",
      "        [0.7410, 0.1817, 0.3918, 0.5769, 0.5076, 0.3831, 0.4310, 0.4952, 0.7151],\n",
      "        [0.4821, 0.4542, 0.2518, 0.4574, 0.6882, 0.5367, 0.5072, 0.5619, 0.4032],\n",
      "        [0.6729, 0.4609, 0.3163, 0.5229, 0.7379, 0.3767, 0.4111, 0.4746, 0.5389]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5152, 0.4537, 0.3690, 0.4646, 0.5632, 0.3224, 0.2473, 0.7081, 0.6836],\n",
      "        [0.5884, 0.5147, 0.5092, 0.5151, 0.4980, 0.4125, 0.5044, 0.6502, 0.1899],\n",
      "        [0.3916, 0.6076, 0.1923, 0.6321, 0.5280, 0.2261, 0.6898, 0.6567, 0.3946],\n",
      "        [0.5420, 0.6042, 0.4694, 0.5875, 0.4856, 0.6578, 0.4701, 0.5929, 0.6090]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.6735, 0.4187, 0.0738, 0.4282, 0.6870, 0.3710, 0.4658, 0.4233, 0.5525],\n",
      "        [0.6973, 0.7798, 0.2319, 0.4410, 0.4737, 0.4727, 0.3951, 0.5843, 0.3691],\n",
      "        [0.5436, 0.4847, 0.3466, 0.5509, 0.6003, 0.3196, 0.6739, 0.4342, 0.5897],\n",
      "        [0.2634, 0.2375, 0.3439, 0.5421, 0.5010, 0.4620, 0.5912, 0.6320, 0.5630]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5903, 0.3675, 0.6172, 0.5373, 0.5349, 0.3677, 0.2448, 0.5113, 0.5781],\n",
      "        [0.4569, 0.4500, 0.2486, 0.5963, 0.6934, 0.5325, 0.3805, 0.4339, 0.3612],\n",
      "        [0.4145, 0.6128, 0.3159, 0.7321, 0.8315, 0.2209, 0.4877, 0.3751, 0.4936],\n",
      "        [0.5694, 0.4819, 0.2908, 0.5664, 0.6294, 0.3926, 0.4069, 0.3503, 0.3115]])\n",
      "batch_labels:  tensor([1., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4414, 0.6048, 0.3934, 0.4910, 0.4402, 0.2706, 0.7120, 0.4614, 0.6282],\n",
      "        [0.3199, 0.5553, 0.5161, 0.4034, 0.4972, 0.4615, 0.3474, 0.8884, 0.6545],\n",
      "        [0.5696, 0.5609, 0.2942, 0.6308, 0.6548, 0.6481, 0.6072, 0.5212, 0.7200],\n",
      "        [0.5173, 0.5529, 0.2385, 0.5818, 0.6359, 0.2452, 0.7517, 0.5273, 0.8751]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4438, 0.3852, 0.2856, 0.5713, 0.5210, 0.3097, 0.7936, 0.7147, 0.3778],\n",
      "        [0.4477, 0.5872, 0.3383, 0.3848, 0.4380, 0.2838, 0.5153, 0.2860, 0.5890],\n",
      "        [0.5682, 0.5147, 0.1550, 0.4965, 0.5948, 0.2298, 0.2799, 0.2961, 0.4331],\n",
      "        [0.6731, 0.2091, 0.5939, 0.2917, 0.8470, 0.5956, 0.7164, 0.3572, 0.7517]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5206, 0.4566, 0.3468, 0.5991, 0.7334, 0.4111, 0.4411, 0.4658, 0.4950],\n",
      "        [0.5515, 0.5542, 0.3915, 0.3800, 0.7929, 0.5459, 0.5618, 0.4489, 0.4728],\n",
      "        [0.4765, 0.5077, 0.3954, 0.3217, 0.7698, 0.4003, 0.5529, 0.3410, 0.6070],\n",
      "        [0.5982, 0.6179, 0.3953, 0.4497, 0.4487, 0.2328, 0.6266, 0.5999, 0.4949]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4641, 0.3167, 0.1970, 0.4615, 0.6867, 0.4165, 0.2221, 0.5636, 0.5227],\n",
      "        [0.5857, 0.5441, 0.6213, 0.4303, 0.6194, 0.3586, 0.5589, 0.6184, 0.4965],\n",
      "        [0.6168, 0.5449, 0.5036, 0.4205, 0.7056, 0.5534, 0.4577, 0.2929, 0.2190],\n",
      "        [0.7291, 0.6216, 0.2559, 0.4543, 0.4879, 0.2755, 0.4577, 0.4803, 0.7433]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5131, 0.4851, 0.7344, 0.3340, 0.5463, 0.2553, 0.4673, 0.3976, 0.3740],\n",
      "        [0.5441, 0.5534, 0.3014, 0.5363, 0.4471, 0.1222, 0.3853, 0.4185, 0.3516],\n",
      "        [0.5365, 0.5779, 0.5252, 0.4361, 0.4811, 0.5317, 0.4479, 0.5326, 0.4659],\n",
      "        [0.5365, 0.6951, 0.3091, 0.1248, 0.4812, 0.6314, 0.3171, 0.5886, 0.5649]])\n",
      "batch_labels:  tensor([0., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.7232, 0.8738, 0.1208, 0.7200, 0.5474, 0.4282, 0.4302, 0.6078, 0.6314],\n",
      "        [0.5272, 0.4259, 0.4356, 0.6154, 0.6824, 0.3376, 0.4817, 0.3499, 0.4012],\n",
      "        [0.6765, 0.5682, 0.4428, 0.4101, 0.5328, 0.5377, 0.7196, 0.3840, 0.7005],\n",
      "        [0.5793, 0.2965, 0.3144, 0.4422, 0.6545, 0.3965, 0.5505, 0.7982, 0.4539]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5522, 0.7211, 0.2328, 0.5923, 0.7503, 0.4386, 0.3541, 0.5897, 0.5592],\n",
      "        [0.3592, 0.5414, 0.2234, 0.4864, 0.6723, 0.5430, 0.7401, 0.5939, 0.3955],\n",
      "        [0.6673, 0.4107, 0.1506, 0.6020, 0.6513, 0.7163, 0.5880, 0.8377, 0.6253],\n",
      "        [0.7740, 0.8629, 0.2645, 0.2783, 0.5828, 0.3969, 0.4234, 0.5504, 0.5063]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.7024, 0.5150, 0.2833, 0.5756, 0.7133, 0.2599, 0.7331, 0.5615, 0.1873],\n",
      "        [0.4671, 0.3887, 0.5452, 0.3807, 0.5168, 0.5837, 0.6323, 0.5932, 0.4559],\n",
      "        [0.4268, 0.6877, 0.2353, 0.3941, 0.5863, 0.2937, 0.4538, 0.4535, 0.5316],\n",
      "        [0.4724, 0.5088, 0.4827, 0.3957, 0.4969, 0.3554, 0.6931, 0.3980, 0.3425]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4818, 0.4552, 0.2004, 0.4055, 0.6679, 0.6440, 0.2841, 0.2224, 0.7718],\n",
      "        [0.6693, 0.2966, 0.2287, 0.6862, 0.5158, 0.7088, 0.2583, 0.5978, 0.4807],\n",
      "        [0.5362, 0.4805, 0.1570, 0.3266, 0.5698, 0.6812, 0.6051, 0.4917, 1.0000],\n",
      "        [0.6371, 0.7793, 0.2681, 0.4331, 0.6420, 0.6526, 0.8000, 0.4586, 0.5009]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.6545, 0.2232, 0.6987, 0.6365, 0.4346, 0.5179, 0.2957, 0.4933, 0.6480],\n",
      "        [0.5402, 0.3685, 0.4400, 0.5852, 0.5698, 0.4173, 0.5595, 0.6976, 0.6280],\n",
      "        [0.3908, 0.5849, 0.2582, 0.4781, 0.6426, 0.2329, 0.3055, 0.2831, 0.3518],\n",
      "        [0.4583, 0.5788, 0.3723, 0.4341, 0.5908, 0.5999, 0.6476, 0.7133, 0.6100]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4367, 0.4856, 0.4955, 0.4891, 0.5406, 0.4470, 0.6922, 0.4537, 0.6063],\n",
      "        [0.5822, 0.5160, 0.2419, 0.6798, 0.7870, 0.4026, 0.5080, 0.7685, 0.5304],\n",
      "        [0.3733, 0.7266, 0.2787, 0.4282, 0.4208, 0.2414, 0.5436, 0.3072, 0.4535],\n",
      "        [0.5427, 0.4866, 0.3170, 0.6615, 0.6681, 0.8068, 0.4908, 0.7100, 0.5812]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.6259, 0.4807, 0.2027, 0.4493, 0.7147, 0.3350, 0.5692, 0.6681, 0.5339],\n",
      "        [0.6851, 0.6561, 0.2295, 0.7463, 0.4661, 0.2268, 0.3322, 0.4668, 0.6525],\n",
      "        [0.6410, 0.5043, 0.3544, 0.3790, 0.4824, 0.2551, 0.4279, 0.6559, 0.7943],\n",
      "        [0.7649, 0.0337, 0.4572, 0.6038, 0.5381, 0.3463, 0.4239, 0.3783, 0.6367]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.6744, 0.5150, 0.1560, 0.3907, 0.6767, 0.5434, 0.4304, 0.4089, 0.4684],\n",
      "        [0.4721, 0.4663, 0.4639, 0.6021, 0.5933, 0.5208, 0.6244, 0.5939, 0.6232],\n",
      "        [0.3746, 0.5471, 0.3578, 0.5046, 0.6459, 0.5864, 0.3232, 0.5324, 0.5691],\n",
      "        [0.5614, 0.4019, 0.4149, 0.6942, 0.3721, 0.2284, 0.5610, 0.8592, 0.6438]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.6291, 0.4568, 0.7385, 0.1720, 0.5910, 0.4703, 0.4642, 0.2902, 0.6091],\n",
      "        [0.6141, 0.3594, 0.7207, 0.3401, 0.5015, 0.5395, 0.5549, 0.5834, 0.4812],\n",
      "        [0.7073, 0.6706, 0.4740, 0.3577, 0.5833, 0.3218, 0.4357, 0.6724, 0.4348],\n",
      "        [0.5438, 0.5667, 0.3753, 0.4769, 0.3975, 0.5334, 0.3725, 0.6626, 0.6974]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_imputs:  tensor([[0.5067, 0.1921, 0.4328, 0.4100, 0.4567, 0.3930, 0.4613, 0.4779, 0.4480],\n",
      "        [0.5824, 0.5243, 0.4378, 0.5527, 0.7388, 0.3880, 0.4290, 0.3750, 0.4144],\n",
      "        [0.5869, 0.5256, 0.4084, 0.6778, 0.5803, 0.1644, 0.3961, 0.4771, 0.4050],\n",
      "        [0.2087, 0.5126, 0.7981, 0.5479, 0.5558, 0.4089, 0.5374, 0.3985, 0.5547]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5765, 0.5225, 0.4775, 0.5003, 0.6112, 0.5872, 0.5620, 0.4995, 0.5628],\n",
      "        [0.5258, 0.6843, 0.6477, 0.2680, 0.5972, 0.4560, 0.5606, 0.5144, 0.3834],\n",
      "        [0.5655, 0.4370, 0.2103, 0.4148, 0.5144, 0.8429, 0.6232, 0.5026, 0.3430],\n",
      "        [0.4936, 0.5409, 0.3839, 0.5015, 0.4992, 0.4364, 0.5500, 0.4939, 0.2957]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3631, 0.4846, 0.4368, 0.4793, 0.5916, 0.2569, 0.5532, 0.5955, 0.3447],\n",
      "        [0.4126, 0.8581, 0.2657, 0.4470, 0.6658, 0.8949, 0.4409, 0.7037, 0.4383],\n",
      "        [0.2466, 0.3420, 0.4703, 0.3095, 0.7379, 0.3392, 0.6045, 0.4764, 0.7771],\n",
      "        [0.4531, 0.6693, 0.1306, 0.7200, 0.2428, 0.2804, 0.4923, 0.3991, 0.2797]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4630, 0.5720, 0.4138, 0.4446, 0.5578, 0.4145, 0.4899, 0.2151, 0.5965],\n",
      "        [0.4458, 0.4523, 0.2012, 0.3957, 0.6103, 0.2921, 0.5822, 0.5604, 0.2309],\n",
      "        [0.5195, 0.5330, 0.0187, 0.8298, 0.9850, 0.2895, 0.5784, 0.4033, 0.3743],\n",
      "        [0.4563, 0.4445, 0.5130, 0.5364, 0.6157, 0.4961, 0.4080, 0.3800, 0.6741]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4393, 0.3120, 0.2747, 0.5851, 0.5355, 0.7319, 0.5248, 0.6422, 0.7543],\n",
      "        [0.4732, 0.5356, 0.3542, 0.4034, 0.4986, 0.6212, 0.3956, 0.5548, 0.6776],\n",
      "        [0.5763, 0.4992, 0.4824, 0.3427, 0.2918, 0.5946, 0.4122, 0.5321, 0.4407],\n",
      "        [0.3907, 0.8136, 0.7720, 0.2357, 0.6757, 0.4518, 0.5741, 0.4563, 0.4614]])\n",
      "batch_labels:  tensor([1., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.3889, 0.5342, 0.5284, 0.4961, 0.5160, 0.2990, 0.4831, 0.4965, 0.4763],\n",
      "        [0.3394, 0.5789, 0.4978, 0.7264, 0.5912, 0.3143, 0.5363, 0.4593, 0.4062],\n",
      "        [0.5523, 0.5318, 0.1932, 0.4137, 0.7553, 0.2476, 0.5675, 0.3410, 0.5559],\n",
      "        [0.6706, 0.6230, 0.2119, 0.1355, 0.7332, 0.5149, 0.4436, 0.4654, 0.2776]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4099, 0.4589, 0.2497, 0.7072, 0.5811, 0.3761, 0.5056, 0.4818, 0.4541],\n",
      "        [0.4389, 0.4786, 0.2550, 0.7109, 0.7671, 0.4476, 0.5788, 0.5706, 0.6269],\n",
      "        [0.3827, 0.4402, 0.3778, 0.4530, 0.6342, 0.3949, 0.4428, 0.5227, 0.3221],\n",
      "        [0.6928, 0.7824, 0.1451, 0.5929, 0.6541, 0.2747, 0.5179, 0.3818, 0.6317]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5864, 0.6517, 0.2889, 0.4220, 0.4888, 0.3511, 0.4672, 0.6068, 0.4842],\n",
      "        [0.6497, 0.8534, 0.8463, 0.5913, 0.5277, 0.4000, 0.3132, 0.4808, 0.2993],\n",
      "        [0.4425, 0.5486, 0.1462, 0.3917, 0.4474, 0.5259, 0.3365, 0.5712, 0.6049],\n",
      "        [0.6022, 0.6760, 0.5067, 0.5872, 0.7177, 0.5070, 0.1538, 0.2644, 0.4937]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3346, 0.2576, 0.4043, 0.3553, 0.6532, 0.6631, 0.3751, 0.4522, 0.4329],\n",
      "        [0.5142, 0.7027, 0.3909, 0.5389, 0.6819, 0.4996, 0.4142, 0.4525, 0.4475],\n",
      "        [0.3494, 0.3319, 0.4043, 0.5427, 0.8345, 0.5233, 0.6260, 0.5279, 0.6769],\n",
      "        [0.4487, 0.4486, 0.3121, 0.5174, 0.5780, 0.3574, 0.6088, 0.4808, 0.6193]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.6486, 0.6885, 0.4958, 0.4626, 0.3794, 0.6648, 0.2387, 0.3438, 0.4148],\n",
      "        [0.3817, 0.5056, 0.3393, 0.3078, 0.4732, 0.2660, 0.6657, 0.5877, 0.5925],\n",
      "        [0.5111, 0.1024, 0.6439, 0.4898, 0.8357, 0.5460, 0.2080, 0.5867, 0.6943],\n",
      "        [0.5068, 0.4198, 0.6317, 0.5688, 0.5429, 0.4838, 0.5629, 0.5421, 0.4584]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5400, 0.6155, 0.3550, 0.5108, 0.6311, 0.5590, 0.4840, 0.5598, 0.7992],\n",
      "        [0.2932, 0.5167, 0.4507, 0.3855, 0.3729, 0.1793, 0.4031, 0.4104, 0.6840],\n",
      "        [0.5261, 0.6142, 0.3492, 0.3731, 0.5361, 0.7045, 0.4578, 0.7007, 0.4812],\n",
      "        [0.5831, 0.5533, 0.3523, 0.4124, 0.3033, 0.5917, 0.4922, 0.5753, 0.6103]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4435, 0.3715, 0.4678, 0.5104, 0.5949, 0.7349, 0.5131, 0.9051, 0.6202],\n",
      "        [0.5613, 0.8335, 0.2998, 0.5496, 0.7625, 0.5670, 0.4970, 0.4504, 0.3966],\n",
      "        [0.5835, 0.5867, 0.4137, 0.3783, 0.5809, 0.4517, 0.2607, 0.2705, 0.3886],\n",
      "        [0.2722, 0.2559, 0.3046, 0.4188, 0.6945, 0.2588, 0.5412, 0.5180, 0.4394]])\n",
      "batch_labels:  tensor([1., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4945, 0.5172, 0.4207, 0.5827, 0.5439, 0.3952, 0.3936, 0.4795, 0.6196],\n",
      "        [0.4858, 0.6145, 0.3123, 0.5628, 0.4841, 0.4120, 0.4044, 0.5221, 0.2461],\n",
      "        [0.6264, 0.6130, 0.3372, 0.3668, 0.7577, 0.4812, 0.3327, 0.5649, 0.3987],\n",
      "        [0.4541, 0.4365, 0.6121, 0.6090, 0.5937, 0.5488, 0.5728, 0.4451, 0.7042]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4375, 0.6245, 0.4202, 0.4795, 0.4965, 0.5129, 0.4528, 0.5096, 0.2523],\n",
      "        [0.4424, 0.5611, 0.2023, 0.4752, 0.5192, 0.3160, 0.3940, 0.4712, 0.6152],\n",
      "        [0.6226, 0.6250, 0.4155, 0.0910, 0.7937, 0.4447, 0.4894, 0.2965, 0.4599],\n",
      "        [0.5235, 0.5520, 0.5025, 0.4353, 0.5966, 0.5821, 0.6013, 0.4915, 0.4515]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3969, 0.4919, 0.3280, 0.4402, 0.5625, 0.4479, 0.4605, 0.4137, 0.5268],\n",
      "        [0.5486, 0.5057, 0.4356, 0.4395, 0.5739, 0.3102, 0.3977, 0.0500, 0.7127],\n",
      "        [0.5052, 0.5232, 0.4436, 0.3260, 0.4396, 0.3306, 0.4123, 0.1261, 0.4392],\n",
      "        [0.3672, 0.4602, 0.4667, 0.4040, 0.5657, 0.6191, 0.6127, 0.3335, 0.6642]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3805, 0.4384, 0.2134, 0.3456, 0.7995, 0.3392, 0.4174, 0.4510, 0.6905],\n",
      "        [0.5054, 0.4538, 0.5484, 0.4249, 0.6361, 0.4906, 0.5082, 0.4625, 0.4627],\n",
      "        [0.4152, 0.4801, 0.2216, 0.6432, 0.5532, 0.5407, 0.4118, 0.3944, 0.6846],\n",
      "        [0.6958, 0.2691, 0.2937, 0.5454, 0.6591, 0.4288, 0.3528, 0.2249, 0.8104]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5252, 0.6729, 0.4434, 0.5016, 0.5328, 0.3191, 0.1497, 0.4632, 0.4954],\n",
      "        [0.3977, 0.1755, 0.5858, 0.4822, 0.4775, 0.5488, 0.2742, 0.3428, 0.5367],\n",
      "        [0.5721, 0.5722, 0.4310, 0.4129, 0.5485, 0.5725, 0.4899, 0.4443, 0.2615],\n",
      "        [0.5481, 0.5825, 0.6868, 0.5431, 0.6058, 0.2679, 0.1582, 0.4961, 0.7881]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.2593, 0.4762, 0.3242, 0.4684, 0.7588, 0.2966, 0.5267, 0.6767, 0.6707],\n",
      "        [0.6039, 0.4426, 0.5538, 0.5252, 0.6289, 0.3485, 0.3244, 0.6424, 0.1721],\n",
      "        [0.3568, 0.1579, 0.1953, 0.3792, 0.7392, 0.2059, 0.4347, 0.6288, 0.6067],\n",
      "        [0.4657, 0.4857, 0.1763, 0.4503, 0.7140, 0.3984, 0.4049, 0.4904, 0.3379]])\n",
      "batch_labels:  tensor([0., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.6657, 0.6203, 0.4541, 0.5113, 0.4903, 0.5477, 0.5917, 0.4366, 0.6256],\n",
      "        [0.7555, 0.5122, 0.2250, 0.4895, 0.5500, 0.5807, 0.5854, 0.5475, 0.4505],\n",
      "        [0.5673, 0.5214, 0.2257, 0.4521, 0.6473, 0.3487, 0.3588, 0.3037, 0.3108],\n",
      "        [0.7132, 0.2434, 0.2000, 0.6101, 0.5525, 0.4371, 0.4505, 0.7243, 0.7302]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4659, 0.3215, 0.1885, 0.2010, 0.3180, 0.4283, 0.5267, 0.4819, 0.4684],\n",
      "        [0.2711, 0.4082, 0.4221, 0.5636, 0.7443, 0.4408, 0.7153, 0.4441, 0.5239],\n",
      "        [0.3550, 0.6240, 0.5447, 0.4104, 0.6893, 0.2814, 0.2368, 0.5962, 0.4930],\n",
      "        [0.4054, 0.3214, 0.4469, 0.5524, 0.5237, 0.5302, 0.5017, 0.5960, 0.3939]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.5977, 0.6242, 0.2734, 0.4277, 0.5265, 0.7878, 0.3392, 0.5492, 0.4079],\n",
      "        [0.7215, 0.4954, 0.5091, 0.5036, 0.5327, 0.1406, 0.6552, 0.4721, 0.2949],\n",
      "        [0.6298, 0.5652, 0.1651, 0.6367, 0.6233, 0.2395, 0.6477, 0.5177, 0.6083],\n",
      "        [0.5448, 0.3919, 0.6772, 0.3952, 0.4782, 0.5877, 0.5592, 0.5747, 0.7363]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4157, 0.2600, 0.4947, 0.5061, 0.7409, 0.4030, 0.5311, 0.5232, 0.6581],\n",
      "        [0.3318, 0.4791, 0.3732, 0.4088, 0.5619, 0.2824, 0.3835, 0.4790, 0.5131],\n",
      "        [0.4662, 0.4437, 0.5415, 0.3894, 0.6105, 0.1017, 0.6272, 0.2315, 0.6695],\n",
      "        [0.4259, 0.5553, 0.3763, 0.6995, 0.3819, 0.4665, 0.6892, 0.1943, 0.6093]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3303, 0.5035, 0.3359, 0.3027, 0.5685, 0.4667, 0.4503, 0.6585, 0.5812],\n",
      "        [0.2978, 0.4867, 0.5390, 0.5142, 0.5633, 0.6201, 0.3623, 0.5544, 0.4477],\n",
      "        [0.4751, 0.4442, 0.4729, 0.3259, 0.4424, 0.4965, 0.5025, 0.4500, 0.6860],\n",
      "        [0.5033, 0.3608, 0.4499, 0.7497, 0.6778, 0.2337, 0.5340, 0.3692, 0.5633]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4675, 0.6110, 0.4451, 0.3050, 0.5967, 0.2120, 0.6921, 0.5557, 0.4913],\n",
      "        [0.5356, 0.5790, 0.1983, 0.8188, 0.7668, 0.2165, 0.3955, 0.4291, 0.4232],\n",
      "        [0.4357, 0.3955, 0.3958, 0.3053, 0.4784, 0.4691, 0.7494, 0.7340, 0.5069],\n",
      "        [0.4478, 0.2475, 0.4185, 0.3184, 0.3918, 0.6739, 0.3077, 0.7490, 0.5434]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4089, 0.3691, 0.3367, 0.4389, 0.5976, 0.4835, 0.7074, 0.4610, 0.2572],\n",
      "        [0.4212, 0.6241, 0.2105, 0.4035, 0.6731, 0.5465, 0.5423, 0.5616, 0.3354],\n",
      "        [0.4976, 0.5051, 0.6524, 0.6472, 0.4696, 0.5953, 0.4685, 0.6688, 0.2408],\n",
      "        [0.5003, 0.4622, 0.5556, 0.4257, 0.5862, 0.3244, 0.6802, 0.5833, 0.5716]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5860, 0.6108, 0.3561, 0.5054, 0.4776, 0.3127, 0.5474, 0.7353, 0.5384],\n",
      "        [0.6324, 0.3052, 0.1823, 0.1963, 0.6879, 0.5051, 0.5958, 0.4556, 0.2738],\n",
      "        [0.4862, 0.7673, 0.4357, 0.3502, 0.5773, 0.7362, 0.5355, 0.3722, 0.5081],\n",
      "        [0.3705, 0.5025, 0.4216, 0.3697, 0.5854, 0.5620, 0.6606, 0.5188, 0.8621]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5263, 0.5821, 0.5526, 0.5204, 0.5922, 0.4996, 0.4026, 0.3927, 0.5086],\n",
      "        [0.4964, 0.4712, 0.3605, 0.5157, 0.6571, 0.8252, 0.5674, 0.6606, 0.5851],\n",
      "        [0.5946, 0.5529, 0.4970, 0.5447, 0.4782, 0.4403, 0.4211, 0.6080, 0.6898],\n",
      "        [0.4056, 0.4533, 0.1743, 0.4385, 0.5126, 0.4350, 0.3724, 0.5972, 0.4503]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5930, 0.6186, 0.4209, 0.2840, 0.5920, 0.4984, 0.6052, 0.4886, 0.4485],\n",
      "        [0.4274, 0.4304, 0.5392, 0.3559, 0.3743, 0.4905, 0.5850, 0.3290, 0.4421],\n",
      "        [0.4962, 0.5643, 0.1955, 0.6370, 0.4856, 0.2753, 0.5924, 0.5112, 0.4972],\n",
      "        [0.5016, 0.4638, 0.3415, 0.5713, 0.5012, 0.2797, 0.5420, 0.5658, 0.2228]])\n",
      "batch_labels:  tensor([0., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.7370, 0.5188, 0.1482, 0.7185, 0.8913, 0.4934, 0.4820, 0.4816, 0.4217],\n",
      "        [0.5191, 0.5154, 0.3002, 0.4441, 0.7358, 0.2823, 0.5945, 0.5832, 0.5075],\n",
      "        [0.4621, 0.6930, 0.1613, 0.5038, 0.5222, 0.4332, 0.4768, 0.5402, 0.3193],\n",
      "        [0.3751, 0.4062, 0.4946, 0.3748, 0.6920, 0.5509, 0.6180, 0.5085, 0.6311]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.7209, 0.9301, 0.2195, 0.4486, 0.7660, 0.5181, 0.2881, 0.5141, 0.7042],\n",
      "        [0.5335, 0.5347, 0.3656, 0.5725, 0.5824, 0.5994, 0.4852, 0.5723, 0.3422],\n",
      "        [0.5263, 0.7082, 0.4769, 0.7158, 0.6027, 0.2503, 0.5651, 0.5980, 0.4020],\n",
      "        [0.5274, 0.5289, 0.4670, 0.4882, 0.5225, 0.1898, 0.6369, 0.5092, 0.5758]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.1959, 0.7667, 0.6928, 0.5350, 0.4954, 0.3654, 0.3672, 0.5256, 0.4418],\n",
      "        [0.6000, 0.5357, 0.4036, 0.5862, 0.6529, 0.4230, 0.6000, 0.4665, 0.4808],\n",
      "        [0.4722, 0.6383, 0.2624, 0.3177, 0.5309, 0.4392, 0.4669, 0.5865, 0.5432],\n",
      "        [0.5340, 0.4399, 0.2077, 0.3056, 0.5658, 0.7545, 0.4580, 0.2654, 0.5961]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4808, 0.5385, 0.3603, 0.7144, 0.7348, 0.3408, 0.4071, 0.3541, 0.3330],\n",
      "        [0.5056, 0.3191, 0.4177, 0.6666, 0.7806, 0.4776, 0.5919, 0.5973, 0.5591],\n",
      "        [0.5586, 0.4095, 0.2338, 0.4735, 0.6470, 0.4889, 0.5756, 0.5148, 0.3815],\n",
      "        [0.5543, 0.5363, 0.4420, 0.5566, 0.5943, 0.4855, 0.5560, 0.6722, 0.5367]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4495, 0.4099, 0.3435, 0.5117, 0.5479, 0.3445, 0.6552, 0.3272, 0.2420],\n",
      "        [0.5464, 0.4453, 0.2374, 0.4624, 0.5930, 0.2295, 0.5253, 0.7250, 0.6493],\n",
      "        [0.5022, 0.3270, 0.2000, 0.6010, 0.5693, 0.1393, 0.3655, 0.6337, 0.4644],\n",
      "        [0.7580, 0.4096, 0.5090, 0.4840, 0.4194, 0.1531, 0.6243, 0.4035, 0.5323]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4607, 0.4886, 0.2542, 0.4068, 0.5259, 0.2579, 0.6105, 0.3856, 0.2718],\n",
      "        [0.4090, 0.6865, 0.3205, 0.3967, 0.6308, 0.5261, 0.2740, 0.3122, 0.5604],\n",
      "        [0.6435, 0.5554, 0.5682, 0.4690, 0.5456, 0.4488, 0.4158, 0.6986, 0.5907],\n",
      "        [0.4929, 0.6095, 0.2854, 0.5494, 0.6368, 0.3961, 0.2677, 0.5022, 0.7535]])\n",
      "batch_labels:  tensor([1., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.3780, 0.4279, 0.5537, 0.2721, 0.6195, 0.5232, 0.5590, 0.4318, 0.2817],\n",
      "        [0.3529, 0.3546, 0.6909, 0.3975, 0.7006, 0.3598, 0.7252, 0.5208, 0.2281],\n",
      "        [0.3846, 0.3430, 0.4611, 0.4221, 0.7124, 0.4961, 0.5927, 0.3685, 0.5121],\n",
      "        [0.4099, 0.3288, 0.3844, 0.7125, 0.5407, 0.2734, 0.4819, 0.4909, 0.7277]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5466, 0.5056, 0.3330, 0.4704, 0.7494, 0.2480, 0.3456, 0.5895, 0.2535],\n",
      "        [0.5871, 0.5046, 0.1957, 0.3340, 0.6687, 0.7364, 0.2522, 0.5902, 0.5630],\n",
      "        [0.5237, 0.4506, 0.3016, 0.2743, 0.5870, 0.4556, 0.3024, 0.6234, 0.2074],\n",
      "        [0.4285, 0.2789, 0.1655, 0.5314, 0.4231, 0.3868, 0.5739, 0.3649, 0.6311]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5224, 0.6024, 0.2751, 0.6618, 0.5423, 0.4743, 0.5959, 0.6211, 0.4269],\n",
      "        [0.5959, 0.6832, 0.1870, 0.5988, 0.5349, 0.4070, 0.2369, 0.3526, 0.3405],\n",
      "        [0.5026, 0.6779, 0.2562, 0.6148, 0.9145, 0.2975, 0.5146, 0.3861, 0.2347],\n",
      "        [0.5493, 0.4692, 0.3698, 0.7834, 0.7426, 0.4738, 0.3734, 0.6268, 0.5149]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.5142, 0.4920, 0.3387, 0.5345, 0.5047, 0.4077, 0.4291, 0.8925, 0.5150],\n",
      "        [0.4612, 0.4654, 0.2916, 0.4315, 0.7103, 0.3691, 0.5158, 0.4642, 0.4685],\n",
      "        [0.4723, 0.5096, 0.5964, 0.5117, 0.6368, 0.2170, 0.6910, 0.6653, 0.4828],\n",
      "        [0.4297, 0.5087, 0.7003, 0.7251, 0.4521, 0.2135, 0.3784, 0.9656, 0.6246]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.6380, 0.6228, 0.8668, 0.3930, 0.4762, 0.4425, 0.5665, 0.6525, 0.6144],\n",
      "        [0.2336, 0.5513, 0.5894, 0.6298, 0.7244, 0.4353, 0.4679, 0.1881, 0.5420],\n",
      "        [0.5570, 0.5628, 0.2773, 0.4700, 0.5422, 0.4478, 0.6438, 1.0000, 0.2783],\n",
      "        [0.5291, 0.5821, 0.2973, 0.5135, 0.5870, 0.5112, 0.4972, 0.4978, 0.5649]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4658, 0.3912, 0.6442, 0.3981, 0.4816, 0.4938, 0.4877, 0.5469, 0.5648],\n",
      "        [0.4740, 0.5572, 0.2404, 0.5254, 0.5841, 0.5391, 0.6909, 0.6283, 0.4975],\n",
      "        [0.6531, 0.3197, 0.4661, 0.5714, 0.4693, 0.6162, 0.4737, 0.2685, 0.5638],\n",
      "        [0.5767, 0.5528, 0.2223, 0.3492, 0.5509, 0.4901, 0.4511, 0.1732, 0.5047]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5490, 0.5708, 0.5262, 0.4778, 0.6581, 0.2863, 0.5091, 0.6522, 0.3803],\n",
      "        [0.6476, 0.6258, 0.1151, 0.6690, 0.5398, 0.4675, 0.4801, 0.6237, 0.3491],\n",
      "        [0.4375, 0.4678, 0.4873, 0.4345, 0.5737, 0.1847, 0.4862, 0.4278, 0.2917],\n",
      "        [0.4113, 0.2701, 0.1902, 0.3341, 0.5975, 0.4438, 0.3373, 0.7028, 0.3691]])\n",
      "batch_labels:  tensor([1., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.3387, 0.3281, 0.1645, 0.5501, 0.6273, 0.5351, 0.3732, 0.4551, 0.4865],\n",
      "        [0.4891, 0.5468, 0.4222, 0.5369, 0.6466, 0.6356, 0.2570, 0.6935, 0.6562],\n",
      "        [0.5169, 0.5172, 0.3339, 0.3729, 0.5908, 0.3835, 0.4145, 0.4177, 0.5645],\n",
      "        [0.5024, 0.4427, 0.5866, 0.5957, 0.6937, 0.5138, 0.5349, 0.3833, 0.6591]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.3515, 0.5667, 0.3999, 0.3357, 0.5343, 0.5108, 0.4957, 0.5946, 0.5773],\n",
      "        [0.5605, 0.8051, 0.6075, 0.4744, 0.7417, 0.4060, 0.4656, 0.4164, 0.4462],\n",
      "        [0.3893, 0.4012, 0.3100, 0.3577, 0.6080, 0.4800, 0.4687, 0.4401, 0.5796],\n",
      "        [0.5019, 0.4336, 0.3479, 0.5727, 0.5935, 0.2953, 0.6121, 0.6912, 0.4602]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4318, 0.2666, 0.3771, 0.8069, 0.5957, 0.4462, 0.4854, 0.2004, 0.2212],\n",
      "        [0.5473, 0.4088, 0.2388, 0.4766, 0.6557, 0.2798, 0.3755, 0.2683, 0.3498],\n",
      "        [0.6043, 0.5585, 0.3927, 0.1077, 0.5487, 0.3843, 0.4352, 0.2981, 0.6228],\n",
      "        [0.5187, 0.5504, 0.4378, 0.7009, 0.6627, 0.2928, 0.3766, 0.5124, 0.5873]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4791, 0.4238, 0.2229, 0.3750, 0.7522, 0.4453, 0.5491, 0.8287, 0.2685],\n",
      "        [0.7477, 0.7492, 0.5634, 0.3081, 0.4533, 0.5505, 0.4167, 0.5784, 0.5731],\n",
      "        [0.6468, 0.4975, 0.1634, 0.4086, 0.6156, 0.6546, 0.4626, 0.5705, 0.3631],\n",
      "        [0.4986, 0.2724, 0.3321, 0.5267, 0.8353, 0.5920, 0.6593, 0.5204, 0.4318]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.6821, 0.4487, 0.5339, 0.3635, 0.8336, 0.6737, 0.6248, 0.3234, 0.5006],\n",
      "        [0.5799, 0.4867, 0.2225, 0.5236, 0.6093, 0.3934, 0.4496, 0.6793, 0.3829],\n",
      "        [0.4148, 0.4189, 0.3001, 0.7686, 0.5085, 0.3648, 0.5221, 0.5699, 0.5051],\n",
      "        [0.3832, 0.3732, 0.2070, 0.4610, 0.4920, 0.6089, 0.4916, 0.5316, 0.6358]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5567, 0.4150, 0.1806, 0.5349, 0.6293, 0.4901, 0.5012, 0.4530, 0.3240],\n",
      "        [0.5787, 0.5315, 0.4875, 0.4330, 0.5678, 0.4404, 0.4858, 0.4707, 0.3790],\n",
      "        [0.2909, 0.4982, 0.3893, 0.4879, 0.7069, 0.2795, 0.5103, 0.4630, 0.4095],\n",
      "        [0.4469, 0.5677, 0.3630, 0.4073, 0.4260, 0.5863, 0.5839, 0.5714, 0.7021]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4750, 0.5256, 0.4552, 0.6797, 0.5642, 0.5759, 0.6256, 0.7060, 0.7440],\n",
      "        [0.5642, 0.6869, 0.1654, 0.7201, 0.2857, 0.4119, 0.5156, 0.2709, 0.2332],\n",
      "        [0.5699, 0.2427, 0.1869, 0.6921, 0.5283, 0.5041, 0.5033, 0.5550, 0.5632],\n",
      "        [0.4944, 0.5613, 0.2402, 0.5954, 0.6065, 0.5219, 0.5089, 0.5252, 0.3638]])\n",
      "batch_labels:  tensor([1., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.3666, 0.4630, 0.7432, 0.4663, 0.5421, 0.2001, 0.6758, 0.5443, 0.4823],\n",
      "        [0.5479, 0.7298, 0.3804, 0.4093, 0.7559, 0.2795, 0.4888, 0.5112, 0.5136],\n",
      "        [0.3498, 0.4356, 0.3959, 0.7438, 0.4756, 0.4507, 0.4844, 0.6367, 0.3730],\n",
      "        [0.4057, 0.4554, 0.5174, 0.3971, 0.6231, 0.3698, 0.6671, 0.6377, 0.5316]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3535, 0.8198, 0.4627, 0.7523, 0.7136, 0.5660, 0.6479, 0.4579, 0.5753],\n",
      "        [0.5445, 0.6580, 0.3801, 0.4194, 0.6002, 0.4905, 0.4918, 0.2426, 0.4501],\n",
      "        [0.5873, 0.5777, 0.3863, 0.5682, 0.6473, 0.2930, 0.6545, 0.7950, 0.6301],\n",
      "        [0.4646, 0.1591, 0.4543, 0.5341, 0.5205, 0.2277, 0.6937, 0.6689, 0.5440]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5514, 0.3432, 0.4094, 0.6555, 0.5563, 0.1686, 0.6041, 0.5544, 0.4129],\n",
      "        [0.3482, 0.2603, 0.2621, 0.5280, 0.7980, 0.4590, 0.4856, 0.5493, 0.6001],\n",
      "        [0.4268, 0.7203, 0.7999, 0.5094, 0.5959, 0.2054, 0.3649, 0.6938, 0.3277],\n",
      "        [0.5172, 0.4927, 0.4703, 0.7691, 0.5125, 0.6450, 0.5773, 0.4549, 0.4389]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.7125, 0.1654, 0.2839, 0.5580, 0.6672, 0.6450, 0.4432, 0.5775, 0.4673],\n",
      "        [0.3630, 0.2199, 0.1351, 0.4577, 0.5865, 0.4961, 0.4243, 0.6138, 0.7311],\n",
      "        [0.4882, 0.5262, 0.3808, 0.4030, 0.6343, 0.3907, 0.7048, 0.3523, 0.5051],\n",
      "        [0.5985, 0.5167, 0.4671, 0.5550, 0.6327, 0.5254, 0.2945, 0.4988, 0.2945]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5844, 0.3685, 0.3862, 0.3708, 0.5075, 0.2719, 0.7199, 0.6058, 0.6485],\n",
      "        [0.7320, 0.5894, 0.4866, 0.6409, 0.6833, 0.3287, 0.1766, 0.4418, 0.3638],\n",
      "        [0.3331, 0.5913, 0.2861, 0.5172, 0.4254, 0.5072, 0.5368, 0.5988, 0.5799],\n",
      "        [0.5492, 0.5044, 0.4227, 0.4597, 0.6281, 0.4892, 0.5298, 0.3116, 0.3224]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.6168, 0.3204, 0.4982, 0.1927, 0.3383, 0.4835, 0.5221, 0.6148, 0.3617],\n",
      "        [0.3383, 0.3520, 0.6821, 0.5947, 0.7014, 0.4467, 0.5894, 0.4384, 0.3524],\n",
      "        [0.3537, 0.5071, 0.3803, 0.5423, 0.4637, 0.4043, 0.3518, 0.3695, 0.5716],\n",
      "        [0.4649, 0.4881, 0.6400, 0.3053, 0.4218, 0.2154, 0.5074, 0.6273, 0.3772]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4218, 0.6297, 0.2255, 0.6038, 0.7482, 0.1899, 0.1984, 0.2826, 0.4250],\n",
      "        [0.4868, 0.3418, 0.6316, 0.5023, 0.7262, 0.3571, 0.6312, 0.5515, 0.5549],\n",
      "        [0.4890, 0.6156, 0.5480, 0.1961, 0.6103, 0.5956, 0.4626, 0.5359, 0.3958],\n",
      "        [0.5206, 0.7652, 0.4702, 0.5697, 0.6594, 0.3169, 0.6308, 0.8048, 0.3228]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5584, 0.5770, 0.4184, 0.5027, 0.6027, 0.3803, 0.7008, 0.1428, 0.5112],\n",
      "        [0.3525, 0.4850, 0.3101, 0.6579, 0.5136, 0.3834, 0.4074, 0.6958, 0.7149],\n",
      "        [0.2958, 0.3086, 0.4686, 0.6690, 0.5334, 0.2976, 0.4158, 0.3942, 0.3207],\n",
      "        [0.4694, 0.5205, 0.6536, 0.2843, 0.4313, 0.3173, 0.4146, 0.4266, 0.2958]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.7120, 0.5748, 0.4471, 0.3248, 0.5398, 0.2912, 0.4755, 0.5150, 0.2877],\n",
      "        [0.4517, 0.6838, 0.2432, 0.6550, 0.5272, 0.4932, 0.6134, 0.6537, 0.4306],\n",
      "        [0.4802, 0.3821, 0.4975, 0.4878, 0.5391, 0.5992, 0.7768, 0.6034, 0.7220],\n",
      "        [0.5042, 0.5154, 0.2286, 0.3725, 0.6314, 0.4259, 0.6814, 0.3812, 0.1505]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3728, 0.4012, 0.4342, 0.2381, 0.6756, 0.5239, 0.5209, 0.2126, 0.0719],\n",
      "        [0.3534, 0.6138, 0.4030, 0.4760, 0.6281, 0.4984, 0.4368, 0.6021, 0.6464],\n",
      "        [0.2328, 0.3239, 0.2848, 0.3904, 0.5229, 0.3830, 0.3132, 0.5192, 0.5263],\n",
      "        [0.5721, 0.6343, 0.3213, 0.4086, 0.3350, 0.3050, 0.5004, 0.8038, 0.6419]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.3868, 0.3314, 0.3593, 0.7033, 0.5240, 0.2784, 0.6558, 0.5767, 0.6118],\n",
      "        [0.5855, 0.5648, 0.3505, 0.6286, 0.4169, 0.4972, 0.4198, 0.5028, 0.3914],\n",
      "        [0.3052, 0.2715, 0.5081, 0.6451, 0.4811, 0.4226, 0.6087, 0.4719, 0.5817],\n",
      "        [0.3886, 0.6157, 0.2309, 0.5375, 0.6815, 0.3148, 0.7266, 0.8318, 0.5142]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5225, 0.5600, 0.5475, 0.4247, 0.5201, 0.4699, 0.5888, 0.2862, 0.4485],\n",
      "        [0.3507, 0.3363, 0.3326, 0.4141, 0.5024, 0.5736, 0.5471, 0.7678, 0.5912],\n",
      "        [0.6465, 0.7925, 0.1711, 0.3937, 0.6339, 0.6184, 0.3537, 0.4956, 0.6584],\n",
      "        [0.4766, 0.3785, 0.3109, 0.3050, 0.5078, 0.3063, 0.5216, 0.7626, 0.5139]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5659, 0.4199, 0.3817, 0.5195, 0.6363, 0.4115, 0.1115, 0.5521, 0.3949],\n",
      "        [0.3857, 0.5217, 0.3685, 0.7188, 0.7430, 0.4272, 0.5142, 0.5076, 0.4570],\n",
      "        [0.4582, 0.5803, 0.2138, 0.5035, 0.7409, 0.4780, 0.8018, 0.1382, 0.3917],\n",
      "        [0.3820, 0.2504, 0.2788, 0.6913, 0.6738, 0.3934, 0.4312, 0.4263, 0.5029]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4513, 0.4494, 0.2007, 0.6450, 0.7932, 0.3324, 0.5623, 0.6477, 0.2856],\n",
      "        [0.4769, 0.4687, 0.2667, 0.5194, 0.5339, 0.5384, 0.7014, 0.4057, 0.7360],\n",
      "        [0.3329, 0.7246, 0.1984, 0.2532, 0.7646, 0.7348, 0.6454, 0.4673, 0.3114],\n",
      "        [0.5691, 0.4127, 0.3747, 0.5198, 0.5289, 0.5354, 0.3716, 0.3261, 0.4572]])\n",
      "batch_labels:  tensor([1., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.6598, 0.5325, 0.4053, 0.4300, 0.4788, 0.3107, 0.5725, 0.6115, 0.3257],\n",
      "        [0.5514, 0.5188, 0.3933, 0.3317, 0.6081, 0.7103, 0.4061, 0.5777, 0.3233],\n",
      "        [0.7354, 0.2577, 0.8599, 0.6619, 0.5651, 0.2974, 0.6359, 0.5959, 0.5455],\n",
      "        [0.6417, 0.3739, 0.3550, 0.5281, 0.4987, 0.3757, 0.3216, 0.6597, 0.5648]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5452, 0.2617, 0.2920, 0.5355, 0.4362, 0.7136, 0.6674, 0.4719, 0.1385],\n",
      "        [0.5703, 0.4611, 0.5001, 0.5295, 0.7180, 0.3644, 0.4285, 0.6793, 0.3813],\n",
      "        [0.6116, 0.4725, 0.2294, 0.4638, 0.5859, 0.3590, 0.3422, 0.3065, 0.4350],\n",
      "        [0.6709, 0.3926, 0.5883, 0.6024, 0.5311, 0.4497, 0.3304, 0.5696, 0.3398]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.6465, 0.5588, 0.2016, 0.4434, 0.5607, 0.5583, 0.3658, 0.5107, 0.3219],\n",
      "        [0.4645, 0.4590, 0.2856, 0.6886, 0.5450, 0.4664, 0.4147, 0.2806, 0.4156],\n",
      "        [0.6275, 0.4916, 0.2944, 0.3229, 0.5379, 0.2789, 0.6785, 0.4352, 0.5417],\n",
      "        [0.5896, 0.6468, 0.2352, 0.5311, 0.5246, 0.5904, 0.6637, 0.4286, 0.5487]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5976, 0.6366, 0.2802, 0.2345, 0.6457, 0.3065, 0.4782, 0.6393, 0.6867],\n",
      "        [0.3241, 0.5224, 0.5673, 0.6119, 0.6697, 0.5714, 0.4114, 0.6623, 0.2539],\n",
      "        [0.4875, 0.4401, 0.2691, 0.4899, 0.5582, 0.5062, 0.7297, 0.4587, 0.5410],\n",
      "        [0.4502, 0.4299, 0.4571, 0.5030, 0.5701, 0.6618, 0.3940, 0.4519, 0.9085]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.7003, 0.1676, 0.4912, 0.6194, 0.5995, 0.5235, 0.2547, 0.4874, 0.4365],\n",
      "        [0.2839, 0.1757, 0.2988, 0.6187, 0.5508, 0.2882, 0.2277, 0.5406, 0.5704],\n",
      "        [0.4960, 0.4694, 0.4680, 0.6106, 0.7852, 0.4725, 0.6542, 0.2834, 0.4289],\n",
      "        [0.4590, 0.4953, 0.1263, 0.3788, 0.6415, 0.2889, 0.3818, 0.4223, 0.5889]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.5205, 0.4798, 0.3960, 0.5896, 0.4688, 0.3848, 0.4475, 0.4751, 0.7018],\n",
      "        [0.4760, 0.5031, 0.4459, 0.4950, 0.5211, 0.4232, 0.3998, 0.5872, 0.7966],\n",
      "        [0.5744, 0.5346, 0.4247, 0.4646, 0.5023, 0.4880, 0.6866, 0.1917, 0.7045],\n",
      "        [0.7019, 0.2259, 0.4649, 0.6295, 0.6271, 0.5058, 0.2784, 0.4917, 0.6279]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5309, 0.6308, 0.2188, 0.6916, 0.6140, 0.2567, 0.4261, 0.6433, 0.7263],\n",
      "        [0.3592, 0.6596, 0.2034, 0.4746, 0.5283, 0.3724, 0.4665, 0.2392, 0.4439],\n",
      "        [0.5688, 0.5518, 0.2701, 0.3604, 0.6618, 0.4020, 0.5310, 0.5793, 0.4264],\n",
      "        [0.5362, 0.6233, 0.2580, 0.5617, 0.6468, 0.2528, 0.5158, 0.4099, 0.2953]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5256, 0.5714, 0.2912, 0.3447, 0.6749, 0.2851, 0.1586, 0.3299, 0.7021],\n",
      "        [0.6061, 0.5088, 0.2772, 0.2961, 0.5186, 0.4769, 0.6666, 0.2742, 0.4076],\n",
      "        [0.6246, 0.5849, 0.3100, 0.5509, 0.7052, 0.1818, 0.5648, 0.4837, 0.5895],\n",
      "        [0.4468, 0.7895, 0.3726, 0.2951, 0.6484, 0.2838, 1.0000, 0.4450, 0.6109]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.7258, 0.7159, 0.5061, 0.5217, 0.7518, 0.1487, 0.4672, 0.6587, 0.2424],\n",
      "        [0.4026, 0.4616, 0.4695, 0.3764, 0.5797, 0.2016, 0.4102, 0.2095, 0.5361],\n",
      "        [0.3531, 0.4133, 0.6013, 0.4559, 0.7035, 0.5886, 0.6009, 0.3463, 0.6718],\n",
      "        [0.5508, 0.4519, 0.1690, 0.5297, 0.7709, 0.6126, 0.4091, 0.7088, 0.6470]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5157, 0.3540, 0.2593, 0.6649, 0.8014, 0.3672, 0.6118, 0.3689, 0.2844],\n",
      "        [0.4421, 0.4656, 0.5756, 0.5759, 0.5261, 0.4744, 0.4855, 0.4478, 0.6844],\n",
      "        [0.3780, 0.5261, 0.5490, 0.5023, 0.4983, 0.4530, 0.3484, 0.6849, 0.4412],\n",
      "        [0.4243, 0.5919, 0.2998, 0.1815, 0.5398, 0.7440, 0.5782, 0.4873, 0.2461]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4395, 0.4315, 0.2961, 0.5517, 0.6855, 0.3388, 0.3536, 0.5721, 0.3115],\n",
      "        [0.3224, 0.4929, 0.8414, 0.4921, 0.6560, 0.5887, 0.4714, 0.5035, 0.5919],\n",
      "        [0.7397, 0.3852, 0.6092, 0.4230, 0.6116, 0.5254, 0.6916, 0.3165, 0.5469],\n",
      "        [0.4208, 0.3988, 0.1888, 0.5803, 0.5022, 0.5569, 0.4049, 0.4712, 0.4397]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.2473, 0.4341, 0.5032, 0.3285, 0.4643, 0.5424, 0.2724, 0.5959, 0.3765],\n",
      "        [0.4934, 0.7834, 0.2788, 0.8150, 0.3780, 0.3826, 0.1256, 0.5844, 0.6981],\n",
      "        [0.5682, 0.5671, 0.6546, 0.5859, 0.3478, 0.5642, 0.6840, 0.5603, 0.3670],\n",
      "        [0.5255, 0.6295, 0.4671, 0.3636, 0.4877, 0.2364, 0.5584, 0.1742, 0.4818]])\n",
      "batch_labels:  tensor([1., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4123, 0.4281, 0.4803, 0.6372, 0.5199, 0.3339, 0.4732, 0.4508, 0.6655],\n",
      "        [0.3924, 0.5341, 0.3387, 0.5672, 0.3873, 0.9182, 0.5463, 0.5252, 0.4087],\n",
      "        [0.5011, 0.4301, 0.4543, 0.5195, 0.5226, 0.2205, 0.5727, 0.5249, 0.3902],\n",
      "        [0.6062, 0.5809, 0.2752, 0.5233, 0.5339, 0.2868, 0.5138, 0.6141, 0.5059]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4996, 0.3081, 0.4160, 0.4782, 0.5969, 0.1057, 0.6054, 0.4113, 0.5085],\n",
      "        [0.5162, 0.4235, 0.3244, 0.4888, 0.4243, 0.4102, 0.5068, 0.6680, 0.7001],\n",
      "        [0.4558, 0.3514, 0.2329, 0.4744, 0.4746, 0.2870, 0.5417, 0.4760, 0.4556],\n",
      "        [0.3409, 0.5077, 0.6796, 0.6607, 0.7222, 0.2825, 0.4404, 0.4617, 0.1668]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5051, 0.7724, 0.2453, 0.6491, 0.6526, 0.1610, 0.6027, 0.6363, 0.6238],\n",
      "        [0.4947, 0.4899, 0.3680, 0.4287, 0.5453, 0.3258, 0.5320, 0.6907, 0.5042],\n",
      "        [0.4465, 0.4455, 0.5826, 0.3375, 0.6629, 0.2694, 0.2174, 0.4995, 0.7838],\n",
      "        [0.6981, 0.5922, 0.1151, 0.3952, 0.5797, 0.4182, 0.4098, 0.3227, 0.5410]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5117, 0.5092, 0.4785, 0.5459, 0.4995, 0.1784, 0.5003, 0.5028, 0.6463],\n",
      "        [0.3409, 0.5533, 0.2790, 0.3627, 0.6268, 0.3676, 0.3710, 0.6580, 0.3726],\n",
      "        [0.4923, 0.7194, 0.4596, 0.5439, 0.5853, 0.3664, 0.3509, 0.5784, 0.6302],\n",
      "        [0.3368, 0.1680, 0.5793, 0.5182, 0.6713, 0.6012, 0.5624, 0.3212, 0.7176]])\n",
      "batch_labels:  tensor([1., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.5190, 0.4978, 0.5065, 0.3138, 0.6277, 0.5318, 0.4857, 0.5936, 0.7290],\n",
      "        [0.6815, 0.0878, 0.2898, 0.6605, 0.5178, 0.6055, 0.4076, 0.5099, 0.5087],\n",
      "        [0.5865, 0.4252, 0.1448, 0.3763, 0.5877, 0.2901, 0.4902, 0.3669, 0.5969],\n",
      "        [0.3436, 0.5838, 0.1703, 0.4740, 0.7116, 0.5906, 0.4888, 0.3796, 0.3975]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4891, 0.4932, 0.4823, 0.7493, 0.5076, 0.1836, 0.5519, 0.6021, 0.1875],\n",
      "        [0.6925, 0.1873, 0.6847, 0.6769, 0.7137, 0.5632, 0.5147, 0.4385, 0.3121],\n",
      "        [0.6862, 0.4711, 0.4644, 0.2286, 0.7582, 0.2236, 0.5933, 0.7177, 0.3131],\n",
      "        [0.6269, 0.5213, 0.2657, 0.3970, 0.5230, 0.5803, 0.4668, 0.5310, 0.4220]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4118, 0.5119, 0.3708, 0.6590, 0.5603, 0.2008, 0.4371, 0.5695, 0.6838],\n",
      "        [0.5288, 0.4458, 0.2987, 0.3884, 0.6484, 0.5392, 0.7468, 0.4513, 0.3751],\n",
      "        [0.5052, 0.5700, 0.4509, 0.5753, 0.6359, 0.4235, 0.2713, 0.5807, 0.2992],\n",
      "        [0.1789, 0.3211, 0.5320, 0.3973, 0.4963, 0.3182, 0.4806, 0.3208, 0.6343]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5532, 0.4933, 0.2394, 0.6490, 0.6097, 0.5595, 0.4663, 0.7849, 0.4395],\n",
      "        [0.4780, 0.5587, 0.5747, 0.5140, 0.6027, 0.2509, 0.5860, 0.2926, 0.5852],\n",
      "        [0.5129, 0.2217, 0.4889, 0.7126, 0.3362, 0.4314, 0.6081, 0.4417, 0.7689],\n",
      "        [0.5749, 0.5944, 0.5524, 0.3508, 0.5842, 0.3173, 0.5114, 0.3798, 0.5664]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5673, 0.5262, 0.2055, 0.4950, 0.4869, 0.3968, 0.2003, 0.7120, 0.3511],\n",
      "        [0.5869, 0.5709, 0.7231, 0.5379, 0.4893, 0.2969, 0.4342, 0.5364, 0.6593],\n",
      "        [0.5145, 0.3495, 0.4065, 0.2345, 0.4191, 0.4258, 0.3503, 0.6873, 0.1528],\n",
      "        [0.4848, 0.6376, 0.1872, 0.5455, 0.6627, 0.5647, 0.4235, 0.2770, 0.5336]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4564, 0.3926, 0.4421, 0.2746, 0.7005, 0.1712, 0.5196, 0.5675, 0.5856],\n",
      "        [0.4974, 0.5123, 0.2907, 0.4721, 0.6237, 0.4906, 0.6067, 0.4423, 0.3595],\n",
      "        [0.4836, 0.4353, 0.5413, 0.4421, 0.4428, 0.3478, 0.2218, 0.4741, 0.2877],\n",
      "        [0.5568, 0.3312, 0.1326, 0.4954, 0.3673, 0.3736, 0.5732, 0.4716, 0.5524]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4562, 0.6167, 0.2640, 0.5348, 0.7397, 0.4267, 0.3985, 0.3791, 0.5502],\n",
      "        [0.5012, 0.8292, 0.1631, 0.5986, 0.4733, 0.3296, 0.6499, 0.7437, 0.1063],\n",
      "        [0.5686, 0.4830, 0.5159, 0.4037, 0.6467, 0.1394, 0.4195, 0.4933, 0.3331],\n",
      "        [0.7235, 0.5662, 0.2370, 0.4374, 0.4774, 0.4835, 0.6132, 0.5557, 0.3872]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.6178, 0.7535, 0.2209, 0.7614, 0.6460, 0.5524, 0.3683, 0.5272, 0.3803],\n",
      "        [0.3805, 0.5066, 0.2237, 0.6709, 0.6205, 0.2783, 0.4258, 0.5075, 0.4495],\n",
      "        [0.5053, 0.4265, 0.6087, 0.3062, 0.4739, 0.5009, 0.5876, 0.4694, 0.5601],\n",
      "        [0.4948, 0.4944, 0.2922, 0.5377, 0.6285, 0.5497, 0.7056, 0.6383, 0.4987]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4903, 0.5207, 0.5438, 0.4095, 0.7461, 0.4003, 0.2768, 0.3437, 0.7904],\n",
      "        [0.5732, 0.5203, 0.4467, 0.4394, 0.5258, 0.3813, 0.4120, 0.4435, 0.5904],\n",
      "        [0.4049, 0.4909, 0.3406, 0.2348, 0.3607, 0.2970, 0.5128, 0.0000, 0.1450],\n",
      "        [0.0874, 0.6342, 0.2246, 0.4110, 0.5418, 0.5324, 0.3964, 0.4554, 0.6935]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.6105, 0.5326, 0.2377, 0.2703, 0.4952, 0.4948, 0.4097, 0.4698, 0.5850],\n",
      "        [0.3974, 0.6562, 0.7316, 0.3838, 0.5146, 0.5585, 0.8259, 0.5647, 0.3872],\n",
      "        [0.4549, 0.6620, 0.3256, 0.6160, 0.4918, 0.4359, 0.4804, 0.4944, 0.5815],\n",
      "        [0.5181, 0.4601, 0.2839, 0.3345, 0.5338, 0.3945, 0.5573, 0.4861, 0.5865]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5050, 0.5203, 0.2347, 0.5616, 0.6515, 0.7539, 0.3619, 0.5455, 0.4671],\n",
      "        [0.6562, 0.3565, 0.3434, 0.2214, 0.8173, 0.4099, 0.5157, 0.7557, 0.3420],\n",
      "        [0.4537, 0.5833, 0.3711, 0.5327, 0.6235, 0.2056, 0.4573, 0.3257, 0.5137],\n",
      "        [0.5624, 0.6726, 0.4130, 0.3377, 0.4391, 0.5026, 0.5265, 0.3907, 0.2728]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.3779, 0.6474, 0.2608, 0.6637, 0.7982, 0.4481, 0.3482, 0.4936, 0.4806],\n",
      "        [0.4076, 0.3461, 0.2807, 0.6874, 0.4220, 0.6317, 0.3898, 0.3783, 0.7135],\n",
      "        [0.6206, 0.4841, 0.3819, 0.2863, 0.7336, 0.4240, 0.3900, 0.4111, 0.4719],\n",
      "        [0.6728, 0.8257, 0.3838, 0.3302, 0.6695, 0.6878, 0.4610, 0.4639, 0.3447]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4627, 0.5119, 0.3696, 0.4127, 0.5752, 0.4465, 0.4328, 0.4441, 0.6447],\n",
      "        [0.5465, 0.4919, 0.3329, 0.5723, 0.7073, 0.7175, 0.2717, 0.3218, 0.4580],\n",
      "        [0.1700, 0.5254, 0.8525, 0.4252, 0.3770, 0.4135, 0.3460, 0.6164, 0.8042],\n",
      "        [0.5070, 0.3673, 0.2476, 0.5080, 0.5542, 0.4348, 0.3061, 0.7047, 0.5971]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4750, 0.4299, 0.2966, 0.4823, 0.6843, 0.1772, 0.6653, 0.4704, 0.4751],\n",
      "        [0.6115, 0.4310, 0.3237, 0.4985, 0.6456, 0.2318, 0.5273, 0.6516, 0.3234],\n",
      "        [0.4517, 0.3689, 0.2953, 0.3205, 0.4381, 0.3550, 0.5880, 0.6363, 0.3730],\n",
      "        [0.5313, 0.5641, 0.6060, 0.5774, 0.6727, 0.4457, 0.6592, 0.4469, 0.4488]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5697, 0.4852, 0.2988, 0.5545, 0.5809, 0.4192, 0.4489, 0.3954, 0.6748],\n",
      "        [0.4735, 0.3810, 0.3944, 0.6394, 0.5358, 0.5906, 0.4281, 0.4068, 0.3692],\n",
      "        [0.4649, 0.5012, 0.3770, 0.4393, 0.6667, 0.2432, 0.3707, 0.4989, 0.2150],\n",
      "        [0.7000, 0.5769, 0.2672, 0.1671, 0.4775, 0.4036, 0.6848, 0.5328, 0.3777]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4191, 0.5997, 0.3387, 0.3953, 0.3843, 0.5362, 0.5717, 0.3269, 0.7130],\n",
      "        [0.5359, 0.4895, 0.4467, 0.3889, 0.4397, 0.4179, 0.4272, 0.6284, 0.6299],\n",
      "        [0.5556, 0.3966, 0.6530, 0.4112, 0.6166, 0.5727, 0.5511, 0.5227, 0.5186],\n",
      "        [0.6685, 0.3482, 0.3588, 0.3806, 0.4443, 0.4988, 0.4913, 0.5596, 0.5453]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5541, 0.5637, 0.4697, 0.4361, 0.6032, 0.3126, 0.2665, 0.5564, 0.3910],\n",
      "        [0.5770, 0.4876, 0.3470, 0.4742, 0.7065, 0.5472, 0.4668, 0.4416, 0.5029],\n",
      "        [0.4226, 0.6442, 0.3553, 0.6791, 0.5022, 0.2391, 0.4190, 0.4048, 0.1520],\n",
      "        [0.5912, 0.4511, 0.2253, 0.4439, 0.5309, 0.5290, 0.4348, 0.6797, 0.4321]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.6564, 0.5131, 0.4338, 0.4022, 0.5655, 0.3539, 0.5753, 0.1889, 0.5697],\n",
      "        [0.3889, 0.4709, 0.5061, 0.5244, 0.5615, 0.1429, 0.2499, 0.4015, 0.2200],\n",
      "        [0.5159, 0.4755, 0.5704, 0.4222, 0.6032, 0.5238, 0.4167, 0.4592, 0.2363],\n",
      "        [0.5133, 0.3100, 0.2779, 0.4396, 0.4176, 0.3014, 0.5048, 0.4683, 0.6386]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4130, 0.8234, 0.1183, 0.7395, 0.3370, 0.2168, 0.3988, 0.2675, 0.2252],\n",
      "        [0.3907, 0.8126, 0.4742, 0.4586, 0.4762, 0.4391, 0.5986, 0.5567, 0.3776],\n",
      "        [0.5480, 0.4904, 0.2739, 0.5530, 0.5549, 0.1815, 0.4506, 0.6972, 0.3686],\n",
      "        [0.6065, 0.3290, 0.3498, 0.5343, 0.5224, 0.5785, 0.5072, 0.5679, 0.2841]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5958, 0.6207, 0.2228, 0.4080, 0.5640, 0.3810, 0.6128, 0.5574, 0.4707],\n",
      "        [0.6228, 0.3434, 0.0785, 0.6354, 0.6470, 0.1770, 0.2919, 0.4597, 0.7386],\n",
      "        [0.3905, 0.4792, 0.2134, 0.6099, 0.5189, 0.3589, 0.6581, 0.5081, 0.4557],\n",
      "        [0.3536, 0.4483, 0.4143, 0.6593, 0.5606, 0.4421, 0.5215, 0.5201, 0.6699]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5198, 0.4761, 0.5128, 0.5990, 0.5470, 0.4648, 0.6046, 0.4175, 0.6674],\n",
      "        [0.4440, 0.3427, 0.3696, 0.5014, 0.5393, 0.2708, 0.4764, 0.4837, 0.6210],\n",
      "        [0.5323, 0.3403, 0.5788, 0.1637, 0.3644, 0.1371, 0.6312, 0.4676, 0.3652],\n",
      "        [0.5406, 0.3256, 0.4036, 0.4125, 0.6091, 0.3616, 0.4859, 0.4827, 0.5586]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.5434, 0.4447, 0.1109, 0.3407, 0.7431, 0.5703, 0.5970, 0.4303, 0.5628],\n",
      "        [0.3880, 0.4767, 0.4596, 0.6341, 0.6615, 0.4213, 0.5630, 0.6944, 0.4919],\n",
      "        [0.3825, 0.3159, 0.3207, 0.5181, 0.8178, 0.1790, 0.4072, 0.4083, 0.6841],\n",
      "        [0.4424, 0.3786, 0.3589, 0.5296, 0.6400, 0.4001, 0.5077, 0.3246, 0.2535]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5186, 0.6684, 0.3325, 0.5124, 0.6560, 0.2817, 0.6377, 0.4305, 0.3992],\n",
      "        [0.4077, 0.5272, 0.2430, 0.4476, 0.4596, 0.4958, 0.6446, 0.6009, 0.6027],\n",
      "        [0.4618, 0.5646, 0.5104, 0.6384, 0.3926, 0.5497, 0.4779, 0.5233, 0.5247],\n",
      "        [0.4136, 0.3862, 0.4563, 0.4180, 0.6289, 0.4898, 0.5470, 0.3877, 0.5268]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3663, 0.4908, 0.3861, 0.4084, 0.3944, 0.2716, 0.5428, 0.5202, 0.5292],\n",
      "        [0.4819, 0.3992, 0.3586, 0.4842, 0.6731, 0.3613, 0.4758, 0.3728, 0.6033],\n",
      "        [0.4673, 0.5171, 0.2774, 0.3295, 0.6181, 0.2641, 0.5559, 0.4555, 0.1542],\n",
      "        [0.2762, 0.2952, 0.2632, 0.5786, 0.5815, 0.2562, 0.4679, 0.6680, 0.5130]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4525, 0.5821, 0.6312, 0.4356, 0.5072, 0.2963, 0.2389, 0.5976, 0.4134],\n",
      "        [0.6605, 0.5709, 0.2747, 0.3502, 0.4768, 0.3592, 0.3395, 0.5716, 0.3086],\n",
      "        [0.5035, 0.6760, 0.2379, 0.6717, 0.4415, 0.5023, 0.5900, 0.5701, 0.4876],\n",
      "        [0.3772, 0.5404, 0.3244, 0.3494, 0.5048, 0.3271, 0.3347, 0.5104, 0.2898]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5366, 0.4478, 0.5951, 0.4120, 0.6833, 0.2277, 0.4783, 0.6429, 0.3910],\n",
      "        [0.2875, 0.5531, 0.3826, 0.3796, 0.5638, 0.1140, 0.3642, 0.3301, 0.6230],\n",
      "        [0.3602, 0.4327, 0.3975, 0.4198, 0.5609, 0.3678, 0.6708, 0.7047, 0.4598],\n",
      "        [0.6270, 0.4436, 0.3052, 0.4892, 0.6462, 0.5935, 0.5333, 0.4508, 0.8541]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5116, 0.3388, 0.2837, 0.5337, 0.7164, 0.7072, 0.4077, 0.4427, 0.3375],\n",
      "        [0.6495, 0.3781, 0.1958, 0.4455, 0.6919, 0.3966, 0.4496, 0.5579, 0.4433],\n",
      "        [0.3703, 0.6547, 0.2361, 0.5088, 0.6460, 0.4294, 0.3164, 0.4042, 0.6751],\n",
      "        [0.5340, 0.4913, 0.3802, 0.7183, 0.7185, 0.3864, 0.5607, 0.7280, 0.6707]])\n",
      "batch_labels:  tensor([1., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4322, 0.7191, 0.2683, 0.5644, 0.4093, 0.5184, 0.3022, 0.5295, 0.4469],\n",
      "        [0.4812, 0.3132, 0.2828, 0.3701, 0.7008, 0.2696, 0.3837, 0.5798, 0.6916],\n",
      "        [0.6789, 0.5424, 0.5832, 0.3637, 0.6468, 0.2383, 0.5960, 0.5227, 0.3904],\n",
      "        [0.5513, 0.6218, 0.2863, 0.4859, 0.5232, 0.3835, 0.5311, 0.2088, 0.1888]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4342, 0.3270, 0.3033, 0.5815, 0.5661, 0.5067, 0.4867, 0.4691, 0.5718],\n",
      "        [0.2960, 0.6296, 0.1247, 0.5197, 0.5616, 0.3829, 0.4316, 0.5213, 0.1111],\n",
      "        [0.5180, 0.6492, 0.5136, 0.5572, 0.6991, 0.3401, 0.4698, 0.2682, 0.4562],\n",
      "        [0.5695, 0.5142, 0.3195, 0.4696, 0.7602, 0.3174, 0.3517, 0.6827, 0.3183]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4867, 0.5499, 0.4280, 0.4969, 0.5250, 0.4992, 0.5763, 0.5758, 0.6835],\n",
      "        [0.5091, 0.5675, 0.2420, 0.5805, 0.6137, 0.5307, 0.5328, 0.2094, 0.6109],\n",
      "        [0.6147, 0.4564, 0.2308, 0.4372, 0.6237, 0.6513, 0.4748, 0.5472, 0.2871],\n",
      "        [0.5539, 0.5384, 0.0943, 0.3771, 0.6095, 0.4176, 0.5139, 0.4105, 0.6115]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4097, 0.4621, 0.3310, 0.6053, 0.5674, 0.4088, 0.4475, 0.3776, 0.4517],\n",
      "        [0.4453, 0.5143, 0.2389, 0.5156, 0.5949, 0.4024, 0.3917, 0.4257, 0.2504],\n",
      "        [0.3919, 0.5837, 0.1550, 0.6702, 0.4127, 0.2520, 0.3419, 0.5537, 0.5759],\n",
      "        [0.4544, 0.6205, 0.4716, 0.1599, 0.5399, 0.3285, 0.3412, 0.4778, 0.3562]])\n",
      "batch_labels:  tensor([0., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.2751, 0.7469, 0.5037, 0.5070, 0.4593, 0.4364, 0.2864, 0.5438, 0.5882],\n",
      "        [0.4381, 0.4698, 0.5962, 0.5752, 0.6036, 0.5812, 0.4945, 0.3333, 0.5842],\n",
      "        [0.6071, 0.6571, 0.1236, 0.4740, 0.3976, 0.1038, 0.2736, 0.2890, 0.5137],\n",
      "        [0.4807, 0.3514, 0.2228, 0.3215, 0.6959, 0.6474, 0.4053, 0.5302, 0.5841]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4657, 0.5142, 0.4904, 0.5059, 0.5380, 0.6744, 0.4431, 0.6322, 0.6431],\n",
      "        [0.5845, 0.6933, 0.2207, 0.3185, 0.6883, 0.6528, 0.5249, 0.4611, 0.4562],\n",
      "        [0.4884, 0.5317, 0.2010, 0.3498, 0.4979, 0.6335, 0.2898, 0.4105, 0.4365],\n",
      "        [0.4658, 0.5403, 0.3595, 0.3849, 0.5237, 0.4605, 0.5572, 0.3775, 0.4480]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4441, 0.3745, 0.2609, 0.7938, 0.5316, 0.2458, 0.6938, 0.4835, 0.4745],\n",
      "        [0.4584, 0.5006, 0.5216, 0.4872, 0.5681, 0.5966, 0.3910, 0.5161, 0.1796],\n",
      "        [0.4956, 0.6863, 0.3415, 0.5675, 0.7234, 0.3182, 0.4336, 0.4067, 0.8369],\n",
      "        [0.4960, 0.4841, 0.2876, 0.6003, 0.6785, 0.4737, 0.4182, 0.0775, 0.4931]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4891, 0.5711, 0.5276, 0.5355, 0.5461, 0.3198, 0.4405, 0.5503, 0.5036],\n",
      "        [0.6400, 0.6062, 0.2462, 0.3353, 0.6751, 0.3194, 0.4357, 0.6872, 0.5745],\n",
      "        [0.5461, 0.5141, 0.3315, 0.5100, 0.5335, 0.3023, 0.3138, 0.4910, 0.3344],\n",
      "        [0.4322, 0.3538, 0.3776, 0.5685, 0.4075, 0.5585, 0.3552, 0.7920, 0.2977]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.3945, 0.6531, 0.2878, 0.4151, 0.4693, 0.3337, 0.6722, 0.5927, 0.7069],\n",
      "        [0.6602, 0.2310, 0.2792, 0.2568, 0.4053, 0.5405, 0.4385, 0.6434, 0.5463],\n",
      "        [0.5278, 0.7110, 0.3972, 0.1747, 0.4776, 0.2825, 0.5620, 0.6162, 0.4733],\n",
      "        [0.3657, 0.2831, 0.4493, 0.4439, 0.8160, 0.4389, 0.2133, 0.5571, 0.7236]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.3963, 0.3325, 0.3081, 0.4493, 0.7417, 0.2226, 0.6108, 0.5097, 0.5186],\n",
      "        [0.5223, 0.5710, 0.3230, 0.4548, 0.6447, 0.5836, 0.3985, 0.3154, 0.7877],\n",
      "        [0.7993, 0.4310, 0.5956, 0.6537, 0.5643, 0.4065, 0.6364, 0.4367, 0.7329],\n",
      "        [0.4328, 0.7219, 0.2201, 0.4143, 0.3814, 0.1326, 0.4899, 0.4249, 0.4155]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4040, 0.4796, 0.3555, 0.4182, 0.6194, 0.6221, 0.6251, 0.6568, 0.5263],\n",
      "        [0.4940, 0.5229, 0.4307, 0.3772, 0.7734, 0.3081, 0.4292, 0.6984, 0.5892],\n",
      "        [0.5817, 0.5171, 0.4402, 0.6729, 0.6302, 0.2297, 0.6669, 0.3971, 0.3251],\n",
      "        [0.4713, 0.5090, 0.3689, 0.4465, 0.5910, 0.7973, 0.5383, 0.4774, 0.6024]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4306, 0.3377, 0.4561, 0.5770, 0.4806, 0.6012, 0.4900, 0.5159, 0.6581],\n",
      "        [0.5221, 0.5135, 0.4285, 0.2897, 0.4554, 0.2986, 0.6537, 0.6881, 0.3848],\n",
      "        [0.5411, 0.5191, 0.5640, 0.5319, 0.4594, 0.6924, 0.5903, 0.2668, 0.3662],\n",
      "        [0.4647, 0.5142, 0.2776, 0.5221, 0.6051, 0.4283, 0.5162, 0.2622, 0.5975]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4291, 0.3211, 0.3604, 0.6047, 0.7248, 0.2936, 0.4641, 0.7625, 0.6451],\n",
      "        [0.4625, 0.4851, 0.4401, 0.5030, 0.7577, 0.5436, 0.5037, 0.6192, 0.5686],\n",
      "        [0.3709, 0.4312, 0.6707, 0.7142, 0.6086, 0.4775, 0.5093, 0.4917, 0.4900],\n",
      "        [0.5566, 0.5247, 0.3597, 0.3611, 0.4830, 0.1853, 0.5263, 0.5455, 0.3672]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5166, 0.5113, 0.6223, 0.3304, 0.4869, 0.4468, 0.4107, 0.4693, 0.5573],\n",
      "        [0.4385, 0.3686, 0.4953, 0.6065, 0.7041, 0.1705, 0.3119, 0.3603, 0.2947],\n",
      "        [0.4616, 0.3833, 0.5321, 0.6917, 0.6001, 0.4141, 0.8479, 0.5564, 0.5601],\n",
      "        [0.5485, 0.5876, 0.6184, 0.5448, 0.5046, 0.4451, 0.3390, 0.2451, 0.6686]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5778, 0.6869, 0.4152, 0.4448, 0.5388, 0.3780, 0.4398, 0.4188, 0.4196],\n",
      "        [0.5360, 0.6143, 0.7221, 0.4806, 0.5160, 0.3057, 0.4908, 0.5647, 0.3362],\n",
      "        [0.6437, 0.4413, 0.3144, 0.4393, 0.5145, 0.3567, 0.3772, 0.2029, 0.5204],\n",
      "        [0.6736, 0.4987, 0.3494, 0.5178, 0.4877, 0.3278, 0.4902, 0.6041, 0.5735]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.6803, 0.3838, 0.3709, 0.5584, 0.6166, 0.2421, 0.4897, 0.3644, 0.7325],\n",
      "        [0.2923, 0.3135, 0.3592, 0.1602, 0.4938, 0.4087, 0.5598, 0.5166, 0.4239],\n",
      "        [0.5004, 0.3587, 0.5734, 0.3151, 0.4638, 0.4326, 0.3148, 0.4601, 0.7729],\n",
      "        [0.3590, 0.5487, 0.7886, 0.5025, 0.4865, 0.6367, 0.4242, 0.3783, 0.2972]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.6043, 0.5456, 0.1804, 0.4338, 0.5600, 0.2650, 0.4756, 0.2921, 0.6846],\n",
      "        [0.3898, 0.4254, 0.3134, 0.6002, 0.4964, 0.6356, 0.3281, 0.4266, 0.7503],\n",
      "        [0.3776, 0.3835, 0.4381, 0.5603, 0.5826, 0.3603, 0.6441, 0.5349, 0.2771],\n",
      "        [0.3330, 0.5402, 0.3085, 0.5735, 0.6292, 0.3850, 0.3547, 0.3364, 0.7415]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4975, 0.6524, 0.4604, 0.2150, 0.5828, 0.3241, 0.2997, 0.2892, 0.4453],\n",
      "        [0.5068, 0.5352, 0.3235, 0.3551, 0.5186, 0.4276, 0.4351, 0.1977, 0.6453],\n",
      "        [0.4508, 0.5792, 0.1610, 0.7334, 0.4104, 0.5559, 0.4324, 0.5445, 0.6889],\n",
      "        [0.3925, 0.8633, 0.4984, 0.4903, 0.5382, 0.4067, 0.3875, 0.5118, 0.7264]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.5341, 0.5897, 0.6413, 0.6085, 0.7015, 0.3485, 0.6144, 0.5991, 0.4346],\n",
      "        [0.4561, 0.5096, 0.3525, 0.4662, 0.6363, 0.4914, 0.3571, 0.4859, 0.4664],\n",
      "        [0.4853, 0.4336, 0.4503, 0.4971, 0.5397, 0.1757, 0.3894, 0.7430, 0.6277],\n",
      "        [0.5922, 0.3423, 0.3846, 0.5339, 0.7117, 0.2958, 0.3859, 0.4703, 0.4234]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5144, 0.5180, 0.2532, 0.6336, 0.4179, 0.5172, 0.6076, 0.5333, 0.7283],\n",
      "        [0.5762, 0.4497, 0.3563, 0.3952, 0.5797, 0.4960, 0.6469, 0.3555, 0.3642],\n",
      "        [0.6012, 0.5096, 0.3521, 0.4316, 0.6111, 0.6422, 0.2753, 0.6095, 0.4820],\n",
      "        [0.6170, 0.5746, 0.3301, 0.6202, 0.5540, 0.3527, 0.7198, 0.7625, 0.6176]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4824, 0.5086, 0.3425, 0.5897, 0.6422, 0.3224, 0.6466, 0.4949, 0.5412],\n",
      "        [0.5279, 0.6694, 0.3813, 0.4429, 0.7906, 0.1769, 0.7473, 0.5176, 0.5535],\n",
      "        [0.5455, 0.4339, 0.2164, 0.7327, 0.8306, 0.4897, 0.2504, 0.4989, 0.3099],\n",
      "        [0.4910, 0.5093, 0.2106, 0.5618, 0.6025, 0.1848, 0.4890, 0.5396, 0.4763]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5092, 0.5270, 0.2518, 0.4555, 0.5256, 0.6039, 0.4843, 0.6443, 0.4625],\n",
      "        [0.6811, 0.6473, 0.0752, 0.4420, 0.4884, 0.2307, 0.3866, 0.6064, 0.3157],\n",
      "        [0.4004, 0.4705, 0.4720, 0.4100, 0.5380, 0.5374, 0.3006, 0.3893, 0.3713],\n",
      "        [0.4820, 0.4599, 0.2432, 0.4816, 0.7000, 0.4729, 0.6045, 0.5716, 0.5741]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5185, 0.5114, 0.4969, 0.6398, 0.4562, 0.4039, 0.6432, 0.1995, 0.2508],\n",
      "        [0.7248, 0.3071, 0.3221, 0.5127, 0.7432, 0.3787, 0.5202, 0.6983, 0.5278],\n",
      "        [0.2566, 0.5025, 0.7963, 0.6250, 0.5543, 0.5285, 0.2605, 0.6635, 0.7009],\n",
      "        [0.6564, 0.5367, 0.2495, 0.6543, 0.5661, 0.4166, 0.3924, 0.7132, 0.7544]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3100, 0.4939, 0.4887, 0.4700, 0.5722, 0.6424, 0.8231, 0.6298, 0.6969],\n",
      "        [0.4450, 0.3737, 0.3065, 0.5926, 0.6140, 0.4157, 0.5293, 0.3331, 0.3896],\n",
      "        [0.4649, 0.3585, 0.3959, 0.3335, 0.5955, 0.3902, 0.5480, 0.3873, 0.7396],\n",
      "        [0.5214, 0.5391, 0.1646, 0.4358, 0.5183, 0.5483, 0.3762, 0.6284, 0.4604]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.6297, 0.5520, 0.3132, 0.2899, 0.5840, 0.3254, 0.4918, 0.3441, 0.4913],\n",
      "        [0.4653, 0.4944, 0.3564, 0.3955, 0.5084, 0.3824, 0.5521, 0.4251, 0.6092],\n",
      "        [0.5608, 0.4590, 0.1030, 0.4880, 0.6130, 0.1491, 0.6734, 0.6690, 0.4831],\n",
      "        [0.4902, 0.4854, 0.4606, 0.5017, 0.5346, 0.6580, 0.6944, 0.3633, 0.6902]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5218, 0.6625, 0.5739, 0.4648, 0.7334, 0.3813, 0.3243, 0.3111, 0.3391],\n",
      "        [0.4557, 0.4028, 0.3655, 0.5380, 0.4349, 0.2861, 0.4545, 0.6502, 0.7823],\n",
      "        [0.6952, 0.1037, 0.4814, 0.6669, 0.5517, 0.5633, 0.4825, 0.4408, 0.2606],\n",
      "        [0.5395, 0.6452, 0.6184, 0.5339, 0.6679, 0.1885, 0.6563, 0.5513, 0.6626]])\n",
      "batch_labels:  tensor([0., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.3917, 0.4961, 0.2813, 0.4701, 0.5899, 0.3749, 0.5710, 0.5896, 0.5041],\n",
      "        [0.4123, 0.6137, 0.2340, 0.6590, 0.7076, 0.2469, 0.4568, 0.2969, 0.2909],\n",
      "        [0.6388, 0.2239, 0.3479, 0.5645, 0.4862, 0.4523, 0.5068, 0.5649, 0.5026],\n",
      "        [0.7753, 0.5475, 0.2809, 0.5790, 0.6837, 0.6773, 0.6191, 0.6253, 0.4500]])\n",
      "batch_labels:  tensor([0., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.5390, 0.5217, 0.2026, 0.4480, 0.6257, 0.3973, 0.6717, 0.3841, 0.3584],\n",
      "        [0.2731, 0.5847, 0.7096, 0.5195, 0.5136, 0.3578, 0.3623, 0.6791, 0.5866],\n",
      "        [0.4964, 0.2753, 0.3137, 0.4162, 0.7018, 0.3643, 0.4128, 0.1810, 0.3857],\n",
      "        [0.4344, 0.3930, 0.3968, 0.2969, 0.5635, 0.6301, 0.5972, 0.3719, 0.4844]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4839, 0.4535, 0.2324, 0.4666, 0.5818, 0.5566, 0.5799, 0.6336, 0.6956],\n",
      "        [0.4416, 0.2467, 0.5473, 0.4759, 0.3497, 0.3252, 0.6047, 0.5424, 0.4268],\n",
      "        [0.7300, 0.5128, 0.1386, 0.3543, 0.5767, 0.6642, 0.5427, 0.1750, 0.6190],\n",
      "        [0.6327, 0.5831, 1.0000, 0.1568, 0.0000, 0.6168, 0.2868, 0.5393, 0.5757]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5030, 0.5112, 0.5761, 0.6460, 0.4378, 0.5981, 0.7097, 0.6355, 0.6303],\n",
      "        [0.4285, 0.5199, 0.5460, 0.6339, 0.6246, 0.2533, 0.2862, 0.6149, 0.6276],\n",
      "        [0.4198, 0.6217, 0.0851, 0.5165, 0.5884, 0.2239, 0.3580, 0.2405, 0.5079],\n",
      "        [0.6997, 0.8390, 0.2253, 0.4701, 0.5408, 0.5166, 0.4898, 0.6604, 0.4464]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5762, 0.3639, 0.1811, 0.5706, 0.8379, 0.5178, 0.5568, 0.5320, 0.5309],\n",
      "        [0.5563, 0.6356, 0.2760, 0.5963, 0.5279, 0.4025, 0.6220, 0.4145, 0.4322],\n",
      "        [0.3465, 0.4790, 0.4273, 0.4975, 0.5565, 0.3692, 0.2433, 0.7871, 0.5968],\n",
      "        [0.3729, 0.4364, 0.4758, 0.4371, 0.5183, 0.3757, 0.3025, 0.6143, 0.4800]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5120, 0.2533, 0.3893, 0.4913, 0.6503, 0.5048, 0.3675, 0.4017, 0.5454],\n",
      "        [0.7037, 0.5154, 0.3765, 0.4609, 0.5686, 0.4149, 0.5549, 0.4394, 0.3837],\n",
      "        [0.6317, 0.4698, 0.3885, 0.2438, 0.7026, 0.4294, 0.2579, 0.7299, 0.7977],\n",
      "        [0.3994, 0.5073, 0.2245, 0.3658, 0.4316, 0.4413, 0.4828, 0.5159, 0.5872]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5657, 0.5097, 0.4056, 0.7059, 0.5509, 0.3518, 0.4490, 0.5222, 0.3446],\n",
      "        [0.5121, 0.6358, 0.5229, 0.5522, 0.5490, 0.3460, 0.5228, 0.6567, 0.2914],\n",
      "        [0.4671, 0.6391, 0.1658, 0.8443, 0.5601, 0.4305, 0.7642, 0.2731, 0.4407],\n",
      "        [0.3883, 0.6147, 0.2534, 0.7071, 0.3000, 0.0931, 0.4051, 0.4414, 0.5638]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.2263, 0.3403, 0.9795, 0.6083, 0.6879, 0.5148, 0.5958, 0.5289, 0.2230],\n",
      "        [0.6119, 0.5933, 0.2578, 0.4067, 0.6737, 0.3901, 0.2723, 0.5549, 0.7331],\n",
      "        [0.5254, 0.5823, 0.4777, 0.5446, 0.7214, 0.3663, 0.5070, 0.4192, 0.7187],\n",
      "        [0.6782, 0.4085, 0.6849, 0.3203, 0.8976, 0.5271, 0.4315, 0.3457, 0.5447]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.3632, 0.4233, 0.4923, 0.5289, 0.8093, 0.4327, 0.4928, 0.5567, 0.3163],\n",
      "        [0.5179, 0.3774, 0.5721, 0.5249, 0.5614, 0.4056, 0.5396, 0.6079, 0.4385],\n",
      "        [0.4167, 0.4975, 0.3032, 0.2621, 0.7829, 0.3719, 0.3765, 0.3431, 0.5406],\n",
      "        [0.5484, 0.6084, 0.7151, 0.4052, 0.4924, 0.6563, 0.3851, 0.3724, 0.6248]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4534, 0.3743, 0.4260, 0.5310, 0.6937, 0.3017, 0.4259, 0.7643, 0.5322],\n",
      "        [0.5567, 0.4217, 0.2025, 0.5800, 0.7039, 0.3288, 0.4224, 0.4220, 0.2805],\n",
      "        [0.5879, 0.7740, 0.3734, 0.4845, 0.6287, 0.6111, 0.6242, 0.5525, 0.5360],\n",
      "        [0.4976, 0.4607, 0.6963, 0.6319, 0.4466, 0.2797, 0.2250, 0.2690, 0.0084]])\n",
      "batch_labels:  tensor([1., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.5350, 0.5480, 0.2344, 0.4091, 0.5659, 0.4546, 0.5084, 0.6883, 0.3872],\n",
      "        [0.6030, 0.5863, 0.5332, 0.4182, 0.5738, 0.4251, 0.3908, 0.4102, 0.1844],\n",
      "        [0.5864, 0.3366, 0.3193, 0.8570, 0.5684, 0.3239, 0.4658, 0.2294, 0.5414],\n",
      "        [0.5820, 0.3368, 0.4223, 0.5324, 0.5945, 0.3927, 0.4461, 0.5025, 0.4122]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4749, 0.4360, 0.4179, 0.3358, 0.5801, 0.4711, 0.4578, 0.4505, 0.5344],\n",
      "        [0.3773, 0.4610, 0.3151, 0.4269, 0.9045, 0.2364, 0.2223, 0.5091, 0.7482],\n",
      "        [0.5421, 0.6188, 0.3834, 0.4815, 0.4155, 0.3683, 0.4293, 0.4729, 0.2578],\n",
      "        [0.3248, 0.4997, 0.6213, 0.5562, 0.5860, 0.6123, 0.3085, 0.4864, 0.4028]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.2687, 0.4846, 0.3028, 0.5369, 0.5042, 0.3706, 0.2974, 0.3197, 0.7158],\n",
      "        [0.5193, 0.6743, 0.2945, 0.4866, 0.5033, 0.5021, 0.4456, 0.7302, 0.7097],\n",
      "        [0.5160, 0.6571, 0.2803, 0.5787, 0.2705, 0.3627, 0.5286, 0.6348, 0.6586],\n",
      "        [0.3828, 0.7800, 0.3488, 0.2867, 0.6759, 0.4246, 0.4257, 0.3714, 0.7329]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.3257, 0.5571, 0.3516, 0.4431, 0.4913, 0.2765, 0.4766, 0.7024, 0.4903],\n",
      "        [0.4028, 0.3947, 0.2562, 0.5002, 0.6541, 0.6054, 0.3859, 0.5087, 0.7363],\n",
      "        [0.5604, 0.5724, 0.2929, 0.2858, 0.4642, 0.5012, 0.4833, 0.6366, 0.4233],\n",
      "        [0.3492, 0.4785, 0.5152, 0.3068, 0.4871, 0.2370, 0.3570, 0.9321, 0.4132]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.3734, 0.3992, 0.4785, 0.5688, 0.7018, 0.3629, 0.4790, 0.6339, 0.3781],\n",
      "        [0.4629, 0.4812, 0.3409, 0.4247, 0.7151, 0.4616, 0.1505, 0.6496, 0.5592],\n",
      "        [0.6252, 0.5017, 0.2010, 0.5521, 0.5788, 0.5679, 0.4068, 0.6832, 0.1263],\n",
      "        [0.6812, 0.6310, 0.3983, 0.3404, 0.5264, 0.3500, 0.5961, 0.5784, 0.5666]])\n",
      "batch_labels:  tensor([0., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.3171, 0.4599, 0.4925, 0.4576, 0.6414, 0.3246, 0.4750, 0.5718, 0.6874],\n",
      "        [0.6245, 0.5047, 0.3094, 0.6433, 0.7128, 0.5170, 0.6175, 0.4558, 0.4645],\n",
      "        [0.4546, 0.6233, 0.6150, 0.6442, 0.7286, 0.2227, 0.4231, 0.7671, 0.6228],\n",
      "        [0.5010, 0.4835, 0.4434, 0.4445, 0.5404, 0.3946, 0.4299, 0.6055, 0.6067]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.6066, 0.4639, 0.3609, 0.2159, 0.6736, 0.3311, 0.3144, 0.5035, 0.3843],\n",
      "        [0.4930, 0.3963, 0.3534, 0.3260, 0.7080, 0.5640, 0.5364, 0.4856, 0.6838],\n",
      "        [0.6026, 0.4188, 0.2050, 0.5192, 0.5096, 0.4941, 0.7920, 0.3794, 0.7202],\n",
      "        [0.1276, 0.5864, 0.4045, 0.4583, 0.6108, 0.2528, 0.3748, 0.6078, 0.4902]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.6202, 0.5818, 0.2430, 0.5247, 0.5505, 0.3034, 0.6740, 0.4001, 0.4612],\n",
      "        [0.4688, 0.4935, 0.6024, 0.7230, 0.6123, 0.5373, 0.2668, 0.5032, 0.5116],\n",
      "        [0.5187, 0.5783, 0.4506, 0.2592, 0.5873, 0.4863, 0.4156, 0.4698, 0.2201],\n",
      "        [0.7336, 0.3813, 0.2760, 0.4265, 0.6595, 0.3162, 0.4694, 0.3767, 0.2425]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5898, 0.6821, 0.3001, 0.4020, 0.4086, 0.1690, 0.3388, 0.4702, 0.4078],\n",
      "        [0.4921, 0.6005, 0.4678, 0.5078, 0.5812, 0.3226, 0.4468, 0.7831, 0.4242],\n",
      "        [0.4233, 0.3102, 0.4145, 0.4385, 0.4934, 0.3474, 0.6214, 0.3954, 0.5589],\n",
      "        [0.2984, 0.5490, 0.6059, 0.4617, 0.6962, 0.5953, 0.4201, 0.3134, 0.5851]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.3348, 0.6875, 0.3206, 0.5123, 0.3083, 0.2785, 0.4240, 0.5789, 0.6205],\n",
      "        [0.5348, 0.4248, 0.2598, 0.3962, 0.6256, 0.2785, 0.6031, 0.2906, 0.3749],\n",
      "        [0.5494, 0.4239, 0.3209, 0.5263, 0.5944, 0.3074, 0.2757, 0.5866, 0.5398],\n",
      "        [0.4930, 0.3850, 0.3150, 0.3845, 0.6634, 0.4891, 0.3424, 0.3156, 0.5256]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.2900, 0.1930, 0.6062, 0.5598, 0.8027, 0.4262, 0.4916, 0.4854, 0.5607],\n",
      "        [0.3921, 0.4874, 0.4012, 0.5431, 0.6080, 0.4304, 0.5240, 0.3609, 0.5177],\n",
      "        [0.4046, 0.4427, 0.2262, 0.4018, 0.6970, 0.3696, 0.5472, 0.2319, 0.5202],\n",
      "        [0.3554, 0.4984, 0.3019, 0.4803, 0.5893, 0.4442, 0.1073, 0.5567, 0.4073]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.3609, 0.5207, 0.6566, 0.5121, 0.5193, 0.6734, 0.6062, 0.5750, 0.3657],\n",
      "        [0.3993, 0.4850, 0.6334, 0.5688, 0.7095, 0.1928, 0.4180, 0.4472, 0.4881],\n",
      "        [0.6378, 0.3872, 0.6150, 0.1490, 0.7718, 0.3331, 0.5794, 0.3634, 0.5592],\n",
      "        [0.4961, 0.4319, 0.6973, 0.6135, 0.4329, 0.5776, 0.3465, 0.5828, 0.2973]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.3716, 0.6767, 0.1779, 0.5480, 0.4340, 0.5342, 0.4202, 0.6824, 0.1810],\n",
      "        [0.5610, 0.4289, 0.3268, 0.3671, 0.6795, 0.2803, 0.6627, 0.4582, 0.2795],\n",
      "        [0.5948, 0.4602, 0.2300, 0.2222, 0.5089, 0.4749, 0.6051, 0.3483, 0.4980],\n",
      "        [0.4457, 0.5395, 0.1196, 0.8446, 0.5577, 0.3081, 0.5705, 0.5695, 0.7286]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4772, 0.6790, 0.1365, 0.7647, 0.8263, 0.3110, 0.6703, 0.3021, 0.4698],\n",
      "        [0.3939, 0.4689, 0.4548, 0.1817, 0.5938, 0.4615, 0.5360, 0.5542, 0.6752],\n",
      "        [0.6045, 0.5918, 0.6892, 0.4768, 0.6952, 0.2518, 0.6807, 0.3923, 0.2955],\n",
      "        [0.4304, 0.3528, 0.3465, 0.7405, 0.5146, 0.5501, 0.5873, 0.2895, 0.4666]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.0000, 0.3241, 0.6891, 0.1765, 0.4394, 0.4376, 0.4435, 0.4656, 0.4154],\n",
      "        [0.5238, 0.4973, 0.6097, 0.6052, 0.4711, 0.2691, 0.6757, 0.6184, 0.2864],\n",
      "        [0.4606, 0.5505, 0.4104, 0.4166, 0.5251, 0.5370, 0.4303, 0.5791, 0.6157],\n",
      "        [0.2944, 0.4728, 0.3919, 0.4743, 0.5572, 0.1904, 0.5674, 0.6413, 0.5791]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5185, 0.5729, 0.3228, 0.5881, 0.4697, 0.5341, 0.3364, 0.7473, 0.4686],\n",
      "        [0.4611, 0.5328, 0.3926, 0.4139, 0.7687, 0.6273, 0.3990, 0.5438, 0.5634],\n",
      "        [0.2628, 0.5670, 0.2558, 0.5255, 0.5622, 0.3075, 0.7887, 0.2357, 0.3357],\n",
      "        [0.4433, 0.4648, 0.4051, 0.5701, 0.5624, 0.0585, 0.3000, 0.4537, 0.7352]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4523, 0.4871, 0.3208, 0.6340, 0.5879, 0.5724, 0.8535, 0.3744, 0.2354],\n",
      "        [0.6226, 0.5410, 0.2279, 0.4525, 0.3820, 0.3583, 0.6736, 0.5145, 0.5117],\n",
      "        [0.5597, 0.5476, 0.3443, 0.6147, 0.5208, 0.2850, 0.7671, 0.4782, 0.4301],\n",
      "        [0.4242, 0.4641, 0.4597, 0.5416, 0.6156, 0.3884, 0.3978, 0.4492, 0.4400]])\n",
      "batch_labels:  tensor([0., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.7215, 0.6976, 0.2885, 0.2216, 0.5166, 0.5185, 0.6056, 0.6523, 0.4125],\n",
      "        [0.5493, 0.7553, 0.3040, 0.5863, 0.3477, 0.4315, 0.2966, 0.3956, 0.3844],\n",
      "        [0.7033, 0.3552, 0.5663, 0.4021, 0.7849, 0.6155, 0.3768, 0.3249, 0.8137],\n",
      "        [0.5625, 0.4112, 0.4723, 0.3975, 0.5935, 0.2649, 0.4659, 0.5801, 0.3461]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3095, 0.4706, 0.2597, 0.6046, 0.6966, 0.5745, 0.3639, 0.4904, 0.4611],\n",
      "        [0.4129, 0.5824, 0.2273, 0.5448, 0.5843, 0.1482, 0.5032, 0.4050, 0.8323],\n",
      "        [0.4400, 0.7579, 0.2396, 0.5191, 0.5672, 0.6558, 0.5749, 0.5626, 0.5263],\n",
      "        [0.6047, 0.5871, 0.3208, 0.5879, 0.5179, 0.3431, 0.6022, 0.2703, 0.4435]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5202, 0.4102, 0.3537, 0.6587, 0.7247, 0.1966, 0.8513, 0.6286, 0.4616],\n",
      "        [0.5539, 0.5588, 0.3477, 0.5665, 0.4866, 0.3024, 0.6581, 0.4216, 0.5356],\n",
      "        [0.5600, 0.5067, 0.1859, 0.5219, 0.7266, 0.3707, 0.5659, 0.5721, 0.3053],\n",
      "        [0.3697, 0.5360, 0.3929, 0.5677, 0.5284, 0.3580, 0.4746, 0.6462, 0.2925]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5873, 0.6060, 0.2813, 0.6889, 0.6226, 0.5438, 0.8046, 0.5786, 0.2597],\n",
      "        [0.5984, 0.2418, 0.3689, 0.5633, 0.6136, 0.2881, 0.3444, 0.4846, 0.2829],\n",
      "        [0.5002, 0.5354, 0.4417, 0.3418, 0.4639, 0.4031, 0.4288, 0.4057, 0.4887],\n",
      "        [0.3397, 0.4113, 0.2575, 0.3794, 0.3936, 0.7589, 0.2248, 0.2618, 0.3374]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.3828, 0.3141, 0.7633, 0.4413, 0.5497, 0.1553, 0.3640, 0.5479, 0.4397],\n",
      "        [0.2952, 0.5713, 0.5361, 0.6169, 0.5809, 0.3286, 0.5474, 0.2703, 0.2686],\n",
      "        [0.4271, 0.4850, 0.4724, 0.6539, 0.5204, 0.3152, 0.5367, 0.5650, 0.6801],\n",
      "        [0.7096, 0.5808, 0.5900, 0.4093, 0.6729, 0.3123, 0.4673, 0.6004, 0.2398]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3940, 0.4030, 0.2868, 0.5021, 0.7355, 0.3942, 0.3876, 0.6734, 0.3997],\n",
      "        [0.3716, 0.4564, 0.3909, 0.7103, 0.5398, 0.5266, 0.3908, 0.6820, 0.2974],\n",
      "        [0.4471, 0.6980, 0.7057, 0.4522, 0.4778, 0.4279, 0.5550, 0.4016, 0.5342],\n",
      "        [0.3274, 0.5322, 0.5052, 0.3306, 0.5530, 0.5568, 0.4782, 0.4902, 0.7028]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.6622, 0.5255, 0.2391, 0.5064, 0.5484, 0.5634, 0.4126, 0.3054, 0.4292],\n",
      "        [0.4282, 0.3207, 0.2630, 0.4448, 0.7196, 0.3381, 0.5814, 0.5249, 0.5475],\n",
      "        [0.3242, 0.6072, 0.4253, 0.6793, 0.5077, 0.3714, 0.4200, 0.4455, 0.5073],\n",
      "        [0.4103, 0.2794, 0.2373, 0.3673, 0.4283, 0.6106, 0.3964, 0.5140, 0.5119]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3574, 0.5120, 0.2933, 0.4531, 0.5623, 0.1844, 0.4156, 0.5008, 0.6718],\n",
      "        [0.5107, 0.4363, 0.4388, 0.3788, 0.6257, 0.5430, 0.6082, 0.3675, 0.4334],\n",
      "        [0.2387, 0.3496, 0.4043, 0.4627, 0.4475, 0.1917, 0.3028, 0.6175, 0.4584],\n",
      "        [0.6487, 0.1901, 0.4682, 0.4017, 0.6087, 0.3228, 0.3507, 0.3986, 0.6815]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.6425, 0.5841, 0.2463, 0.3092, 0.5809, 0.1997, 0.3457, 0.5245, 0.3939],\n",
      "        [0.3825, 0.4550, 0.4704, 0.5083, 0.5767, 0.4677, 0.6538, 0.5484, 0.5284],\n",
      "        [0.6440, 0.7805, 0.6782, 0.5320, 0.4146, 0.4271, 0.6484, 0.5713, 0.7976],\n",
      "        [0.5010, 0.4109, 0.3381, 0.4382, 0.6918, 0.1700, 0.2045, 0.6950, 0.3858]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.7518, 0.5753, 0.1954, 0.5349, 0.4863, 0.5357, 0.6358, 0.6478, 0.3007],\n",
      "        [0.5395, 0.6704, 0.2479, 0.4174, 0.6936, 0.3897, 0.3331, 0.6695, 0.1957],\n",
      "        [0.4281, 0.4422, 0.2637, 0.3777, 0.4683, 0.3444, 0.3786, 0.4624, 0.7945],\n",
      "        [0.9528, 0.3251, 0.3230, 0.4539, 0.5848, 0.4517, 0.6044, 0.6698, 0.2143]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.6363, 0.5016, 0.4167, 0.5212, 0.6241, 0.6342, 0.5262, 0.5833, 0.6035],\n",
      "        [0.3676, 0.4152, 0.5052, 0.6148, 0.5341, 0.5058, 0.4655, 0.3803, 0.4128],\n",
      "        [0.3357, 0.2999, 0.3544, 0.4217, 0.6816, 0.2626, 0.5267, 0.4194, 0.4349],\n",
      "        [0.5605, 0.8351, 0.4259, 0.5258, 0.4101, 0.1907, 0.3868, 0.5323, 0.3149]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3470, 0.3568, 0.4789, 0.8650, 0.4573, 0.1842, 0.5793, 0.5382, 0.4391],\n",
      "        [0.4439, 0.3480, 0.2665, 0.5290, 0.6063, 0.2416, 0.2837, 0.2558, 0.7946],\n",
      "        [0.5132, 0.6654, 0.6360, 0.3242, 0.7050, 0.3335, 0.5987, 0.7022, 0.5389],\n",
      "        [0.5436, 0.4972, 0.4810, 0.5317, 0.5485, 0.2650, 0.3403, 0.4778, 0.3434]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4090, 0.8796, 0.0591, 0.2285, 0.7462, 0.4450, 0.1678, 0.3516, 0.3918],\n",
      "        [0.4901, 0.5416, 0.2809, 0.3525, 0.6885, 0.5994, 0.3284, 0.5545, 0.7686],\n",
      "        [1.0000, 0.6651, 0.4217, 0.3616, 0.7161, 0.4697, 0.4536, 0.5569, 0.3411],\n",
      "        [0.4734, 0.3315, 0.4418, 0.6054, 0.4144, 0.2328, 0.5556, 0.5317, 0.4035]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5248, 0.6226, 0.2835, 0.5805, 0.6281, 0.2357, 0.4400, 0.4469, 0.2934],\n",
      "        [0.4533, 0.4234, 0.5390, 0.2558, 0.5558, 0.5860, 0.5811, 0.6560, 0.3321],\n",
      "        [0.5426, 0.1972, 0.2966, 0.4620, 0.6399, 0.3020, 0.4353, 0.5257, 0.3856],\n",
      "        [0.3838, 0.5703, 0.4903, 0.4478, 0.4473, 0.5853, 0.4381, 0.7914, 0.5967]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4349, 0.5340, 0.2720, 0.5420, 0.6597, 0.4555, 0.4997, 0.5395, 0.5352],\n",
      "        [0.4116, 0.4661, 0.6551, 0.2735, 0.3527, 0.5973, 0.3713, 0.5953, 0.4380],\n",
      "        [0.5482, 0.6573, 0.2930, 0.4032, 0.5526, 0.5776, 0.6287, 0.4485, 0.6409],\n",
      "        [0.5250, 0.4510, 0.2566, 0.5184, 0.5871, 0.5093, 0.2726, 0.6412, 0.6041]])\n",
      "batch_labels:  tensor([1., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.5452, 0.6216, 0.3414, 0.4914, 0.4572, 0.4211, 0.5222, 0.5734, 0.4462],\n",
      "        [0.4256, 0.5486, 0.1962, 0.6388, 0.5348, 0.5984, 0.3819, 0.3447, 0.5782],\n",
      "        [0.5065, 0.3894, 0.4007, 0.4169, 0.4059, 0.4273, 0.5729, 0.4846, 0.9791],\n",
      "        [0.3464, 0.8472, 0.4723, 0.4039, 0.6966, 0.1740, 0.5390, 0.5370, 0.3875]])\n",
      "batch_labels:  tensor([1., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4264, 0.3573, 0.2415, 0.5242, 0.6752, 0.4501, 0.6661, 0.4836, 0.1437],\n",
      "        [0.4809, 0.3875, 0.7169, 0.1688, 0.3876, 0.1791, 0.5565, 0.5526, 0.3232],\n",
      "        [0.6553, 0.6668, 0.2232, 0.3744, 0.4184, 0.2325, 0.4196, 0.4076, 0.4195],\n",
      "        [0.4196, 0.6290, 0.3553, 0.5773, 0.2742, 0.1348, 0.3004, 0.3818, 0.5124]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4742, 0.5932, 0.3956, 0.4947, 0.4990, 0.3279, 0.6707, 0.3919, 0.4341],\n",
      "        [0.4266, 0.4343, 0.4251, 0.4912, 0.5467, 0.5878, 0.4546, 0.4460, 0.1670],\n",
      "        [0.5418, 0.5565, 0.5207, 0.7180, 0.4697, 0.2793, 0.4724, 0.5467, 0.4894],\n",
      "        [0.4486, 0.4526, 0.3597, 0.6015, 0.6737, 0.6290, 0.4535, 0.5240, 0.6109]])\n",
      "batch_labels:  tensor([1., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.5404, 0.2044, 0.5968, 0.3260, 0.7435, 0.4737, 0.6651, 0.6440, 0.4924],\n",
      "        [0.4791, 0.4657, 0.8158, 0.4045, 0.6355, 0.3114, 0.4195, 0.4347, 0.3127],\n",
      "        [0.7315, 0.5172, 0.1951, 0.5175, 0.8648, 0.4719, 0.6006, 0.4732, 0.4773],\n",
      "        [0.6501, 0.8215, 0.4223, 0.4698, 0.7651, 0.5009, 0.4510, 0.5448, 0.6053]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5098, 0.6160, 0.4271, 0.5114, 0.4165, 0.1906, 0.3022, 0.5945, 0.5771],\n",
      "        [0.4163, 0.4454, 0.4203, 0.4088, 0.6703, 0.6632, 0.2254, 0.4297, 0.6878],\n",
      "        [0.5826, 0.4548, 0.3791, 0.4921, 0.5005, 0.3830, 0.4673, 0.5477, 0.2289],\n",
      "        [0.5663, 0.3930, 0.3356, 0.5701, 0.7855, 0.2700, 0.5231, 0.5149, 0.4531]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4508, 0.4901, 0.3429, 0.5325, 0.5281, 0.3227, 0.4312, 0.5827, 0.3897],\n",
      "        [0.5075, 0.4376, 0.2361, 0.3921, 0.5368, 0.3994, 0.4100, 0.4754, 0.4552],\n",
      "        [0.4382, 0.5471, 0.5536, 0.2673, 0.6270, 0.6623, 0.5548, 0.5583, 0.5080],\n",
      "        [0.8210, 0.4502, 0.0675, 0.5134, 0.7669, 0.4960, 0.3483, 0.5271, 0.3073]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4349, 0.5420, 0.5802, 0.3881, 0.4812, 0.3863, 0.4002, 0.6123, 0.1252],\n",
      "        [0.5700, 0.2125, 0.4204, 0.6290, 0.5360, 0.3565, 0.5273, 0.4686, 0.5610],\n",
      "        [0.4459, 0.6637, 0.6077, 0.6629, 0.4725, 0.2824, 0.2827, 0.4393, 0.1637],\n",
      "        [0.2967, 0.4824, 0.2217, 0.5829, 0.4430, 0.5406, 0.4556, 0.5880, 0.4903]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4250, 0.4467, 0.5519, 0.5311, 0.5389, 0.5380, 0.3708, 0.6300, 0.1272],\n",
      "        [0.5553, 0.6266, 0.2206, 0.5038, 0.6176, 0.4418, 0.1557, 0.4726, 0.5528],\n",
      "        [0.3633, 0.3223, 0.4357, 0.4190, 0.7386, 0.1927, 0.4190, 0.3730, 0.4451],\n",
      "        [0.3254, 0.4333, 0.3912, 0.4587, 0.7909, 0.3075, 0.6445, 0.6754, 0.4777]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.6027, 0.6323, 0.4813, 0.5356, 0.6278, 0.3381, 0.4197, 0.6204, 0.6238],\n",
      "        [0.4454, 0.4165, 0.4542, 0.5839, 0.5822, 0.1823, 0.3369, 0.5331, 0.4424],\n",
      "        [0.5118, 0.4172, 0.3974, 0.5535, 0.4667, 0.3113, 0.6132, 0.4178, 0.7161],\n",
      "        [0.5532, 0.6175, 0.4085, 0.3861, 0.4869, 0.3378, 0.4518, 0.2989, 0.2058]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4245, 0.2765, 0.2043, 0.6593, 0.8768, 0.3833, 0.5134, 0.3417, 0.7531],\n",
      "        [0.4121, 0.5264, 0.4464, 0.5369, 0.5245, 0.4225, 0.6372, 0.4453, 0.6219],\n",
      "        [0.3533, 0.6818, 0.4998, 0.0000, 0.3677, 0.4544, 0.4691, 0.5453, 0.6317],\n",
      "        [0.4701, 0.3906, 0.3001, 0.4260, 0.5729, 0.3685, 0.3478, 0.3772, 0.5410]])\n",
      "batch_labels:  tensor([1., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.7486, 0.5194, 0.2412, 0.5090, 0.7967, 0.2523, 0.5996, 0.5558, 0.4704],\n",
      "        [0.4719, 0.5083, 0.4574, 0.4738, 0.6182, 0.4925, 0.6546, 0.5275, 0.5368],\n",
      "        [0.4263, 0.4778, 0.4888, 0.4305, 0.6219, 0.0802, 0.5014, 0.5618, 0.5010],\n",
      "        [0.4589, 0.4204, 0.6774, 0.5133, 0.4235, 0.1622, 0.6943, 0.6307, 0.8881]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4303, 0.3679, 0.8520, 0.4910, 0.4845, 0.2594, 0.1193, 0.4068, 0.6680],\n",
      "        [0.3430, 0.3269, 0.3525, 0.6471, 0.7444, 0.3928, 0.3883, 0.5182, 0.4798],\n",
      "        [0.6946, 0.2312, 0.3625, 0.6817, 0.4630, 0.4087, 0.3891, 0.6076, 0.2964],\n",
      "        [0.7380, 0.7761, 0.6907, 0.1546, 0.4452, 0.4924, 0.4475, 0.4916, 0.8567]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5208, 0.5960, 0.1391, 0.4171, 0.5163, 0.5748, 0.5235, 0.3661, 0.6799],\n",
      "        [0.3440, 0.6043, 0.3825, 0.4141, 0.5187, 0.3349, 0.6383, 0.3927, 0.3909],\n",
      "        [0.4434, 0.5085, 0.4120, 0.4031, 0.4958, 0.3588, 0.6701, 0.4648, 0.5132],\n",
      "        [0.2912, 0.2518, 0.5167, 0.5786, 0.6313, 0.3640, 0.4123, 0.6514, 0.4633]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4597, 0.3738, 0.5402, 0.6358, 0.4077, 0.6017, 0.3531, 0.6505, 0.5484],\n",
      "        [0.5869, 0.7063, 0.1355, 0.6341, 0.6944, 0.2664, 0.4799, 0.6599, 0.5865],\n",
      "        [0.4165, 0.6133, 0.4293, 0.4116, 0.5026, 0.1502, 0.5236, 0.2735, 0.4515],\n",
      "        [0.5418, 0.6064, 0.5329, 0.4157, 0.5439, 0.5947, 0.6358, 0.6595, 0.6995]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4062, 0.5354, 0.6561, 0.5519, 0.5682, 0.4806, 0.4752, 0.7646, 0.5790],\n",
      "        [0.3939, 0.2688, 0.2894, 0.5510, 0.7429, 0.3932, 0.4462, 0.4982, 0.4801],\n",
      "        [0.4174, 0.7606, 0.4798, 0.5332, 0.7234, 0.5664, 0.4054, 0.6402, 0.3062],\n",
      "        [0.3607, 0.4169, 0.5902, 0.5979, 0.5404, 0.5123, 0.5891, 0.7432, 0.7782]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4002, 0.4771, 0.2760, 0.5725, 0.5228, 0.4049, 0.5119, 0.6307, 0.2523],\n",
      "        [0.2515, 0.5291, 0.1624, 0.7628, 0.5231, 0.6200, 0.5336, 0.4906, 0.4751],\n",
      "        [0.5176, 0.6614, 0.5535, 0.5116, 0.4389, 0.4117, 0.8049, 0.6829, 0.6145],\n",
      "        [0.5521, 0.4469, 0.3349, 0.4612, 0.6002, 0.4202, 0.3464, 0.5832, 0.4674]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4506, 0.4239, 0.4706, 0.4382, 0.5327, 0.5501, 0.7707, 0.4466, 0.3306],\n",
      "        [0.3630, 0.4258, 0.4999, 0.4178, 0.5888, 0.2298, 0.6556, 0.4635, 0.1605],\n",
      "        [0.4562, 0.4732, 0.3518, 0.4404, 0.6817, 0.3014, 0.5082, 0.8029, 0.4980],\n",
      "        [0.4094, 0.3009, 0.3446, 0.2963, 0.5426, 0.3857, 0.5371, 0.6569, 0.5612]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5002, 0.4930, 0.3230, 0.3011, 0.5399, 0.3043, 0.5096, 0.3973, 0.4531],\n",
      "        [0.7208, 0.7001, 0.4350, 0.2829, 0.4852, 0.3371, 0.5306, 0.5393, 0.4521],\n",
      "        [0.5128, 0.5402, 0.4592, 0.3193, 0.6499, 0.3648, 0.2322, 0.4776, 0.6444],\n",
      "        [0.6288, 0.4391, 0.4583, 0.6321, 0.5631, 0.3209, 0.6216, 0.3457, 0.6504]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4295, 0.3034, 0.6150, 0.1954, 0.4444, 0.4963, 0.7554, 0.3953, 0.7771],\n",
      "        [0.5467, 0.5723, 0.4440, 0.5321, 0.6667, 0.6197, 0.5262, 0.8544, 0.5383],\n",
      "        [0.6236, 0.5530, 0.4711, 0.4970, 0.5685, 0.4147, 0.1996, 0.6917, 0.2826],\n",
      "        [0.6567, 0.7496, 0.4734, 0.3729, 0.4137, 0.4824, 0.4102, 0.7046, 0.4548]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5961, 0.4495, 0.2232, 0.5120, 0.6612, 0.6985, 0.5534, 0.6010, 0.4689],\n",
      "        [0.5701, 0.4128, 0.2200, 0.5031, 0.5811, 0.7031, 0.5100, 0.2682, 0.4284],\n",
      "        [0.4602, 0.2793, 0.2235, 0.6583, 0.6020, 0.2508, 0.6009, 0.6714, 0.1554],\n",
      "        [0.4740, 0.6470, 0.3243, 0.6277, 0.6066, 0.3326, 0.4712, 0.6127, 0.7360]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4519, 0.5126, 0.3326, 0.5040, 0.5865, 0.1004, 0.4646, 0.3837, 0.3619],\n",
      "        [0.4438, 0.6214, 0.7994, 0.3765, 0.6647, 0.4239, 0.3703, 0.6246, 0.4432],\n",
      "        [0.7241, 0.4453, 0.1370, 0.3559, 0.5931, 0.1631, 0.4543, 0.3638, 0.7383],\n",
      "        [0.3502, 0.4849, 0.3192, 0.5732, 0.4409, 0.3120, 0.6388, 0.7215, 0.4917]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4364, 0.4298, 0.3845, 0.4852, 0.5876, 0.1558, 0.6152, 0.3325, 0.4754],\n",
      "        [0.5817, 0.5115, 0.1982, 0.3339, 0.5123, 0.3615, 0.4452, 0.6292, 0.2646],\n",
      "        [0.6762, 0.6174, 0.5584, 0.9035, 0.5294, 0.5296, 0.6810, 0.6309, 0.3726],\n",
      "        [0.6448, 0.5291, 0.4337, 0.3566, 0.5844, 0.4812, 0.4328, 0.3323, 0.6030]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.6125, 0.4103, 0.3563, 0.3617, 0.8828, 0.4677, 0.5677, 0.7048, 0.7275],\n",
      "        [0.6044, 0.5861, 0.5090, 0.4726, 0.4722, 0.5606, 0.5645, 0.6176, 0.5147],\n",
      "        [0.6601, 0.5161, 0.2488, 0.5448, 0.6734, 0.2480, 0.5247, 0.4749, 0.5311],\n",
      "        [0.7242, 0.4811, 0.1531, 0.2990, 0.5042, 0.2352, 0.6581, 0.5196, 0.4984]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3819, 0.4335, 0.3532, 0.3255, 0.5007, 0.5600, 0.4188, 0.4357, 0.5498],\n",
      "        [0.5568, 0.3905, 0.5057, 0.6774, 0.6391, 0.5724, 0.3948, 0.6176, 0.5831],\n",
      "        [0.2538, 0.3697, 0.6702, 0.4511, 0.5616, 0.4820, 0.4985, 0.3639, 0.4386],\n",
      "        [0.5137, 0.5063, 0.3869, 0.3410, 0.5006, 0.4531, 0.5025, 0.5470, 0.5342]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.6418, 0.5327, 0.3986, 0.3896, 0.5471, 0.5339, 0.6517, 0.5877, 0.5165],\n",
      "        [0.5755, 0.2200, 0.1773, 0.3781, 0.3938, 0.5189, 0.3928, 0.7108, 0.2886],\n",
      "        [0.3746, 0.5704, 0.7091, 0.5737, 0.5391, 0.2790, 0.6107, 0.4820, 0.4386],\n",
      "        [0.2470, 0.7000, 0.4368, 0.4454, 0.6760, 0.4358, 0.4476, 0.4411, 0.6551]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.3480, 0.3423, 0.3374, 0.4085, 0.5754, 0.2533, 0.5642, 0.5781, 0.5232],\n",
      "        [0.5551, 0.5993, 0.2215, 0.5697, 0.6564, 0.2704, 0.5442, 0.6548, 0.2951],\n",
      "        [0.6287, 0.4033, 0.3346, 0.4356, 0.7815, 0.3590, 0.6218, 0.5913, 0.3059],\n",
      "        [0.5557, 0.6254, 0.3412, 0.4105, 0.6458, 0.4907, 0.3949, 0.4025, 0.4222]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4867, 0.4786, 0.4533, 0.4148, 0.5739, 0.5077, 0.4777, 0.5372, 0.4460],\n",
      "        [0.6615, 0.7172, 0.3044, 0.4495, 0.6071, 0.5511, 0.7072, 0.4339, 0.0838],\n",
      "        [0.5239, 0.4403, 0.3187, 0.6123, 0.7849, 0.6583, 0.5067, 0.4261, 0.1469],\n",
      "        [0.5358, 0.4525, 0.5166, 0.3675, 0.3708, 0.4085, 0.4760, 0.7192, 0.6174]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.6193, 0.5196, 0.3777, 0.3003, 0.5366, 0.3681, 0.4663, 0.3410, 0.4314],\n",
      "        [0.4565, 0.5137, 0.3721, 0.6203, 0.5528, 0.3837, 0.5120, 0.6175, 0.7435],\n",
      "        [0.5469, 0.5443, 0.6041, 0.5572, 0.4833, 0.2638, 0.6914, 0.6242, 0.6225],\n",
      "        [0.4386, 0.3330, 0.4047, 0.4637, 0.4593, 0.3980, 0.4709, 0.4966, 0.3845]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5683, 0.5227, 0.2194, 0.5043, 0.5836, 0.4443, 0.5139, 0.5426, 0.4092],\n",
      "        [0.4772, 0.6911, 0.6912, 0.6911, 0.1652, 0.3169, 0.3722, 0.5649, 0.4767],\n",
      "        [0.6355, 0.4545, 0.4388, 0.4153, 0.5858, 0.5147, 0.2451, 0.4797, 0.5580],\n",
      "        [0.4993, 0.5255, 0.3164, 0.6035, 0.6608, 0.2666, 0.2573, 0.3535, 0.6567]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5276, 0.5079, 0.4693, 0.4948, 0.4002, 0.3152, 0.4408, 0.5286, 0.4698],\n",
      "        [0.4559, 0.5282, 0.2985, 0.4099, 0.5615, 0.5078, 0.5779, 0.3260, 0.4160],\n",
      "        [0.4703, 0.6450, 0.1675, 0.3879, 0.2677, 0.3700, 0.4284, 0.5701, 0.3909],\n",
      "        [0.6231, 0.6259, 0.3173, 0.3016, 0.5448, 0.2692, 0.4893, 0.4831, 0.4815]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5361, 0.6101, 0.4405, 0.6110, 0.4515, 0.5504, 0.6480, 0.5183, 0.2821],\n",
      "        [0.3494, 0.4959, 0.3386, 0.4945, 0.5972, 0.5695, 0.3438, 0.4553, 0.3324],\n",
      "        [0.4013, 0.6894, 0.5617, 0.5034, 0.2115, 0.5335, 0.8290, 0.5445, 0.8861],\n",
      "        [0.5625, 0.3557, 0.5191, 0.0908, 0.5541, 0.3074, 0.6649, 0.3960, 0.5192]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5725, 0.5896, 0.6741, 0.4996, 0.5196, 0.1440, 0.4365, 0.6065, 0.5909],\n",
      "        [0.5400, 0.5598, 0.4037, 0.3539, 0.6093, 0.3917, 0.2238, 0.4763, 0.2492],\n",
      "        [0.3996, 0.6160, 0.0184, 0.4351, 0.7145, 0.7589, 0.5028, 0.4631, 0.4412],\n",
      "        [0.4737, 0.5327, 0.4630, 0.5943, 0.6048, 0.3259, 0.6985, 0.4307, 0.4571]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5566, 0.5323, 0.2943, 0.5064, 0.5987, 0.3577, 0.6901, 0.4332, 0.4080],\n",
      "        [0.3299, 0.5203, 0.8489, 0.6624, 0.6003, 0.1981, 0.6679, 0.4773, 0.4930],\n",
      "        [0.5224, 0.5324, 0.7091, 0.3588, 0.3624, 0.3628, 0.2752, 0.3850, 0.6019],\n",
      "        [0.5187, 0.4398, 0.4514, 0.5101, 0.5158, 0.1748, 0.4221, 0.1645, 0.5223]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.3244, 0.5143, 0.4352, 0.5529, 0.6377, 0.5641, 0.7158, 0.3099, 0.6327],\n",
      "        [0.5241, 0.3169, 0.0685, 0.7824, 0.9872, 0.2791, 0.5302, 0.5734, 0.2569],\n",
      "        [0.5217, 0.5043, 0.3052, 0.4191, 0.6425, 0.1800, 0.4425, 0.6240, 0.3648],\n",
      "        [0.4670, 0.4466, 0.2939, 0.4840, 0.6445, 0.4224, 0.5812, 0.5271, 0.4995]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4519, 0.4349, 0.1366, 0.4095, 0.7053, 0.3352, 0.5335, 0.5754, 0.9629],\n",
      "        [0.5043, 0.4835, 0.2560, 0.4402, 0.5251, 0.5862, 0.4205, 0.8637, 0.3239],\n",
      "        [0.4506, 0.4255, 0.3561, 0.4250, 0.6933, 0.3143, 0.3823, 0.4596, 0.4344],\n",
      "        [0.4798, 0.5420, 0.3205, 0.4535, 0.4796, 0.5308, 0.4680, 0.5383, 0.6943]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4557, 0.3681, 0.2613, 0.5326, 0.5826, 0.5724, 0.6180, 0.2529, 0.6964],\n",
      "        [0.4854, 0.3373, 0.3143, 0.3004, 0.4173, 0.4314, 0.6523, 0.4066, 0.2304],\n",
      "        [0.2936, 0.3828, 0.4288, 0.5113, 0.4778, 0.2681, 0.4547, 0.3976, 0.4587],\n",
      "        [0.4340, 0.5665, 0.6252, 0.4129, 0.5259, 0.6359, 0.2604, 0.4139, 0.5266]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5185, 0.5354, 0.1461, 0.6884, 0.8545, 0.2301, 0.3617, 0.6958, 0.4429],\n",
      "        [0.4877, 0.5126, 0.2952, 0.4218, 0.4844, 0.4875, 0.5178, 0.4554, 0.5533],\n",
      "        [0.5266, 0.1787, 0.4992, 0.2822, 0.8120, 0.4902, 0.6506, 0.5871, 0.4490],\n",
      "        [0.4906, 0.4438, 0.3182, 0.5856, 0.6879, 0.0000, 0.3655, 0.5165, 0.3878]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5136, 0.4272, 0.4116, 0.6575, 0.5604, 0.5018, 0.4758, 0.4038, 0.2626],\n",
      "        [0.3951, 0.5174, 0.1642, 0.6320, 0.6093, 0.3199, 0.7893, 0.6230, 0.0912],\n",
      "        [0.5953, 0.3535, 0.3428, 0.5345, 0.6112, 0.3427, 0.6267, 0.3903, 0.5539],\n",
      "        [0.4894, 0.4295, 0.7064, 0.6424, 0.5910, 0.3481, 0.4855, 0.5787, 0.4327]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.7341, 0.3682, 0.3828, 0.5546, 0.6453, 0.6518, 0.4804, 0.4125, 0.7162],\n",
      "        [0.7293, 0.3696, 0.3307, 0.7394, 0.3995, 0.4438, 0.3893, 0.6400, 0.3429],\n",
      "        [0.6258, 0.4713, 0.3100, 0.3977, 0.5345, 0.3947, 0.6013, 0.4477, 0.2924],\n",
      "        [0.4436, 0.5765, 0.2546, 0.4425, 0.5312, 0.3066, 0.4039, 0.6506, 0.4636]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5632, 0.1951, 0.7191, 0.3754, 0.8987, 0.2481, 0.4281, 0.4392, 0.6180],\n",
      "        [0.4798, 0.3824, 0.4268, 0.4661, 0.5792, 0.3429, 0.5566, 0.6803, 0.4394],\n",
      "        [0.4443, 0.4644, 0.7254, 0.7020, 0.6689, 0.5712, 0.3765, 0.5761, 0.5801],\n",
      "        [0.4317, 0.4687, 0.1812, 0.5395, 0.5497, 0.4812, 0.7673, 0.5162, 0.5312]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5433, 0.4136, 0.5465, 0.5812, 0.4001, 0.4276, 0.2870, 0.3723, 0.4854],\n",
      "        [0.5259, 0.4254, 0.2745, 0.4676, 0.4207, 0.3625, 0.3663, 0.4302, 0.4476],\n",
      "        [0.5644, 0.6727, 0.3222, 0.5907, 0.5085, 0.3530, 0.4552, 0.6426, 0.6084],\n",
      "        [0.5092, 0.5738, 0.4115, 0.3866, 0.5663, 0.2243, 0.4770, 0.4505, 0.4723]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5459, 0.5691, 0.3801, 0.6022, 0.6601, 0.4629, 0.7752, 0.2999, 0.4418],\n",
      "        [0.4665, 0.2933, 0.3481, 0.3042, 0.4518, 0.6241, 0.3524, 0.5471, 0.4544],\n",
      "        [0.5052, 0.4768, 0.2314, 0.5489, 0.7092, 0.6157, 0.4149, 0.2869, 0.4865],\n",
      "        [0.4910, 0.6049, 0.3641, 0.5939, 0.5071, 0.2265, 0.4066, 0.4695, 0.6658]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4543, 0.4386, 0.5112, 0.5036, 0.5605, 0.3137, 0.6323, 0.5836, 0.2455],\n",
      "        [0.4823, 0.7292, 0.3811, 0.6316, 0.4283, 0.6123, 0.4351, 0.4144, 0.6495],\n",
      "        [0.4738, 0.4859, 0.3187, 0.2156, 0.4749, 0.3410, 0.3019, 0.7247, 0.7240],\n",
      "        [0.6551, 0.4550, 0.3993, 0.5122, 0.6988, 0.4257, 0.5322, 0.3137, 0.5048]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4837, 0.4734, 0.4815, 0.5634, 0.6433, 0.4780, 0.4103, 0.5764, 0.6070],\n",
      "        [0.6535, 0.5217, 0.4704, 0.4637, 0.5989, 0.2942, 0.4815, 0.6790, 0.6700],\n",
      "        [0.5103, 0.5195, 0.5746, 0.5267, 0.5555, 0.5214, 0.4074, 0.3215, 0.4992],\n",
      "        [0.4097, 0.5505, 0.3903, 0.4437, 0.6351, 0.4785, 0.5095, 0.5999, 0.6421]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4128, 0.4548, 0.7215, 0.4815, 0.5765, 0.6557, 0.7948, 0.4355, 0.4857],\n",
      "        [0.4502, 0.5309, 0.3667, 0.3525, 0.5954, 0.2374, 0.4277, 0.5764, 0.4200],\n",
      "        [0.5824, 0.5005, 0.4986, 0.3398, 0.4324, 0.7016, 0.6400, 0.5390, 0.6488],\n",
      "        [0.3416, 0.3739, 0.5490, 0.5130, 0.7238, 0.5527, 0.5152, 0.5257, 0.7128]])\n",
      "batch_labels:  tensor([1., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4395, 0.5398, 0.4567, 0.5988, 0.7234, 0.4621, 0.4739, 0.2099, 0.6243],\n",
      "        [0.6405, 0.3938, 0.0716, 0.3741, 0.7320, 0.4899, 0.5632, 0.4691, 0.2704],\n",
      "        [0.5627, 0.6614, 0.2678, 0.3702, 0.7050, 0.7468, 0.4834, 0.3495, 0.6549],\n",
      "        [0.6303, 0.5289, 0.5935, 0.3443, 0.5733, 0.4070, 0.6676, 0.6133, 0.6326]])\n",
      "batch_labels:  tensor([1., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.6075, 0.7803, 0.4077, 0.4263, 0.7243, 0.7019, 0.4587, 0.6724, 0.6550],\n",
      "        [0.6476, 0.5668, 0.2065, 0.4976, 0.5987, 0.5910, 0.6480, 0.3384, 0.4647],\n",
      "        [0.4333, 0.5001, 0.3385, 0.6579, 0.6075, 0.4058, 0.6052, 0.6631, 0.5444],\n",
      "        [0.3663, 0.4439, 0.3328, 0.6495, 0.9025, 0.3415, 0.3589, 0.4787, 0.5181]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.3907, 0.3259, 0.3474, 0.6778, 0.5522, 0.7150, 0.4910, 0.3539, 0.6332],\n",
      "        [0.3251, 0.3556, 0.0856, 0.5873, 0.6497, 0.2593, 0.4845, 0.2228, 0.5273],\n",
      "        [0.4707, 0.5337, 0.4171, 0.4546, 0.6063, 0.4610, 0.5514, 0.4774, 0.4784],\n",
      "        [0.4478, 0.6026, 0.3691, 0.6262, 0.6222, 0.2750, 0.7029, 0.3477, 0.6506]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5520, 0.5731, 0.3294, 0.4332, 0.5328, 0.3691, 0.5915, 0.4100, 0.4166],\n",
      "        [0.7448, 0.2587, 0.5795, 0.5972, 0.4202, 0.3889, 0.6726, 0.4462, 0.6381],\n",
      "        [0.0554, 0.2449, 0.2956, 0.6733, 0.8959, 0.2187, 0.3318, 0.3032, 0.7355],\n",
      "        [0.3580, 0.1870, 0.5977, 0.5267, 0.7911, 0.2240, 0.5952, 0.5601, 0.5242]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4448, 0.5445, 0.3220, 0.1988, 0.6227, 0.3409, 0.4436, 0.4480, 0.2787],\n",
      "        [0.6354, 0.5725, 0.3331, 0.3324, 0.5339, 0.4922, 0.5519, 0.4983, 0.6356],\n",
      "        [0.4192, 0.4650, 0.3958, 0.5965, 0.5744, 0.4409, 0.0914, 0.4971, 0.5128],\n",
      "        [0.5456, 0.5936, 0.4007, 0.6225, 0.6675, 0.5789, 0.5285, 0.5644, 0.4542]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5868, 0.5120, 0.4277, 0.5924, 0.4257, 0.4620, 0.5367, 0.4840, 0.4572],\n",
      "        [0.6260, 0.5097, 0.3527, 0.3231, 0.5696, 0.2807, 0.3903, 0.3217, 0.3048],\n",
      "        [0.3360, 0.2965, 0.2597, 0.7190, 0.7490, 0.4670, 0.3324, 0.3787, 0.6437],\n",
      "        [0.4819, 0.5875, 0.2352, 0.3602, 0.7764, 0.6380, 0.5439, 0.6741, 0.4966]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5366, 0.5299, 0.7873, 0.3771, 0.5939, 0.4666, 0.4495, 0.5634, 0.4598],\n",
      "        [0.5618, 0.3201, 0.4443, 0.4870, 0.6344, 0.5910, 0.5479, 0.3785, 0.3848],\n",
      "        [0.4860, 0.5037, 0.6931, 0.6052, 0.5351, 0.5182, 0.5038, 0.2874, 0.6044],\n",
      "        [0.5662, 0.5742, 0.2695, 0.5350, 0.5372, 0.3166, 0.2912, 0.4062, 0.5322]])\n",
      "batch_labels:  tensor([1., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.3533, 0.7292, 0.5328, 0.4540, 0.3921, 0.1269, 0.5112, 0.5389, 0.6150],\n",
      "        [0.4980, 0.4876, 0.4487, 0.5081, 0.5503, 0.6295, 0.4968, 0.4813, 0.5041],\n",
      "        [0.2476, 0.6785, 0.1741, 0.5233, 0.5924, 0.5574, 0.4684, 0.3559, 0.7922],\n",
      "        [0.5049, 0.5583, 0.2648, 0.3923, 0.5947, 0.2546, 0.2307, 0.5455, 0.7213]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5519, 0.4234, 0.5878, 0.3449, 0.4488, 0.1604, 0.1480, 0.5817, 0.7432],\n",
      "        [0.3549, 0.4858, 0.3436, 0.3979, 0.5535, 0.4352, 0.3534, 0.3523, 0.4861],\n",
      "        [0.4894, 0.4529, 0.2329, 0.4317, 0.6897, 0.4198, 0.4992, 0.4978, 0.6825],\n",
      "        [0.4840, 0.3981, 0.3054, 0.3241, 0.6656, 0.7974, 0.6040, 0.2802, 0.6182]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.3750, 0.5107, 0.3486, 0.5498, 0.6248, 0.3955, 0.5005, 0.6237, 0.3031],\n",
      "        [0.5374, 0.3416, 0.4615, 0.5919, 0.3580, 0.5335, 0.4609, 0.4941, 0.5416],\n",
      "        [0.3281, 0.4626, 0.5846, 0.6348, 0.6851, 0.1728, 0.5073, 0.3455, 0.4458],\n",
      "        [0.4126, 0.6875, 0.4522, 0.2911, 0.7297, 0.4731, 0.4884, 0.4506, 0.5070]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4650, 0.5257, 0.4244, 0.5601, 0.6835, 0.2632, 0.5980, 0.4560, 0.3838],\n",
      "        [0.5366, 0.5049, 0.4764, 0.5106, 0.6141, 0.2309, 0.2559, 0.4468, 0.1866],\n",
      "        [0.4959, 0.4272, 0.2280, 0.5046, 0.6770, 0.3482, 0.5707, 0.3922, 0.6019],\n",
      "        [0.2618, 0.5956, 0.4133, 0.4332, 0.6349, 0.3980, 0.6883, 0.4360, 0.6578]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3437, 0.3804, 0.3901, 0.7269, 0.4719, 0.4486, 0.3951, 0.4752, 0.4862],\n",
      "        [0.6348, 0.5014, 0.1554, 0.5177, 0.7597, 0.3206, 0.6272, 0.9152, 0.5021],\n",
      "        [0.4602, 0.3537, 0.3334, 0.4518, 0.4389, 0.3480, 0.6453, 0.5066, 0.2618],\n",
      "        [0.7685, 0.5561, 0.2052, 0.7456, 0.6276, 0.3472, 0.5351, 0.4978, 0.5880]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4918, 0.5985, 0.4574, 0.4167, 0.7563, 0.5106, 0.6989, 0.3317, 0.5716],\n",
      "        [0.5034, 0.4495, 0.1143, 0.2055, 0.4221, 0.4104, 0.3064, 0.7057, 0.4827],\n",
      "        [0.5377, 0.5174, 0.2847, 0.7251, 0.6521, 0.3968, 0.3362, 0.7942, 0.2928],\n",
      "        [0.5603, 0.5673, 0.5653, 0.5435, 0.4583, 0.2750, 0.6318, 0.6057, 0.5276]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3916, 0.6295, 0.4902, 0.4372, 0.5120, 0.3851, 0.5939, 0.6053, 0.3944],\n",
      "        [0.2760, 0.5327, 0.7479, 0.6100, 0.4280, 0.5476, 0.4660, 0.3276, 0.5411],\n",
      "        [0.3326, 0.4620, 0.3347, 0.4826, 0.6545, 0.6813, 0.2461, 0.5595, 0.4257],\n",
      "        [0.3394, 0.2807, 0.2367, 0.5893, 0.6807, 0.4304, 0.3113, 0.6418, 0.5260]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4860, 0.7335, 0.1917, 0.7330, 0.4453, 0.3027, 0.6015, 0.3040, 0.3623],\n",
      "        [0.4396, 0.3560, 0.2986, 0.4550, 0.5002, 0.4039, 0.4908, 0.2833, 0.5962],\n",
      "        [0.5665, 0.3467, 0.3444, 0.6001, 0.4382, 0.4163, 0.7456, 0.4453, 0.5825],\n",
      "        [0.2921, 0.3899, 0.2805, 0.3383, 0.3757, 0.4485, 0.3688, 0.6790, 0.5285]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4550, 0.5399, 0.3472, 0.4221, 0.4812, 0.5093, 0.4017, 0.7009, 0.6860],\n",
      "        [0.4756, 0.5477, 0.2654, 0.4083, 0.5465, 0.5829, 0.4226, 0.6722, 0.5576],\n",
      "        [0.6322, 0.8396, 0.2467, 0.5741, 0.5379, 0.2422, 0.5831, 0.3446, 0.5798],\n",
      "        [0.6116, 0.3324, 0.2774, 0.4363, 0.8244, 0.4408, 0.5022, 0.3547, 0.3601]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.6491, 0.4555, 0.3813, 0.9233, 0.4986, 0.2102, 0.5877, 0.3680, 0.7888],\n",
      "        [0.4936, 0.5303, 0.4127, 0.3279, 0.5867, 0.4885, 0.4713, 0.4780, 0.8999],\n",
      "        [0.7953, 0.6305, 0.4480, 0.6549, 0.7813, 0.6566, 0.6340, 0.5493, 0.5789],\n",
      "        [0.3982, 0.2966, 0.3710, 0.5593, 0.7278, 0.4340, 0.5838, 0.5362, 0.4962]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.6195, 0.6005, 0.5883, 0.3661, 0.5540, 0.4385, 0.6274, 0.6166, 0.2854],\n",
      "        [0.4549, 0.4075, 0.2547, 0.5407, 0.6261, 0.8173, 0.3230, 0.4191, 0.6378],\n",
      "        [0.4140, 0.4862, 0.3368, 0.6472, 0.7703, 0.4670, 0.3101, 0.3776, 0.4248],\n",
      "        [0.5367, 0.1641, 0.6580, 0.4234, 0.7070, 0.1518, 0.5978, 0.3496, 0.4618]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5129, 0.5284, 0.3840, 0.5315, 0.5989, 0.3220, 0.2199, 0.4804, 0.5526],\n",
      "        [0.5977, 0.6901, 0.5162, 0.3743, 0.5252, 0.2301, 0.6489, 0.6579, 0.4713],\n",
      "        [0.4583, 0.5821, 0.5102, 0.4792, 0.5208, 0.4068, 0.6349, 0.4021, 0.5206],\n",
      "        [0.4026, 0.5194, 0.4900, 0.4892, 0.5387, 0.3850, 0.5382, 0.4674, 0.3229]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4754, 0.3317, 0.2707, 0.3999, 0.6080, 0.7184, 0.6014, 0.4119, 0.3107],\n",
      "        [0.5184, 0.6591, 0.2711, 0.5505, 0.6679, 0.3473, 0.5225, 0.4865, 0.3854],\n",
      "        [0.5072, 0.4230, 0.6126, 0.3214, 0.4508, 0.2367, 0.3276, 0.5951, 0.4059],\n",
      "        [0.7115, 0.0845, 0.4485, 0.4451, 0.7284, 0.3387, 0.3905, 0.5259, 0.4532]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.7115, 0.6183, 0.2607, 0.5144, 0.5908, 0.5726, 0.6715, 0.4920, 0.5416],\n",
      "        [0.6945, 0.3591, 0.5328, 0.3258, 0.3666, 0.3834, 0.4149, 0.5861, 0.4518],\n",
      "        [0.5673, 0.6208, 0.1168, 0.5748, 0.8237, 0.2888, 0.4114, 0.5600, 0.5028],\n",
      "        [0.4455, 0.5492, 0.1696, 0.7136, 0.5444, 0.4803, 0.6835, 0.4305, 0.5132]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4427, 0.4614, 0.4080, 0.3836, 0.6199, 0.3619, 0.4460, 0.4496, 0.4212],\n",
      "        [0.5781, 0.6402, 0.2293, 0.3934, 0.5825, 0.7320, 0.5104, 0.8209, 0.4437],\n",
      "        [0.7842, 0.6350, 0.2279, 0.5220, 0.5407, 0.3165, 0.2352, 0.3461, 0.5409],\n",
      "        [0.4593, 0.5139, 0.5997, 0.6220, 0.4145, 0.4994, 0.4906, 0.6030, 0.6419]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4651, 0.6760, 0.2227, 0.5075, 0.5747, 0.4533, 0.7031, 0.5599, 0.5770],\n",
      "        [0.7306, 0.3662, 0.3302, 0.4700, 0.6113, 0.6961, 0.6715, 0.5694, 0.4064],\n",
      "        [0.3439, 0.3887, 0.3093, 0.7102, 0.5813, 0.2745, 0.6085, 0.5084, 0.6565],\n",
      "        [0.4370, 0.5151, 0.4750, 0.5468, 0.4770, 0.5023, 0.6018, 0.6604, 0.6552]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.6234, 0.6680, 0.7186, 0.4446, 0.4958, 0.1391, 0.4989, 0.5570, 0.5535],\n",
      "        [0.5623, 0.3180, 0.5253, 0.5344, 0.7864, 0.3177, 0.6927, 0.6029, 0.1961],\n",
      "        [0.5747, 0.6080, 0.5250, 0.6330, 0.2185, 0.6435, 0.3442, 0.4413, 0.6452],\n",
      "        [0.5184, 0.4575, 0.2462, 0.3573, 0.5555, 0.2453, 0.5254, 0.3589, 0.3174]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5309, 0.4607, 0.3784, 0.5157, 0.5797, 0.4395, 0.5495, 0.3508, 0.6109],\n",
      "        [0.4589, 0.8411, 0.4484, 0.4566, 0.6757, 0.5360, 0.5790, 0.6129, 0.4285],\n",
      "        [0.4614, 0.8181, 0.6560, 0.5729, 0.8155, 0.2716, 0.5212, 0.6124, 0.5455],\n",
      "        [0.6119, 0.6101, 0.2378, 0.5011, 0.6239, 0.4699, 0.6376, 0.5532, 0.6222]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4815, 0.4330, 0.4851, 0.3830, 0.2794, 0.3443, 0.5027, 0.6489, 0.6050],\n",
      "        [0.4828, 0.2599, 0.4827, 0.4857, 0.5068, 0.2548, 0.6532, 0.6291, 0.4713],\n",
      "        [0.4665, 0.4694, 0.3353, 0.3884, 0.6146, 0.4210, 0.7386, 0.1522, 0.4384],\n",
      "        [0.5958, 0.3597, 0.2774, 0.5993, 0.4861, 0.5046, 0.5282, 0.5450, 0.4324]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4207, 0.6704, 0.3485, 0.5280, 0.4486, 0.2060, 0.4004, 0.5679, 0.5110],\n",
      "        [0.3577, 0.1388, 0.3346, 0.6736, 0.5797, 0.4645, 0.6146, 0.5980, 0.4559],\n",
      "        [0.4185, 0.6197, 0.5281, 0.5106, 0.5702, 0.7305, 0.6265, 0.4899, 0.6721],\n",
      "        [0.3648, 0.3873, 0.6133, 0.2243, 0.7049, 0.2065, 0.3317, 0.5373, 0.5198]])\n",
      "batch_labels:  tensor([0., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.5747, 0.6034, 0.3523, 0.5160, 0.6417, 0.2994, 0.7063, 0.3911, 0.6278],\n",
      "        [0.2831, 0.2132, 0.1940, 0.3387, 0.3762, 0.4416, 0.6601, 0.6745, 0.5967],\n",
      "        [0.4850, 0.5610, 0.7116, 0.4673, 0.4688, 0.2521, 0.6471, 0.6536, 0.0091],\n",
      "        [0.6013, 0.5201, 0.1828, 0.4262, 0.5068, 0.6953, 0.3870, 0.4787, 0.2121]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5045, 0.5446, 0.4535, 0.5457, 0.5462, 0.5141, 0.5392, 0.3515, 0.6528],\n",
      "        [0.4977, 0.3936, 0.5257, 0.3453, 0.6289, 0.2744, 0.6756, 0.1890, 0.4035],\n",
      "        [0.5786, 0.5783, 0.1793, 0.4179, 0.5630, 0.3653, 0.5187, 0.5560, 0.3506],\n",
      "        [0.4124, 0.5740, 0.7392, 0.5567, 0.5208, 0.2821, 0.5401, 0.3972, 0.5642]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4701, 0.5539, 0.5116, 0.4804, 0.4936, 0.2906, 0.3392, 0.3925, 0.5586],\n",
      "        [0.5583, 0.8389, 0.4784, 0.6671, 0.8402, 0.2849, 0.5182, 0.4181, 0.4380],\n",
      "        [0.5930, 0.4681, 0.1831, 0.5495, 0.6358, 0.3165, 0.4505, 0.4364, 0.2743],\n",
      "        [0.4832, 0.5619, 0.2489, 0.4987, 0.5333, 0.6685, 0.5546, 0.5375, 0.5258]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3452, 0.6047, 0.3680, 0.5619, 0.2941, 0.3118, 0.4045, 0.3238, 0.5997],\n",
      "        [0.4068, 0.3772, 0.5288, 0.6000, 0.5835, 0.5302, 0.5832, 0.5285, 0.7418],\n",
      "        [0.6050, 0.7025, 0.2481, 0.5166, 0.5311, 0.5419, 0.6461, 0.4227, 0.2952],\n",
      "        [0.6253, 0.7077, 0.3714, 0.5391, 0.6080, 1.0000, 0.5933, 0.4493, 0.3306]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.3730, 0.6758, 0.2838, 0.5212, 0.3595, 0.3478, 0.4138, 0.1604, 0.3431],\n",
      "        [0.4807, 0.5179, 0.4625, 0.5068, 0.6399, 0.3551, 0.8038, 0.3722, 0.4688],\n",
      "        [0.5867, 0.6416, 0.3228, 0.4690, 0.5951, 0.4772, 0.2948, 0.6539, 0.6295],\n",
      "        [0.5737, 0.5644, 0.4035, 0.4591, 0.5607, 0.3015, 0.4721, 0.4091, 0.6684]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4640, 0.6568, 0.3432, 0.2821, 0.8623, 0.3626, 0.3856, 0.5598, 0.5922],\n",
      "        [0.6907, 0.3833, 0.2368, 0.4980, 0.7274, 0.3044, 0.4081, 0.5192, 0.2216],\n",
      "        [0.3495, 0.6510, 0.4510, 0.3867, 0.5662, 0.5935, 0.4571, 0.2579, 0.4268],\n",
      "        [0.4879, 0.5769, 0.5809, 0.3488, 0.5807, 0.2125, 0.4277, 0.0616, 0.6908]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.1678, 0.1120, 0.3481, 0.3087, 0.8210, 0.3973, 0.4749, 0.6703, 0.2756],\n",
      "        [0.4674, 0.5958, 0.2876, 0.5056, 0.4853, 0.3819, 0.6044, 0.2812, 0.6050],\n",
      "        [0.4077, 0.3888, 0.3353, 0.4676, 0.5752, 0.5531, 0.4969, 0.6225, 0.5339],\n",
      "        [0.5109, 0.3566, 0.2815, 0.5709, 0.5666, 0.5019, 0.4279, 0.3034, 0.4957]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.3423, 0.3823, 0.3469, 0.5659, 0.8441, 0.2726, 0.5360, 0.5201, 0.7188],\n",
      "        [0.3700, 0.6515, 0.6642, 0.6381, 0.7146, 0.6874, 0.4069, 0.4049, 0.2836],\n",
      "        [0.1380, 0.4889, 0.4377, 0.5425, 0.7230, 0.4929, 0.4872, 0.4139, 0.4742],\n",
      "        [0.5199, 0.5774, 0.2025, 0.6717, 0.7002, 0.2813, 0.5234, 0.6208, 0.4719]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3383, 0.8178, 0.2702, 0.4767, 0.3908, 0.6669, 0.6088, 0.6153, 0.3230],\n",
      "        [0.4409, 0.4054, 0.7186, 0.2430, 0.4932, 0.5148, 0.6667, 0.4872, 0.4479],\n",
      "        [0.5044, 0.5328, 0.3575, 0.5360, 0.4491, 0.2065, 0.4972, 0.5703, 0.4936],\n",
      "        [0.4869, 0.5917, 0.3330, 0.1471, 0.5342, 0.4470, 0.4331, 0.5913, 0.1112]])\n",
      "batch_labels:  tensor([0., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4301, 0.6865, 0.1072, 0.7003, 0.8304, 0.2769, 0.4088, 0.6469, 0.4166],\n",
      "        [0.5504, 0.4360, 0.2976, 0.4250, 0.6223, 0.7041, 0.3988, 0.6326, 0.5383],\n",
      "        [0.5026, 0.5294, 0.4066, 0.3985, 0.4914, 0.1819, 0.6217, 0.2921, 0.4633],\n",
      "        [0.5132, 0.4467, 0.2383, 0.3832, 0.4875, 0.4042, 0.6395, 0.5654, 0.7148]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4282, 0.4351, 0.4919, 0.5696, 0.4961, 0.4813, 0.4690, 0.5236, 0.4323],\n",
      "        [0.4053, 0.3447, 0.1361, 0.4507, 0.3806, 0.3191, 0.6128, 0.5275, 0.4262],\n",
      "        [0.4497, 0.4380, 0.4578, 0.7089, 0.5112, 0.4920, 0.6258, 0.4247, 0.3350],\n",
      "        [0.6427, 0.6092, 0.9510, 0.4690, 0.3552, 0.3286, 0.4235, 0.8061, 0.6148]])\n",
      "batch_labels:  tensor([0., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4549, 0.5724, 0.6052, 0.6519, 0.5860, 0.2023, 0.3602, 0.5393, 0.3823],\n",
      "        [0.6934, 0.5759, 0.4211, 0.6998, 0.4682, 0.5535, 0.5590, 0.6436, 0.2219],\n",
      "        [0.6043, 0.6700, 0.3117, 0.2864, 0.6023, 0.4015, 0.5286, 0.6269, 0.3150],\n",
      "        [0.5666, 0.6116, 0.3172, 0.6274, 0.5269, 0.4556, 0.3977, 0.6062, 0.3744]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5240, 0.5314, 0.4481, 0.5781, 0.8083, 0.3694, 0.4468, 0.5704, 0.2223],\n",
      "        [0.2671, 0.6558, 0.5666, 0.4775, 0.6231, 0.1229, 0.3005, 0.4779, 0.4862],\n",
      "        [0.5505, 0.1106, 0.2082, 0.3256, 0.3358, 0.7315, 0.2988, 0.4982, 0.1977],\n",
      "        [0.3827, 0.5380, 0.5194, 0.5294, 0.5528, 0.4988, 0.5834, 0.6484, 0.7156]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3794, 0.5156, 0.2515, 0.5367, 0.4810, 0.4849, 0.4765, 0.7514, 0.7415],\n",
      "        [0.4564, 0.6388, 0.3944, 0.9534, 0.1791, 0.5037, 0.3138, 0.5033, 0.6270],\n",
      "        [0.5620, 0.4390, 0.3394, 0.7223, 0.5582, 0.3343, 0.3654, 0.5085, 0.5192],\n",
      "        [0.2856, 0.4439, 0.4539, 0.6087, 0.4779, 0.3583, 0.2880, 0.3298, 0.5388]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.6410, 0.5092, 0.3041, 0.5366, 0.5922, 0.3863, 0.5301, 0.4775, 0.3706],\n",
      "        [0.5738, 0.4282, 0.4898, 0.6489, 0.5836, 0.3542, 0.5537, 0.6308, 0.3791],\n",
      "        [0.8041, 0.0163, 0.6927, 0.6073, 0.5923, 0.3792, 0.4889, 0.3859, 0.3686],\n",
      "        [0.6122, 0.1694, 0.4129, 0.6258, 0.5796, 0.2121, 0.5788, 0.3837, 0.2866]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.5734, 0.5496, 0.4659, 0.6092, 0.5371, 0.4169, 0.3175, 0.4800, 0.6491],\n",
      "        [0.3522, 0.4577, 0.3170, 0.2313, 0.4149, 0.5918, 0.3679, 0.6217, 0.4323],\n",
      "        [0.4397, 0.5409, 0.3487, 0.4846, 0.4409, 0.4899, 0.6380, 0.4833, 0.6008],\n",
      "        [0.4137, 0.4639, 0.7844, 0.4451, 0.6040, 0.1302, 0.4256, 0.4408, 0.5499]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.6248, 0.4237, 0.2110, 0.5184, 0.5461, 0.3512, 0.4145, 0.4963, 0.4885],\n",
      "        [0.3999, 0.3479, 0.4458, 0.5400, 0.7060, 0.6646, 0.4606, 0.5837, 0.6508],\n",
      "        [0.7041, 0.6776, 0.1849, 0.4021, 0.6323, 0.3703, 0.4576, 0.4409, 0.6450],\n",
      "        [0.6049, 0.5142, 0.1462, 0.2902, 0.5466, 0.4567, 0.4899, 0.5696, 0.4948]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4119, 0.5431, 0.5352, 0.6864, 0.5206, 0.5632, 0.1655, 0.4028, 0.4775],\n",
      "        [0.6255, 0.6417, 0.1339, 0.7769, 0.4245, 0.3053, 0.5479, 0.5942, 0.6198],\n",
      "        [0.7177, 0.6846, 0.2672, 0.3410, 0.6616, 0.3651, 0.5616, 0.4551, 0.3916],\n",
      "        [0.5495, 0.2567, 0.4658, 0.5253, 0.8451, 0.4890, 0.4976, 0.3718, 0.4320]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4349, 0.4751, 0.2641, 0.4626, 0.5053, 0.1743, 0.3936, 0.6308, 0.4044],\n",
      "        [0.6362, 0.5805, 0.2777, 0.4181, 0.5225, 0.3422, 0.3104, 0.4028, 0.6272],\n",
      "        [0.3817, 0.3800, 0.3707, 0.5297, 0.5503, 0.1898, 0.4826, 0.4814, 0.5181],\n",
      "        [0.4893, 0.3467, 0.2125, 0.4869, 0.6889, 0.3277, 0.4921, 0.6023, 0.2988]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5136, 0.2868, 0.8261, 0.2878, 0.3507, 0.4445, 0.4183, 0.4511, 0.3390],\n",
      "        [0.5426, 0.6032, 0.5183, 0.4231, 0.5504, 0.4411, 0.4365, 0.6000, 0.4632],\n",
      "        [0.4180, 0.4400, 0.5862, 0.5705, 0.6696, 0.3468, 0.7366, 0.3601, 0.4041],\n",
      "        [0.1111, 0.3038, 0.7338, 0.5400, 0.7017, 0.4111, 0.3478, 0.4889, 0.3008]])\n",
      "batch_labels:  tensor([1., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4547, 0.5415, 0.3396, 0.5541, 0.6805, 0.5042, 0.5484, 0.4194, 0.1944],\n",
      "        [0.4446, 0.3638, 0.3920, 0.4667, 0.7119, 0.2455, 0.3835, 0.4972, 0.4474],\n",
      "        [0.5381, 0.4297, 0.3202, 0.4394, 0.6628, 0.3490, 0.3665, 0.6360, 0.6039],\n",
      "        [0.4814, 0.6550, 0.3967, 0.4462, 0.6792, 0.3821, 0.5936, 0.4677, 0.5662]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4504, 0.5499, 0.4724, 0.4854, 0.4976, 0.3930, 0.6337, 0.2273, 0.6652],\n",
      "        [0.4223, 0.4723, 0.4368, 0.2539, 0.4741, 0.2780, 0.2185, 0.6183, 0.6532],\n",
      "        [0.5614, 0.4566, 0.4722, 0.5353, 0.5631, 0.3401, 0.3561, 0.3806, 0.5070],\n",
      "        [0.4370, 0.3680, 0.4645, 0.3953, 0.8523, 0.5589, 0.8614, 0.0918, 0.7125]])\n",
      "batch_labels:  tensor([0., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.5859, 0.5114, 0.3053, 0.5855, 0.6834, 0.1680, 0.6380, 0.3074, 0.7832],\n",
      "        [0.6194, 0.5074, 0.3427, 0.5200, 0.7040, 0.5741, 0.6847, 0.2357, 0.4118],\n",
      "        [0.5770, 0.7003, 0.5482, 0.2843, 0.4441, 0.3933, 0.5109, 0.4149, 0.6461],\n",
      "        [0.5413, 0.5666, 0.2208, 0.4500, 0.7157, 0.2873, 0.4827, 0.5317, 0.7125]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.6049, 0.5767, 0.6845, 0.4445, 0.5142, 0.3281, 0.5521, 0.4212, 0.2261],\n",
      "        [0.4443, 0.0976, 0.3458, 0.1714, 0.5012, 0.5461, 0.5198, 0.6756, 0.6098],\n",
      "        [0.6024, 0.2802, 0.2196, 0.8413, 0.6200, 0.3362, 0.4269, 0.5285, 0.5735],\n",
      "        [0.3953, 0.4564, 0.3063, 0.3343, 0.5967, 0.3767, 0.5239, 0.2024, 0.3605]])\n",
      "batch_labels:  tensor([0., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4149, 0.7204, 0.2574, 0.4260, 0.5874, 0.5726, 0.5536, 0.5023, 0.5654],\n",
      "        [0.3948, 0.3666, 0.5619, 0.5898, 0.6297, 0.6329, 0.5415, 0.5534, 0.6188],\n",
      "        [0.5727, 0.6685, 0.4684, 0.4155, 0.4150, 0.5354, 0.6606, 0.4309, 0.2388],\n",
      "        [0.5168, 0.5277, 0.2975, 0.4108, 0.6603, 0.7226, 0.6087, 0.6974, 0.5645]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5566, 0.6022, 0.2514, 0.5663, 0.4862, 0.2491, 0.6540, 0.5062, 0.5248],\n",
      "        [0.7682, 0.5130, 0.5215, 0.3742, 0.4989, 0.3292, 0.5121, 0.3407, 0.5773],\n",
      "        [0.4982, 0.4329, 0.3693, 0.5181, 0.7067, 0.6705, 0.4202, 0.6642, 0.3600],\n",
      "        [0.7068, 0.6010, 0.2069, 0.5997, 0.5922, 0.3572, 0.5076, 0.4541, 0.3561]])\n",
      "batch_labels:  tensor([1., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.5917, 0.7162, 0.4897, 0.4865, 0.6081, 0.4202, 0.6635, 0.3875, 0.8432],\n",
      "        [0.4629, 0.4148, 0.3790, 0.4423, 0.5111, 0.8264, 0.2767, 0.5220, 0.4247],\n",
      "        [0.5357, 0.7158, 0.2544, 0.4231, 0.5493, 0.1336, 0.3832, 0.7468, 0.6207],\n",
      "        [0.6722, 0.2026, 0.9976, 0.2410, 0.2572, 0.5061, 0.4569, 0.2872, 0.5317]])\n",
      "batch_labels:  tensor([0., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.3756, 0.2758, 0.3017, 0.7384, 0.5663, 0.4916, 0.3651, 0.4189, 0.6690],\n",
      "        [0.5419, 0.3350, 0.6455, 0.5368, 0.7845, 0.6077, 0.5650, 0.5978, 0.5139],\n",
      "        [0.4892, 0.3658, 0.4271, 0.6594, 0.5078, 0.5242, 0.5366, 0.8154, 0.4994],\n",
      "        [0.5226, 0.5372, 0.3256, 0.5150, 0.5374, 0.2489, 0.5662, 0.7453, 0.2198]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4398, 0.6118, 0.3241, 0.6467, 0.7564, 0.5719, 0.5510, 0.4055, 0.7098],\n",
      "        [0.5251, 0.5914, 0.3403, 0.2768, 0.6347, 0.5301, 0.4942, 0.4212, 0.4740],\n",
      "        [0.5523, 0.4011, 0.4557, 0.6134, 0.5063, 0.4476, 0.5727, 0.4471, 0.4129],\n",
      "        [0.4908, 0.3947, 0.3410, 0.3090, 0.6733, 0.4061, 0.6093, 0.3492, 0.5997]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5511, 0.6053, 0.2389, 0.4246, 0.4508, 0.4694, 0.4235, 0.5042, 0.6289],\n",
      "        [0.6597, 0.2446, 0.7417, 0.4462, 0.8188, 0.1200, 0.3293, 0.5793, 0.6033],\n",
      "        [0.8231, 0.4160, 0.3390, 0.4350, 0.5779, 0.2985, 0.6180, 0.2587, 0.7250],\n",
      "        [0.4677, 0.4809, 0.2835, 0.4245, 0.5549, 0.3292, 0.2278, 0.6746, 0.1021]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5497, 0.4712, 0.5766, 0.8255, 0.3670, 0.5538, 0.6479, 0.6637, 0.5267],\n",
      "        [0.4608, 0.4653, 0.3989, 0.4108, 0.5732, 0.3324, 0.3976, 0.5546, 0.6992],\n",
      "        [0.5235, 0.6940, 0.3537, 0.4031, 0.5033, 0.3843, 0.3250, 0.4848, 0.4791],\n",
      "        [0.4649, 0.5564, 0.3590, 0.5017, 0.5791, 0.5859, 0.7479, 0.4476, 0.3380]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.6396, 0.5160, 0.3806, 0.3902, 0.6283, 0.1575, 0.4515, 0.5587, 0.8349],\n",
      "        [0.3706, 0.4978, 0.2909, 0.5626, 0.5331, 0.2420, 0.3217, 0.4418, 0.5917],\n",
      "        [0.5358, 0.3571, 0.6919, 0.5484, 0.5200, 0.5465, 0.4502, 0.4630, 0.4113],\n",
      "        [0.4749, 0.5342, 0.3711, 0.3274, 0.3467, 0.2416, 0.4440, 0.6176, 0.3668]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.6857, 0.2342, 0.5323, 0.6747, 0.6854, 0.3811, 0.6379, 0.5855, 0.4847],\n",
      "        [0.3721, 0.3158, 0.4892, 0.3471, 0.9003, 0.4002, 0.5621, 0.6047, 0.6599],\n",
      "        [0.5591, 0.6202, 0.4821, 0.4673, 0.6087, 0.2072, 0.4812, 0.2067, 0.6734],\n",
      "        [0.5364, 0.5388, 0.1439, 0.3938, 0.8218, 0.1986, 0.4250, 0.5086, 0.5537]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4201, 0.5961, 0.3784, 0.6736, 0.5459, 0.4398, 0.5057, 0.4667, 0.3976],\n",
      "        [0.5545, 0.5932, 0.4046, 0.5147, 0.6276, 0.3856, 0.5074, 0.5548, 0.4234],\n",
      "        [0.5341, 0.4575, 0.4051, 0.3836, 0.4787, 0.5735, 0.3966, 0.6215, 0.5380],\n",
      "        [0.6091, 0.6368, 0.3348, 0.4794, 0.5650, 0.3297, 0.5063, 0.2833, 0.6214]])\n",
      "batch_labels:  tensor([0., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.8182, 0.5024, 0.2464, 0.4980, 0.5197, 0.2826, 0.6902, 0.6392, 0.3335],\n",
      "        [0.4482, 0.4052, 0.2780, 0.3021, 0.6005, 0.4237, 0.3578, 0.4314, 0.6168],\n",
      "        [0.3576, 0.4587, 0.4513, 0.5478, 0.5382, 0.4500, 0.6491, 0.3532, 0.4743],\n",
      "        [0.3551, 0.4356, 0.4610, 0.3504, 0.4950, 0.3045, 0.5064, 0.6433, 0.4672]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4784, 0.6716, 0.4246, 0.6233, 0.6271, 0.4992, 0.5794, 0.7310, 0.5599],\n",
      "        [0.6408, 0.1908, 0.3896, 0.6797, 0.4438, 0.3093, 0.4974, 0.4813, 0.5570],\n",
      "        [0.5187, 0.3063, 0.7431, 0.5603, 0.5555, 0.6221, 0.6033, 0.4687, 0.5727],\n",
      "        [0.4894, 0.4247, 0.4018, 0.4294, 0.5292, 0.5549, 0.5276, 0.2356, 0.6679]])\n",
      "batch_labels:  tensor([1., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4948, 0.4298, 0.4469, 0.4586, 0.5324, 0.3384, 0.3772, 0.5604, 0.3270],\n",
      "        [0.4015, 0.4039, 0.1383, 0.5039, 0.5714, 0.4371, 0.3694, 0.7565, 0.5059],\n",
      "        [0.3478, 0.3933, 0.5119, 0.7942, 0.4773, 0.4814, 0.5528, 0.1318, 0.5623],\n",
      "        [0.4518, 0.8294, 0.1475, 0.5377, 0.4068, 0.3313, 0.5595, 0.3970, 0.4491]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4025, 0.4962, 0.2822, 0.4219, 0.5391, 0.3362, 0.3968, 0.3806, 0.5532],\n",
      "        [0.4112, 0.4534, 0.6160, 0.5121, 0.6102, 0.1449, 0.5051, 0.4681, 0.5790],\n",
      "        [0.6623, 0.7327, 0.2282, 0.4075, 0.5435, 0.2686, 0.4398, 0.4351, 0.4615],\n",
      "        [0.4137, 0.1558, 0.2687, 0.4694, 0.6217, 0.1377, 0.4459, 0.5685, 0.5429]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4582, 0.5083, 0.2788, 0.5141, 0.4111, 0.4542, 0.6605, 0.5991, 0.7322],\n",
      "        [0.3148, 0.3257, 0.2345, 0.5205, 0.5954, 0.5845, 0.4815, 0.5236, 0.6690],\n",
      "        [0.6237, 0.4194, 0.4069, 0.4550, 0.6765, 0.6352, 0.2230, 0.7179, 0.4785],\n",
      "        [0.6260, 0.7755, 0.4290, 0.3415, 0.3185, 0.5297, 0.4459, 0.3339, 0.9004]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5171, 0.5792, 0.5772, 0.4226, 0.5428, 0.4285, 0.5479, 0.4054, 0.4152],\n",
      "        [0.7449, 0.4576, 0.4653, 0.6951, 0.7481, 0.4606, 0.5553, 0.3364, 0.4667],\n",
      "        [0.6655, 0.5805, 0.3609, 0.7412, 0.5748, 0.4449, 0.3458, 0.3972, 0.6374],\n",
      "        [0.6722, 0.5956, 0.2677, 0.6087, 0.5307, 0.4133, 0.5410, 0.4873, 0.3511]])\n",
      "batch_labels:  tensor([0., 1., 1., 1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_imputs:  tensor([[0.5536, 0.6637, 0.2571, 0.5412, 0.5954, 0.5511, 0.3895, 0.3554, 0.7441],\n",
      "        [0.1870, 0.4619, 0.2065, 0.6178, 0.5788, 0.4458, 0.6564, 0.6855, 0.4044],\n",
      "        [0.4637, 0.2774, 0.4509, 0.4969, 0.4722, 0.3138, 0.4772, 0.5694, 0.4142],\n",
      "        [0.4349, 0.2356, 0.3408, 0.4858, 0.4861, 0.6435, 0.4790, 0.4273, 0.7683]])\n",
      "batch_labels:  tensor([1., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.5332, 0.4081, 0.1516, 0.6966, 0.8729, 0.1889, 0.3551, 0.7269, 0.4897],\n",
      "        [0.4193, 0.5024, 0.2816, 0.3661, 0.4914, 0.2452, 0.3946, 0.3061, 0.5680],\n",
      "        [0.5728, 0.5544, 0.4213, 0.5217, 0.6176, 0.4253, 0.2988, 0.5095, 0.2943],\n",
      "        [0.5752, 0.6017, 0.4212, 0.5107, 0.6574, 0.4716, 0.4501, 0.8214, 0.6936]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.5616, 0.6185, 0.1999, 0.6903, 0.6774, 0.4535, 0.5124, 0.6161, 0.1659],\n",
      "        [0.4797, 0.4468, 0.3801, 0.4275, 0.5595, 0.3547, 0.5767, 0.5708, 0.2396],\n",
      "        [0.6134, 0.5218, 0.2622, 0.6169, 0.6471, 0.4344, 0.6310, 0.5719, 0.6995],\n",
      "        [0.5103, 0.5051, 0.7809, 0.3302, 0.3733, 0.2223, 0.2398, 0.5267, 0.6115]])\n",
      "batch_labels:  tensor([1., 1., 0., 1.])\n",
      "batch_imputs:  tensor([[0.4115, 0.4862, 0.2561, 0.5551, 0.5023, 0.4135, 0.5167, 0.3146, 0.7186],\n",
      "        [0.4975, 0.2605, 0.4266, 0.3677, 0.8654, 0.2558, 0.2787, 0.6910, 0.8134],\n",
      "        [0.4294, 0.5101, 0.4694, 0.5280, 0.5688, 0.6279, 0.5497, 0.2832, 0.7750],\n",
      "        [0.5117, 0.4988, 0.3770, 0.4414, 0.6582, 0.3929, 0.3702, 0.6295, 0.5593]])\n",
      "batch_labels:  tensor([0., 0., 0., 0.])\n",
      "batch_imputs:  tensor([[0.3223, 0.4011, 0.6295, 0.2985, 0.5273, 0.5443, 0.4842, 0.4187, 0.6159],\n",
      "        [0.6543, 0.5703, 0.2583, 0.4927, 0.5543, 0.6775, 0.5797, 0.5052, 0.4008],\n",
      "        [0.5584, 0.5080, 0.4020, 0.5873, 0.4725, 0.2836, 0.4337, 0.5468, 0.3838],\n",
      "        [0.6046, 0.4848, 0.5660, 0.5730, 0.4677, 0.5752, 0.2567, 0.4287, 0.4190]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5364, 0.7076, 0.5880, 0.5821, 0.6159, 0.4425, 0.3452, 0.7779, 0.3054],\n",
      "        [0.5583, 0.5248, 0.6963, 0.5227, 0.4182, 0.4186, 0.6297, 0.5342, 0.5600],\n",
      "        [0.4729, 0.5080, 0.6121, 0.3816, 0.3752, 0.3415, 0.6272, 0.7174, 0.5807],\n",
      "        [0.7744, 0.4275, 0.4519, 0.5342, 0.5210, 0.3291, 0.6156, 0.2966, 0.4331]])\n",
      "batch_labels:  tensor([1., 1., 0., 0.])\n",
      "batch_imputs:  tensor([[0.4224, 0.3165, 0.2363, 0.4316, 0.7748, 0.3454, 0.7106, 0.3031, 0.6868],\n",
      "        [0.4220, 0.3713, 0.1713, 0.5396, 0.6299, 0.3139, 0.5832, 0.4935, 0.4904],\n",
      "        [0.4987, 0.6070, 0.3012, 0.6638, 0.5500, 0.4367, 0.5795, 0.6025, 0.6612],\n",
      "        [0.3748, 0.3685, 0.3441, 0.6563, 0.5262, 0.5259, 0.5360, 0.3475, 0.4218]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5152, 0.6432, 0.4337, 0.5142, 0.5535, 0.2677, 0.2942, 0.3646, 0.5019],\n",
      "        [0.4751, 0.4968, 0.2742, 0.4563, 0.5965, 0.4352, 0.8341, 0.5796, 0.3558],\n",
      "        [0.4514, 0.3820, 0.4368, 0.6903, 0.4500, 0.5036, 0.3425, 0.4945, 0.4167],\n",
      "        [0.5286, 0.4060, 0.3206, 0.4701, 0.6318, 0.3180, 0.3418, 0.5222, 0.4466]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.6207, 0.3439, 0.3880, 0.5573, 0.4994, 0.5059, 0.5439, 0.6442, 0.5836],\n",
      "        [0.8178, 0.0874, 0.6564, 0.6708, 0.3691, 0.4319, 0.5633, 0.2857, 0.5787],\n",
      "        [0.4326, 0.6666, 0.0156, 0.4047, 0.6962, 0.4252, 0.3585, 0.7901, 0.5234],\n",
      "        [0.7037, 0.5478, 0.2888, 0.4813, 0.6648, 0.1398, 0.5987, 0.3095, 0.5288]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.3911, 0.5375, 0.2901, 0.3603, 0.5315, 0.2536, 0.5230, 0.5620, 0.3994],\n",
      "        [0.4301, 0.3933, 0.4196, 0.5066, 0.7011, 0.3116, 0.5444, 0.3441, 0.6735],\n",
      "        [0.7279, 0.5938, 0.3176, 0.6192, 0.6264, 0.2439, 0.6951, 0.6436, 0.6165],\n",
      "        [0.3863, 0.5363, 0.7064, 0.4803, 0.5403, 0.4175, 0.5321, 0.2892, 0.4947]])\n",
      "batch_labels:  tensor([0., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.5057, 0.6353, 0.2684, 0.5119, 0.5845, 0.1691, 0.4729, 0.3654, 0.5258],\n",
      "        [0.5512, 0.4336, 0.4849, 0.5209, 0.5296, 0.2854, 0.4200, 0.3795, 0.3725],\n",
      "        [0.5321, 0.4797, 0.5179, 0.5520, 0.6276, 0.5852, 0.6937, 0.6149, 0.5251],\n",
      "        [0.6397, 0.6310, 0.6059, 0.3564, 0.2899, 0.3988, 0.5697, 0.7283, 0.4473]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.5595, 0.5382, 0.2210, 0.5390, 0.5741, 0.4496, 0.5430, 0.4057, 0.6114],\n",
      "        [0.4501, 0.4736, 0.2073, 0.5266, 0.6717, 0.5462, 0.4703, 0.7645, 0.4523],\n",
      "        [0.4434, 0.4591, 0.3238, 0.4415, 0.6476, 0.2994, 0.5740, 0.5908, 0.5019],\n",
      "        [0.4811, 0.3469, 0.2064, 0.5320, 0.7305, 0.4930, 0.5942, 0.4689, 0.6234]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.4722, 0.4528, 0.1591, 0.5636, 0.6138, 0.2158, 0.3977, 0.4147, 0.4979],\n",
      "        [0.4860, 0.5509, 0.2914, 0.7362, 0.4472, 0.5081, 0.3052, 0.6040, 0.3600],\n",
      "        [0.4807, 0.5001, 0.2775, 0.4133, 0.5405, 0.3672, 0.6747, 0.5789, 0.4524],\n",
      "        [0.5823, 0.4200, 0.1708, 0.3054, 0.5552, 0.1823, 0.3576, 0.5446, 0.4940]])\n",
      "batch_labels:  tensor([1., 1., 1., 0.])\n",
      "batch_imputs:  tensor([[0.6075, 0.6343, 0.5232, 0.3863, 0.3640, 0.5732, 0.5548, 0.3844, 0.6025],\n",
      "        [0.4233, 0.4547, 0.2579, 0.3717, 0.7267, 0.4720, 0.5060, 0.2226, 0.5792],\n",
      "        [0.4766, 0.8124, 0.2497, 0.7270, 0.6813, 0.7413, 0.2897, 0.7176, 0.3941],\n",
      "        [0.4342, 0.4898, 0.2336, 0.3773, 0.5593, 0.6021, 0.5034, 0.4497, 0.4161]])\n",
      "batch_labels:  tensor([1., 0., 1., 0.])\n",
      "batch_imputs:  tensor([[0.3373, 0.6201, 0.2962, 0.4846, 0.5512, 0.2769, 0.5439, 0.6185, 0.4892],\n",
      "        [0.4767, 0.9561, 0.5018, 0.4619, 0.4661, 0.1894, 0.2744, 0.4534, 0.2093],\n",
      "        [0.4066, 0.4819, 0.4548, 0.2925, 0.5313, 0.3058, 0.6515, 0.3473, 0.3428],\n",
      "        [0.5956, 0.5012, 0.6219, 0.4527, 0.5276, 0.1468, 0.4059, 0.3285, 0.3576]])\n",
      "batch_labels:  tensor([1., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4848, 0.7588, 0.6255, 0.2974, 0.2194, 0.2121, 0.4741, 0.4963, 0.4793],\n",
      "        [0.6146, 0.2901, 0.0397, 0.6656, 0.6220, 0.5724, 0.4742, 0.2929, 0.1652],\n",
      "        [0.4830, 0.5792, 0.3594, 0.6514, 0.5465, 0.1906, 0.4143, 0.6161, 0.6443],\n",
      "        [0.4015, 0.3096, 0.5714, 0.6636, 0.5404, 0.3736, 0.3999, 0.2915, 0.4520]])\n",
      "batch_labels:  tensor([1., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.4548, 0.4738, 0.5365, 0.3979, 0.4787, 0.4990, 0.5149, 0.3330, 0.5793],\n",
      "        [0.6403, 0.6098, 0.4007, 0.5299, 0.4660, 0.6473, 0.5304, 0.3117, 0.5478],\n",
      "        [0.7302, 0.7211, 0.4084, 0.1653, 0.4415, 0.4844, 0.1205, 0.5116, 0.2765],\n",
      "        [0.5655, 0.5640, 0.2442, 0.7163, 0.7395, 0.5246, 0.4964, 0.2338, 0.5666]])\n",
      "batch_labels:  tensor([0., 0., 0., 1.])\n",
      "batch_imputs:  tensor([[0.3090, 0.4055, 0.2279, 0.3311, 0.4608, 0.3841, 0.3899, 0.5798, 0.1494],\n",
      "        [0.3313, 0.8006, 0.3123, 0.2696, 0.7052, 0.7381, 0.3469, 0.6509, 0.3586],\n",
      "        [0.4969, 0.5747, 0.3511, 0.5293, 0.4575, 0.7317, 0.2626, 0.4318, 0.5637],\n",
      "        [0.4910, 0.6251, 0.3090, 0.4991, 0.7069, 0.5901, 0.4671, 0.6867, 0.7403]])\n",
      "batch_labels:  tensor([0., 1., 1., 1.])\n",
      "batch_imputs:  tensor([[0.3967, 0.6878, 0.2450, 0.3705, 0.4672, 0.5377, 0.9092, 0.5385, 0.3050],\n",
      "        [0.4800, 0.5032, 0.2057, 0.7016, 0.6714, 0.2940, 0.5129, 0.2820, 0.6594],\n",
      "        [0.7452, 0.6050, 0.5656, 0.9574, 0.5804, 0.3665, 0.3412, 0.6880, 0.2849],\n",
      "        [0.6743, 0.5833, 0.2890, 0.5246, 0.5476, 0.4573, 0.2999, 0.4270, 0.2369]])\n",
      "batch_labels:  tensor([0., 0., 1., 1.])\n",
      "batch_imputs:  tensor([[0.5638, 0.4926, 0.2544, 0.4966, 0.5780, 0.4839, 0.3498, 0.5077, 0.5179],\n",
      "        [0.5570, 0.4684, 0.5678, 0.3072, 0.5441, 0.3598, 0.7125, 0.3321, 0.5943],\n",
      "        [0.6186, 0.3072, 0.3891, 0.3466, 0.6828, 0.3729, 0.5520, 0.5509, 0.6569]])\n",
      "batch_labels:  tensor([0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for batch_imputs, batch_labels in dataloader:\n",
    "    print('batch_imputs: ', batch_imputs )\n",
    "    print('batch_labels: ', batch_labels )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76759400",
   "metadata": {},
   "source": [
    "# Full example based on Water dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3492381c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0848],\n",
      "        [-0.0390],\n",
      "        [-0.1087],\n",
      "        ...,\n",
      "        [ 0.0297],\n",
      "        [-0.0790],\n",
      "        [-0.0654]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Load the different columns into two PyTorch tensors\n",
    "features = torch.tensor(water[['ph', 'Sulfate', 'Conductivity', 'Organic_carbon']].to_numpy()).float()\n",
    "target = torch.tensor(water['Potability'].to_numpy()).float()\n",
    "\n",
    "# Create a dataset from the two generated tensors\n",
    "dataset = TensorDataset(features, target)\n",
    "\n",
    "# Create a dataloader using the above dataset\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=2)\n",
    "x, y = next(iter(dataloader))\n",
    "\n",
    "# Create a model using the nn.Sequential API\n",
    "model = nn.Sequential(nn.Linear(4,8),\n",
    "    nn.Linear(8,1))\n",
    "output = model(features)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee76d0",
   "metadata": {},
   "source": [
    "# Sigmoid\n",
    "- the gradients are always low and approach zero for low and high values of x. This behavior is called saturation\n",
    "- gradient will be so small that it can prevent the weight from changing or updating. This phenomenon is called vanishing gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e56c2d0",
   "metadata": {},
   "source": [
    "# ReLU\n",
    "- or positive inputs, the output of the function is equal to the input. For strictly negative outputs, the output of the function is equal to zero."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c48b515",
   "metadata": {},
   "source": [
    "relu = nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "59baa282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create a ReLU function with PyTorch\n",
    "relu_pytorch = nn.ReLU()\n",
    "\n",
    "# Apply your ReLU function on x, and calculate gradients\n",
    "x = torch.tensor(-1.0, requires_grad=True)\n",
    "y = relu_pytorch(x)\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient of the ReLU function for x\n",
    "gradient = y\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c69f343",
   "metadata": {},
   "source": [
    "# Leaky ReLU\n",
    "- For positive inputs, it behaves similarly to the ReLU function. For negative inputs, however, it multiplies them by a small coefficient (defaulted to 0.01 in PyTorch). \n",
    "- By doing this, the leaky ReLU function has non-null gradients for negative inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d499dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_relu = nn.LeakyReLU(negative_slope = 0.05)\n",
    "# the negative_slope parameter indicates the coefficient by which negative inputs are multiplied. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3edf99d",
   "metadata": {},
   "source": [
    "# Counting the number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ffc02111",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(8,4), # 4 neurons * (8+1 bias) parameters = 36\n",
    "    nn.Linear(4,2)) # 2 neurons * (4+1 bias) parameters = 10\n",
    "# total = 46 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4700ef66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .numel() - returns the number of elements in the tensor\n",
    "total = 0\n",
    "for parameter in model.parameters():\n",
    "    total += parameter.numel()\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cf979c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_capacity(model):\n",
    "  total = 0\n",
    "  for p in model.parameters():\n",
    "    total += p.numel()\n",
    "  return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b46fcc",
   "metadata": {},
   "source": [
    "# Updating weights with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cbca65e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.95)\n",
    "# lr = learning rate - controls the tep size\n",
    "# Typical learning rate values range from 0.10, to 0.001\n",
    "# momentum - controls the inertia of the optimizer (bezwładność)\n",
    "# The momentum keeps the step size large when previous steps were also large, even if the current gradient is small. \n",
    "# Momentum usually ranges from 0.85 to 0.99."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e68c10",
   "metadata": {},
   "source": [
    "# Layer initialization and transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9a6f17eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min:  tensor(-0.1249, grad_fn=<MinBackward1>) max:  tensor(0.1250, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "layer = nn.Linear(64,128)\n",
    "print('min: ', layer.weight.min(), 'max: ', layer.weight.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2af02ed",
   "metadata": {},
   "source": [
    "### Layer initialization usuing uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b77f00a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Parameter' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[119], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m custom_layer \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39muniform_(layer\u001b[38;5;241m.\u001b[39mweight)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mcustom_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241m.\u001b[39mmin(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax: \u001b[39m\u001b[38;5;124m'\u001b[39m, custom_layer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mmax())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Parameter' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "custom_layer = nn.init.uniform_(layer.weight)\n",
    "print('min: ', custom_layer.weight.min(), 'max: ', custom_layer.weight.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd26f81",
   "metadata": {},
   "source": [
    "# Transfer learning \n",
    "- transfer learning consists in taking a model that was trained on a first task and reuse for a second task\n",
    "- we can load the weights from the first model and use them as a starting point to train on this new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb2d875",
   "metadata": {},
   "source": [
    "# Fine tuning - dostrajanie\n",
    "- we load weights from a previously trained model, but train the model with a smaller learning rate\n",
    "- We can even train part of a network, if we decide some of the network layers do not need to be trained and choose to freeze them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbb0b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(64,128),\n",
    "    nn.Linear(128,256)) \n",
    "\n",
    "# Freeze the parameters of the first two layers of this model.\n",
    "for name, param in model.named_parameters():    \n",
    "  \n",
    "    # Check if the parameters belong to the first layer\n",
    "    if name == '0.weight' or name == '0.bias':\n",
    "      \n",
    "        # Freeze the parameters\n",
    "        param.requires_grad = False\n",
    "  \n",
    "    # Check if the parameters belong to the second layer\n",
    "    if name == '1.weight' or name == '1.bias':\n",
    "      \n",
    "        # Freeze the parameters\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a417185",
   "metadata": {},
   "source": [
    "# Evaluating model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82859f1",
   "metadata": {},
   "source": [
    "### Calculating training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b4bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = 0\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    # run the forward pass\n",
    "    .\n",
    "    .\n",
    "    # calculate the loss\n",
    "    loss = criterion(outputs,labels)\n",
    "    # calculate gradient\n",
    "    .\n",
    "    .\n",
    "    # calculate an sum the loss\n",
    "    training_loss +=loss.item()\n",
    "epoch_loss = training_loss /len(trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f998fd",
   "metadata": {},
   "source": [
    "### Calculating validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46603517",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_loss = 0\n",
    "model.eval() # to put the model in evaluation mode, because some layers behave differently at training vs validation\n",
    "with torch.no_grad(): # we will not be performing gradient calculation in this epoch\n",
    "    for i, data in enumerate(validationloader, 0):\n",
    "        # run the forward pass\n",
    "        outputs = model(data[0])\n",
    "        .\n",
    "        # calculate the loss\n",
    "        loss = criterion(outputs,labels)\n",
    "        validation_loss +=loss.item()\n",
    "epoch_loss = validation_loss /len(validationloader)\n",
    "model.train() # in a mood for training again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1714822a",
   "metadata": {},
   "source": [
    "### Calculating accuracy with torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88e7235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=3)\n",
    "\n",
    "for i, data in enumerate(dataloader, 0):\n",
    "    features,labels = data\n",
    "    outputs = model(features)\n",
    "    # calculate accuracy over the batch\n",
    "    acc= metric(outputs, labels.argmax(dim=-1)) # The output variable here would be the probabilities \n",
    "    # returned by the softmax function. If the labels contain one-hot encoded classes, \n",
    "    # we'll need the argmax function to obtain numbers instead of one-hot vectors.\n",
    "# calculate total accuracy over the whole epoch\n",
    "acc = metric.compute()\n",
    "print(f'Accuraccy of all data: {acc}')\n",
    "# reset the metric for the next epoch\n",
    "metric.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5e092d",
   "metadata": {},
   "source": [
    "# Fighting overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad2441c",
   "metadata": {},
   "source": [
    "### Reasons:\n",
    "- a small dataset, \n",
    "- a model with too much capacity, \n",
    "- large values of weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a42f2c",
   "metadata": {},
   "source": [
    "### How to fight:\n",
    "- reduce the model size\n",
    "- add a new type of layer called dropout\n",
    "- use weight decay to force the parameters to remain small\n",
    "- get more data or use data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321c0e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Regularization\" using a dropout layer\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8,4),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5)) # dropout layers are added after activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec81fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with weight decay\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, weight_decay = 0.0001) # value between (0,1)\n",
    "# This regularization term is proportional to the current value of the weight, \n",
    "# and it is subtracted from the gradient during backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30412ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "# Data augmentation is commonly applied to image data, which can be rotated and scaled, \n",
    "# so that different views of the same face become available as \"new\" data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90874b1",
   "metadata": {},
   "source": [
    "# Improving model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6b75b",
   "metadata": {},
   "source": [
    "### Step 1: overfit the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562f40f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is recommended to overfit a single data point\n",
    "features,labels = next(iter(trainloader))\n",
    "for i in range(1000):\n",
    "    outputs = model(features)\n",
    "    loss = criterion(outputs, labels)    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "# Overfitting a single data point should give us an accuracy of one and a loss close to zero\n",
    "# We can then overfit the whole training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f726a2",
   "metadata": {},
   "source": [
    "### Step 2: reduce overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1229b0",
   "metadata": {},
   "source": [
    "### Step 3: fine-tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3eed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search over the hyperparameters\n",
    "for factor in range(2,6):\n",
    "    lr = 10 ** - factor\n",
    "    \n",
    "factor = np.random.uniform(2,6)\n",
    "lr = 10 ** - factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd087b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "for idx in range(10):\n",
    "    # Randomly sample a learning rate factor between 2 and 4\n",
    "    factor = np.random.uniform(2,4)\n",
    "    lr = 10 ** -factor\n",
    "    \n",
    "    # Randomly select a momentum between 0.85 and 0.99\n",
    "    momentum = np.random.uniform(0.85,0.99)\n",
    "    \n",
    "    values.append((lr, momentum))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
